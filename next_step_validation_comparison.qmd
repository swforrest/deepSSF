---
title: "Validating the next step ahead predictions"
subtitle: "To compare the predictions of the deepSSF model with predictions of typical SSFs"
author: "Scott Forrest"
date: "`r Sys.Date()`"
execute: 
  cache: false
bibliography: references.bib
toc: true
number-sections: false
format: 
  html:
    self-contained: true
    code-fold: show
    code-tools: true
    df-print: paged
    code-line-numbers: true
    code-overflow: scroll
    fig-format: png
    fig-dpi: 300
  pdf:
    geometry: 
      - top=30mm
      - left=30mm
editor:
  source
---

## Loading packages

```{r}
#| warning=FALSE

library(tidyverse)
packages <- c("amt", "sf", "terra", "beepr", "tictoc", "circular", "matrixStats", "progress")
walk(packages, require, character.only = T)

```

## Step selection function probabilities

```{r}

# create vector of GPS data filenames
validation_ssf <- list.files(path = "outputs", pattern = "next_step_probs_ssf") 
validation_ids <- substr(validation_ssf, 23, 26)

# import data
validation_ssf_list <- vector(mode = "list", length = length(validation_ssf))

for(i in 1:length(validation_ssf)){
  validation_ssf_list[[i]] <-  read_csv(paste("outputs/",
                                             validation_ssf[[i]], 
                                             sep = ""))
  
  # validation_ssf_list[i]$id <- validation_ids[i]
  attr(validation_ssf_list[[i]]$t_, "tzone") <- "Australia/Queensland"
  attr(validation_ssf_list[[i]]$t2_, "tzone") <- "Australia/Queensland"
  
  print(sum(is.na(validation_ssf_list[[i]]$prob_next_step_ssf_0p)))
  
}

validation_ssf_list

validation_ssf_all <- bind_rows(validation_ssf_list)

```

Lengthening data frames to stack together for plotting

```{r}

validation_ssf_move <- validation_ssf_all %>% 
  dplyr::select(id, x_, y_, t_, x2_, y2_, t2_, hour_t2, yday_t2, year_t2, contains("prob_movement")) %>% 
  pivot_longer(cols = contains("movement"),
               names_to = "full_name",
               values_to = "value") %>% 
  mutate(model = gsub("prob_movement_", "", full_name),
         probability = "move",
         .after = "full_name")

validation_ssf_habitat <- validation_ssf_all %>% 
  dplyr::select(id, x_, y_, t_, x2_, y2_, t2_, hour_t2, yday_t2, year_t2, contains("prob_habitat")) %>% 
  pivot_longer(cols = contains("habitat"),
               names_to = "full_name",
               values_to = "value") %>% 
  mutate(model = gsub("prob_habitat_", "", full_name),
         probability = "habitat",
         .after = "full_name")

validation_ssf_next_step <- validation_ssf_all %>%
  dplyr::select(id, x_, y_, t_, x2_, y2_, t2_, hour_t2, yday_t2, year_t2, contains("prob_next_step")) %>% 
  pivot_longer(cols = contains("next_step"),
               names_to = "full_name",
               values_to = "value") %>% 
  mutate(model = gsub("prob_next_step_", "", full_name),
         probability = "next_step",
         .after = "full_name")

validation_ssf_long <- bind_rows(validation_ssf_move,
                                 validation_ssf_habitat,
                                 validation_ssf_next_step)

```

## deepSSF probabilities

```{r}

# create vector of GPS data filenames
validation_deepssf <- list.files(path = "outputs", pattern = "next_step_probs_TAmix") 
validation_ids <- substr(validation_deepssf, 25, 28)

# import data
validation_deepssf_list <- vector(mode = "list", length = length(validation_deepssf))

for(i in 1:length(validation_deepssf)){
  validation_deepssf_list[[i]] <-  read_csv(paste("outputs/",
                                             validation_deepssf[[i]], 
                                             sep = ""))
  
  # validation_deepssf_list[i]$id <- validation_ids[i]
  attr(validation_deepssf_list[[i]]$t_, "tzone") <- "Australia/Queensland"
  attr(validation_deepssf_list[[i]]$t2_, "tzone") <- "Australia/Queensland"
  
}

validation_deepssf_list

validation_deepssf_all <- bind_rows(validation_deepssf_list)

```

Lengthening data frames to stack together for plotting

```{r}

validation_deepssf_long <- validation_deepssf_all %>% 
  dplyr::select(id, x_, y_, t_, x2_, y2_, t2_, hour_t2, yday_t2, year_t2, contains("probs")) %>% 
  pivot_longer(cols = contains("probs"),
               names_to = "full_name",
               values_to = "value") %>% 
  mutate(model = "deepSSF",
         probability = gsub("_probs", "", full_name),
         .after = "full_name")

validation_all_long <- bind_rows(validation_ssf_long,
                                 validation_deepssf_long)

validation_all_long <- validation_all_long %>% filter(value > 0)

```

# Plot the validation data

```{r}

# if there were uniform probabilities (i.e. no selection)
uniform_prob <- 1/(101*101)

validation_all_long %>% filter(probability == "habitat") %>%
  ggplot() +
  geom_point(aes(x = t_,
                 y = value,
                 colour = model,
                 group = interaction(id, model)),
             alpha = 0.01) +
  geom_smooth(aes(x = t_, 
                  y = value, 
                  colour = model, 
                  group = interaction(id, model)), 
              alpha = 0.25) +
  geom_hline(yintercept = uniform_prob, linetype = "dashed") +
  # scale_y_continuous() +
  scale_y_log10() +
  # scale_colour_viridis_d() +
  theme_bw()

validation_all_long %>% filter(probability == "move") %>%
  ggplot() +
  geom_point(aes(x = t_,
                 y = value,
                 colour = model,
                 group = interaction(id, model)),
             alpha = 0.01) +
  geom_smooth(aes(x = t_, 
                  y = value, 
                  colour = model, 
                  group = interaction(id, model)), 
              alpha = 0.25) +
  geom_hline(yintercept = uniform_prob, linetype = "dashed") +
  # scale_y_continuous() +
  scale_y_log10() +
  # scale_colour_viridis_d() +
  theme_bw()

validation_all_long %>% filter(probability == "next_step") %>%
  ggplot() +
  geom_point(aes(x = t_,
                 y = value,
                 colour = model,
                 group = interaction(id, model)),
             alpha = 0.01) +
  geom_smooth(aes(x = t_, 
                  y = value, 
                  colour = model, 
                  group = interaction(id, model)), 
              alpha = 0.25) +
  geom_hline(yintercept = uniform_prob, linetype = "dashed") +
  # scale_y_continuous() +
  scale_y_log10() +
  # scale_colour_viridis_d() +
  theme_bw()

```

Subset

```{r}

validation_ssf_long %>% filter(probability == "habitat" &
                                 year_t2 == 2019 & 
                                 yday_t2 %in% c(4)) %>% 
  ggplot() +
  geom_line(aes(x = t_, y = value, colour = as.factor(id)), 
             alpha = 1) +
  # geom_smooth(aes(x = t_, y = habitat_probs, colour = habitat_model)) +
  geom_hline(yintercept = uniform_prob, linetype = "dashed") +
  scale_y_log10() +
  scale_colour_viridis_d() +
  theme_bw()

```

## Hourly

```{r}

validation_all_long %>% filter(probability == "habitat") %>%
  ggplot() +
  geom_jitter(aes(x = hour_t2,
                 y = value,
                 colour = model,
                 group = interaction(id, model)),
             alpha = 0.01) +
  geom_smooth(aes(x = hour_t2, 
                  y = value, 
                  colour = model, 
                  group = interaction(id, model)), 
              alpha = 0.25) +
  geom_hline(yintercept = uniform_prob, linetype = "dashed") +
  scale_y_continuous() +
  # scale_y_log10(limits = c(1e-6, 1e-2)) + 
  # scale_colour_viridis_d() +
  theme_bw()

validation_all_long %>% filter(probability == "move") %>%
  ggplot() +
  geom_jitter(aes(x = hour_t2,
                 y = value,
                 colour = model,
                 group = interaction(id, model)),
             alpha = 0.01) +
  geom_smooth(aes(x = hour_t2, 
                  y = value, 
                  colour = model, 
                  group = interaction(id, model)), 
              alpha = 0.25) +
  geom_hline(yintercept = uniform_prob, linetype = "dashed") +
  # scale_y_continuous() +
  scale_y_log10() +
  # scale_colour_viridis_d() +
  theme_bw()

validation_all_long %>% filter(probability == "next_step") %>%
  ggplot() +
  geom_jitter(aes(x = hour_t2,
                 y = value,
                 colour = model,
                 group = interaction(id, model)),
             alpha = 0.01) +
  geom_smooth(aes(x = hour_t2, 
                  y = value, 
                  colour = model, 
                  group = interaction(id, model)), 
              alpha = 0.25) +
  geom_hline(yintercept = uniform_prob, linetype = "dashed") +
  # scale_y_continuous() +
  scale_y_log10() +
  # scale_colour_viridis_d() +
  theme_bw()


```

## Hourly

```{r}

validation_all_long %>% filter(probability == "habitat" & id == 2005) %>%
  ggplot() +
  geom_jitter(aes(x = factor(hour_t2),
                 y = value,
                 colour = model,
                 group = interaction(id, model)),
             alpha = 0.01) +
  geom_smooth(aes(x = factor(hour_t2), 
                  y = value, 
                  colour = model, 
                  group = interaction(id, model)
                  ), 
              alpha = 0.25) +
  geom_hline(yintercept = uniform_prob, linetype = "dashed") +
  # scale_y_continuous() +
  scale_y_log10() + # limits = c(1e-5, 1e-3)
  # scale_colour_viridis_d() +
  theme_bw()

validation_all_long %>% filter(probability == "move" & id == 2005) %>%
  ggplot() +
  geom_jitter(aes(x = hour_t2,
                  y = value,
                  colour = model,
                 group = interaction(id, model)),
             alpha = 0.01) +
  geom_smooth(aes(x = hour_t2, 
                  y = value, 
                  colour = model, 
                  group = interaction(id, model)), 
              alpha = 0.25) +
  geom_hline(yintercept = uniform_prob, linetype = "dashed") +
  # scale_y_continuous() +
  scale_y_log10() +
  # scale_colour_viridis_d() +
  theme_bw()

validation_all_long %>% filter(probability == "next_step" & id == 2005) %>%
  ggplot() +
  geom_jitter(aes(x = hour_t2,
                  y = value,
                  colour = model,
                 group = interaction(id, model)),
             alpha = 0.01) +
  geom_smooth(aes(x = hour_t2, 
                  y = value, 
                  colour = model, 
                  group = interaction(id, model)), 
              alpha = 0.25) +
  geom_hline(yintercept = uniform_prob, linetype = "dashed") +
  # scale_y_continuous() +
  scale_y_log10() +
  # scale_colour_viridis_d() +
  theme_bw()


```

# Summary statistics

```{r}

validation_all_long %>% group_by(model, probability) %>% 
  summarise(average_prob = mean(value, na.rm = T),
            sd_prob = sd(value, na.rm = T))

```