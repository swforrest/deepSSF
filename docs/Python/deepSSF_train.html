<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Scott Forrest">
<meta name="dcterms.date" content="2025-02-16">

<title>deepSSF Training â€“ deepSSF</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-4a1c1709ed6c34e18d4d8b73dec7994d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">deepSSF</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../getting_started.html"> 
<span class="menu-text">Getting Started</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../study_system.html"> 
<span class="menu-text">Study System</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../data_preparation.html"> 
<span class="menu-text">Data Preparation</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../model_training.html" aria-current="page"> 
<span class="menu-text">Model Training</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../predictions.html"> 
<span class="menu-text">Predictions</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../inference.html"> 
<span class="menu-text">Inference</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../validation.html"> 
<span class="menu-text">Validation</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/swforrest/deepSSF"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:scottwforrest@gmail.com"> <i class="bi bi-envelope-at-fill" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/swforrest/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../Python/deepSSF_train.html">deepSSF Training</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../model_training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model Training</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Python/deepSSF_train.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">deepSSF Training</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Python/deepSSF_train_S2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">deepSSF Training - S2</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#model-overview" id="toc-model-overview" class="nav-link active" data-scroll-target="#model-overview">Model overview</a>
  <ul class="collapse">
  <li><a href="#import-packages" id="toc-import-packages" class="nav-link" data-scroll-target="#import-packages">Import packages</a>
  <ul class="collapse">
  <li><a href="#if-using-google-colab-uncomment-the-following-lines" id="toc-if-using-google-colab-uncomment-the-following-lines" class="nav-link" data-scroll-target="#if-using-google-colab-uncomment-the-following-lines">If using Google Colab, uncomment the following lines</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#prepare-data" id="toc-prepare-data" class="nav-link" data-scroll-target="#prepare-data">Prepare data</a>
  <ul class="collapse">
  <li><a href="#set-paths-to-data" id="toc-set-paths-to-data" class="nav-link" data-scroll-target="#set-paths-to-data">Set paths to data</a></li>
  <li><a href="#read-buffalo-data" id="toc-read-buffalo-data" class="nav-link" data-scroll-target="#read-buffalo-data">Read buffalo data</a></li>
  </ul></li>
  <li><a href="#spatial-data" id="toc-spatial-data" class="nav-link" data-scroll-target="#spatial-data">Spatial data</a>
  <ul class="collapse">
  <li><a href="#ndvi" id="toc-ndvi" class="nav-link" data-scroll-target="#ndvi">NDVI</a>
  <ul class="collapse">
  <li><a href="#normalise-the-layers" id="toc-normalise-the-layers" class="nav-link" data-scroll-target="#normalise-the-layers">Normalise the layers</a></li>
  </ul></li>
  <li><a href="#canopy-cover" id="toc-canopy-cover" class="nav-link" data-scroll-target="#canopy-cover">Canopy cover</a></li>
  <li><a href="#herbaceous-vegetation" id="toc-herbaceous-vegetation" class="nav-link" data-scroll-target="#herbaceous-vegetation">Herbaceous vegetation</a></li>
  <li><a href="#slope" id="toc-slope" class="nav-link" data-scroll-target="#slope">Slope</a></li>
  <li><a href="#presence-records---target-of-model" id="toc-presence-records---target-of-model" class="nav-link" data-scroll-target="#presence-records---target-of-model">Presence records - target of model</a>
  <ul class="collapse">
  <li><a href="#combine-the-spatial-layers-into-channels" id="toc-combine-the-spatial-layers-into-channels" class="nav-link" data-scroll-target="#combine-the-spatial-layers-into-channels">Combine the spatial layers into channels</a></li>
  </ul></li>
  <li><a href="#defining-data-sets-and-data-loaders" id="toc-defining-data-sets-and-data-loaders" class="nav-link" data-scroll-target="#defining-data-sets-and-data-loaders">Defining data sets and data loaders</a>
  <ul class="collapse">
  <li><a href="#creating-a-dataset-class" id="toc-creating-a-dataset-class" class="nav-link" data-scroll-target="#creating-a-dataset-class">Creating a dataset class</a></li>
  <li><a href="#split-into-training-validation-and-test-sets" id="toc-split-into-training-validation-and-test-sets" class="nav-link" data-scroll-target="#split-into-training-validation-and-test-sets">Split into training, validation and test sets</a></li>
  <li><a href="#create-dataloaders" id="toc-create-dataloaders" class="nav-link" data-scroll-target="#create-dataloaders">Create dataloaders</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#define-the-model" id="toc-define-the-model" class="nav-link" data-scroll-target="#define-the-model">Define the model</a>
  <ul class="collapse">
  <li><a href="#convolutional-block-for-the-habitat-selection-subnetwork" id="toc-convolutional-block-for-the-habitat-selection-subnetwork" class="nav-link" data-scroll-target="#convolutional-block-for-the-habitat-selection-subnetwork">Convolutional block for the habitat selection subnetwork</a></li>
  <li><a href="#convolutional-block-for-the-movement-subnetwork" id="toc-convolutional-block-for-the-movement-subnetwork" class="nav-link" data-scroll-target="#convolutional-block-for-the-movement-subnetwork">Convolutional block for the movement subnetwork</a></li>
  <li><a href="#fully-connected-block-for-the-movement-subnetwork" id="toc-fully-connected-block-for-the-movement-subnetwork" class="nav-link" data-scroll-target="#fully-connected-block-for-the-movement-subnetwork">Fully connected block for the movement subnetwork</a></li>
  <li><a href="#block-to-convert-the-movement-parameters-to-a-probability-distribution" id="toc-block-to-convert-the-movement-parameters-to-a-probability-distribution" class="nav-link" data-scroll-target="#block-to-convert-the-movement-parameters-to-a-probability-distribution">Block to convert the movement parameters to a probability distribution</a>
  <ul class="collapse">
  <li><a href="#what-the-block-does" id="toc-what-the-block-does" class="nav-link" data-scroll-target="#what-the-block-does">What the block does</a></li>
  <li><a href="#constraints" id="toc-constraints" class="nav-link" data-scroll-target="#constraints">Constraints</a></li>
  <li><a href="#notes" id="toc-notes" class="nav-link" data-scroll-target="#notes">Notes</a></li>
  </ul></li>
  <li><a href="#scalar-to-grid-block" id="toc-scalar-to-grid-block" class="nav-link" data-scroll-target="#scalar-to-grid-block">Scalar to grid block</a></li>
  <li><a href="#combine-the-blocks-into-the-deepssf-model" id="toc-combine-the-blocks-into-the-deepssf-model" class="nav-link" data-scroll-target="#combine-the-blocks-into-the-deepssf-model">Combine the blocks into the deepSSF model</a></li>
  <li><a href="#set-the-parameters-for-the-model-which-will-be-specified-in-a-dictionary" id="toc-set-the-parameters-for-the-model-which-will-be-specified-in-a-dictionary" class="nav-link" data-scroll-target="#set-the-parameters-for-the-model-which-will-be-specified-in-a-dictionary">Set the parameters for the model which will be specified in a dictionary</a></li>
  <li><a href="#define-the-parameters-for-the-model" id="toc-define-the-parameters-for-the-model" class="nav-link" data-scroll-target="#define-the-parameters-for-the-model">Define the parameters for the model</a></li>
  <li><a href="#note-about-the-model" id="toc-note-about-the-model" class="nav-link" data-scroll-target="#note-about-the-model">Note about the model</a></li>
  <li><a href="#instantiate-the-model" id="toc-instantiate-the-model" class="nav-link" data-scroll-target="#instantiate-the-model">Instantiate the model</a></li>
  </ul></li>
  <li><a href="#testing-model-components" id="toc-testing-model-components" class="nav-link" data-scroll-target="#testing-model-components">Testing model components</a>
  <ul class="collapse">
  <li><a href="#testing-the-movement-parameter-to-probability-distribution-block" id="toc-testing-the-movement-parameter-to-probability-distribution-block" class="nav-link" data-scroll-target="#testing-the-movement-parameter-to-probability-distribution-block">Testing the movement parameter to probability distribution block</a></li>
  <li><a href="#pull-out-some-testing-data" id="toc-pull-out-some-testing-data" class="nav-link" data-scroll-target="#pull-out-some-testing-data">Pull out some testing data</a>
  <ul class="collapse">
  <li><a href="#for-visualisation-we-can-return-the-scale-of-the-covariates-to-their-original-values." id="toc-for-visualisation-we-can-return-the-scale-of-the-covariates-to-their-original-values." class="nav-link" data-scroll-target="#for-visualisation-we-can-return-the-scale-of-the-covariates-to-their-original-values.">For visualisation, we can return the scale of the covariates to their original values.</a></li>
  <li><a href="#pull-out-the-scalar-values" id="toc-pull-out-the-scalar-values" class="nav-link" data-scroll-target="#pull-out-the-scalar-values">Pull out the scalar values</a></li>
  <li><a href="#helper-functions" id="toc-helper-functions" class="nav-link" data-scroll-target="#helper-functions">Helper functions</a></li>
  <li><a href="#calculate-the-hour-day-of-year-and-previous-bearing-of-the-test-sample" id="toc-calculate-the-hour-day-of-year-and-previous-bearing-of-the-test-sample" class="nav-link" data-scroll-target="#calculate-the-hour-day-of-year-and-previous-bearing-of-the-test-sample">Calculate the hour, day of year and previous bearing of the test sample</a></li>
  <li><a href="#grab-the-row-and-column-of-the-observed-next-step-label-or-target" id="toc-grab-the-row-and-column-of-the-observed-next-step-label-or-target" class="nav-link" data-scroll-target="#grab-the-row-and-column-of-the-observed-next-step-label-or-target">Grab the row and column of the observed next step (label or target)</a></li>
  <li><a href="#plot-the-sample-covariates" id="toc-plot-the-sample-covariates" class="nav-link" data-scroll-target="#plot-the-sample-covariates">Plot the sample covariates</a></li>
  </ul></li>
  <li><a href="#plot-the-target-location-of-the-next-step" id="toc-plot-the-target-location-of-the-next-step" class="nav-link" data-scroll-target="#plot-the-target-location-of-the-next-step">Plot the target (location of the next step)</a></li>
  <li><a href="#testing-the-scalar-to-grid-function" id="toc-testing-the-scalar-to-grid-function" class="nav-link" data-scroll-target="#testing-the-scalar-to-grid-function">Testing the scalar to grid function</a></li>
  </ul></li>
  <li><a href="#test-the-full-model" id="toc-test-the-full-model" class="nav-link" data-scroll-target="#test-the-full-model">Test the full model</a>
  <ul class="collapse">
  <li><a href="#habitat-predictions" id="toc-habitat-predictions" class="nav-link" data-scroll-target="#habitat-predictions">Habitat predictions</a></li>
  <li><a href="#movement-predictions" id="toc-movement-predictions" class="nav-link" data-scroll-target="#movement-predictions">Movement predictions</a></li>
  <li><a href="#next-step-probability-distribution" id="toc-next-step-probability-distribution" class="nav-link" data-scroll-target="#next-step-probability-distribution">Next-step probability distribution</a></li>
  </ul></li>
  <li><a href="#prepare-for-training" id="toc-prepare-for-training" class="nav-link" data-scroll-target="#prepare-for-training">Prepare for training</a>
  <ul class="collapse">
  <li><a href="#loss-function" id="toc-loss-function" class="nav-link" data-scroll-target="#loss-function">Loss function</a></li>
  <li><a href="#early-stopping-code" id="toc-early-stopping-code" class="nav-link" data-scroll-target="#early-stopping-code">Early stopping code</a></li>
  <li><a href="#set-the-learning-rate" id="toc-set-the-learning-rate" class="nav-link" data-scroll-target="#set-the-learning-rate">Set the learning rate</a>
  <ul class="collapse">
  <li><a href="#path-to-save-the-model-weights" id="toc-path-to-save-the-model-weights" class="nav-link" data-scroll-target="#path-to-save-the-model-weights">Path to save the model weights</a></li>
  </ul></li>
  <li><a href="#instantiate-the-loss-function-optimiser-learning-rate-scheduler-and-early-stopping-code" id="toc-instantiate-the-loss-function-optimiser-learning-rate-scheduler-and-early-stopping-code" class="nav-link" data-scroll-target="#instantiate-the-loss-function-optimiser-learning-rate-scheduler-and-early-stopping-code">Instantiate the loss function, optimiser, learning rate scheduler and early stopping code</a></li>
  <li><a href="#training-loop" id="toc-training-loop" class="nav-link" data-scroll-target="#training-loop">Training loop</a></li>
  <li><a href="#test-loop" id="toc-test-loop" class="nav-link" data-scroll-target="#test-loop">Test loop</a></li>
  </ul></li>
  <li><a href="#train-the-model" id="toc-train-the-model" class="nav-link" data-scroll-target="#train-the-model">Train the model</a></li>
  <li><a href="#loading-in-previous-models" id="toc-loading-in-previous-models" class="nav-link" data-scroll-target="#loading-in-previous-models">Loading in previous models</a>
  <ul class="collapse">
  <li><a href="#if-loading-a-previously-trained-model" id="toc-if-loading-a-previously-trained-model" class="nav-link" data-scroll-target="#if-loading-a-previously-trained-model">If loading a previously trained model</a></li>
  </ul></li>
  <li><a href="#view-model-outputs" id="toc-view-model-outputs" class="nav-link" data-scroll-target="#view-model-outputs">View model outputs</a>
  <ul class="collapse">
  <li><a href="#save-the-validation-loss-as-a-dataframe" id="toc-save-the-validation-loss-as-a-dataframe" class="nav-link" data-scroll-target="#save-the-validation-loss-as-a-dataframe">Save the validation loss as a dataframe</a></li>
  <li><a href="#plot-the-validation-loss" id="toc-plot-the-validation-loss" class="nav-link" data-scroll-target="#plot-the-validation-loss">Plot the validation loss</a></li>
  <li><a href="#animation-of-model-training" id="toc-animation-of-model-training" class="nav-link" data-scroll-target="#animation-of-model-training">Animation of model training</a></li>
  </ul></li>
  <li><a href="#test-the-model-on-sample-covariates" id="toc-test-the-model-on-sample-covariates" class="nav-link" data-scroll-target="#test-the-model-on-sample-covariates">Test the model on sample covariates</a>
  <ul class="collapse">
  <li><a href="#run-the-model-on-the-sample-covariates" id="toc-run-the-model-on-the-sample-covariates" class="nav-link" data-scroll-target="#run-the-model-on-the-sample-covariates">Run the model on the sample covariates</a></li>
  </ul></li>
  <li><a href="#extracting-convolution-layer-outputs" id="toc-extracting-convolution-layer-outputs" class="nav-link" data-scroll-target="#extracting-convolution-layer-outputs">Extracting convolution layer outputs</a>
  <ul class="collapse">
  <li><a href="#convolutional-layer-1" id="toc-convolutional-layer-1" class="nav-link" data-scroll-target="#convolutional-layer-1">Convolutional layer 1</a>
  <ul class="collapse">
  <li><a href="#activation-hook" id="toc-activation-hook" class="nav-link" data-scroll-target="#activation-hook">Activation hook</a></li>
  <li><a href="#stack-spatial-and-scalar-as-grid-covariates" id="toc-stack-spatial-and-scalar-as-grid-covariates" class="nav-link" data-scroll-target="#stack-spatial-and-scalar-as-grid-covariates">Stack spatial and scalar (as grid) covariates</a></li>
  <li><a href="#extract-filters-and-plot" id="toc-extract-filters-and-plot" class="nav-link" data-scroll-target="#extract-filters-and-plot">Extract filters and plot</a></li>
  </ul></li>
  <li><a href="#convolutional-layer-2" id="toc-convolutional-layer-2" class="nav-link" data-scroll-target="#convolutional-layer-2">Convolutional layer 2</a>
  <ul class="collapse">
  <li><a href="#activation-hook-1" id="toc-activation-hook-1" class="nav-link" data-scroll-target="#activation-hook-1">Activation hook</a></li>
  <li><a href="#extract-filters-and-plot-1" id="toc-extract-filters-and-plot-1" class="nav-link" data-scroll-target="#extract-filters-and-plot-1">Extract filters and plot</a></li>
  </ul></li>
  <li><a href="#convolutional-layer-3" id="toc-convolutional-layer-3" class="nav-link" data-scroll-target="#convolutional-layer-3">Convolutional layer 3</a>
  <ul class="collapse">
  <li><a href="#activation-hook-2" id="toc-activation-hook-2" class="nav-link" data-scroll-target="#activation-hook-2">Activation hook</a></li>
  <li><a href="#extract-filters-and-plot-2" id="toc-extract-filters-and-plot-2" class="nav-link" data-scroll-target="#extract-filters-and-plot-2">Extract filters and plot</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#checking-estimated-movement-parameters" id="toc-checking-estimated-movement-parameters" class="nav-link" data-scroll-target="#checking-estimated-movement-parameters">Checking estimated movement parameters</a>
  <ul class="collapse">
  <li><a href="#plot-the-movement-distributions" id="toc-plot-the-movement-distributions" class="nav-link" data-scroll-target="#plot-the-movement-distributions">Plot the movement distributions</a></li>
  <li><a href="#generate-a-distribution-of-movement-parameters" id="toc-generate-a-distribution-of-movement-parameters" class="nav-link" data-scroll-target="#generate-a-distribution-of-movement-parameters">Generate a distribution of movement parameters</a>
  <ul class="collapse">
  <li><a href="#plot-the-distribution-of-movement-parameters" id="toc-plot-the-distribution-of-movement-parameters" class="nav-link" data-scroll-target="#plot-the-distribution-of-movement-parameters">Plot the distribution of movement parameters</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">deepSSF Training</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Scott Forrest <a href="mailto:scottwforrest@gmail.com" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 16, 2025</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    <p>In this script, we will train a deepSSF model on the training data. In this case the training data was generated using the <code>deepSSF_data_prep_id.qmd</code> script, which crops out local images for each step of the observed telemetry data.</p>
  </div>
</div>


</header>


<section id="model-overview" class="level1">
<h1>Model overview</h1>
<p>Refer to the paper and the <a href="../index.html">Model Overview</a> section for a conceptual overview of the model.</p>
<section id="import-packages" class="level2">
<h2 class="anchored" data-anchor-id="import-packages">Import packages</h2>
<div id="cell-3" class="cell" data-outputid="205da944-eee9-4a12-8089-25362f87a046">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># If using Google Colab, uncomment the following line</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install rasterio</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sys.version)  <span class="co"># Print Python version in use</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np                                      <span class="co"># Array operations</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt                         <span class="co"># Plotting library</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch                                            <span class="co"># Main PyTorch library</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim                             <span class="co"># Optimization algorithms</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn                                    <span class="co"># Neural network modules</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os                                               <span class="co"># Operating system utilities</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd                                     <span class="co"># Data manipulation</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> rasterio                                         <span class="co"># Geospatial raster data</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader        <span class="co"># Dataset and batch data loading</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> datetime                           <span class="co"># Date/time utilities</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> rasterio.plot <span class="im">import</span> show                           <span class="co"># Plot raster data</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Get today's date</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>today_date <span class="op">=</span> datetime.today().strftime(<span class="st">'%Y-%m-</span><span class="sc">%d</span><span class="st">'</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seed for reproducibility</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="dv">42</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:18:29) [MSC v.1929 64 bit (AMD64)]</code></pre>
</div>
</div>
<section id="if-using-google-colab-uncomment-the-following-lines" class="level3">
<h3 class="anchored" data-anchor-id="if-using-google-colab-uncomment-the-following-lines">If using Google Colab, uncomment the following lines</h3>
<p>The file directories will also need to be changed to match the location of the files in your Google Drive.</p>
<div id="cell-5" class="cell" data-outputid="a4f7f38c-a7fd-4451-ef8c-e8cdf69c3201" data-execution_count="2">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># from google.colab import drive</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># drive.mount('/content/drive')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
</section>
<section id="prepare-data" class="level1">
<h1>Prepare data</h1>
<section id="set-paths-to-data" class="level2">
<h2 class="anchored" data-anchor-id="set-paths-to-data">Set paths to data</h2>
<div id="cell-8" class="cell">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># select the id to train the model on</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>buffalo_id <span class="op">=</span> <span class="dv">2005</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">10297</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify the path to CSV file</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>csv_file_path <span class="op">=</span> <span class="ss">f'../buffalo_local_data_id/buffalo_</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_data_df_lag_1hr_n</span><span class="sc">{</span>n_samples<span class="sc">}</span><span class="ss">.csv'</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Path to your TIF file</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>ndvi_path <span class="op">=</span> <span class="ss">f'../buffalo_local_layers_id/buffalo_</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_ndvi_cent101x101_lag_1hr_n</span><span class="sc">{</span>n_samples<span class="sc">}</span><span class="ss">.tif'</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Path to your TIF file</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>canopy_path <span class="op">=</span> <span class="ss">f'../buffalo_local_layers_id/buffalo_</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_canopy_cent101x101_lag_1hr_n</span><span class="sc">{</span>n_samples<span class="sc">}</span><span class="ss">.tif'</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Path to your TIF file</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>herby_path <span class="op">=</span> <span class="ss">f'../buffalo_local_layers_id/buffalo_</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_herby_cent101x101_lag_1hr_n</span><span class="sc">{</span>n_samples<span class="sc">}</span><span class="ss">.tif'</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Path to your TIF file</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>slope_path <span class="op">=</span> <span class="ss">f'../buffalo_local_layers_id/buffalo_</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_slope_cent101x101_lag_1hr_n</span><span class="sc">{</span>n_samples<span class="sc">}</span><span class="ss">.tif'</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Path to your TIF file</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>pres_path <span class="op">=</span> <span class="ss">f'../buffalo_local_layers_id/buffalo_</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_pres_cent101x101_lag_1hr_n</span><span class="sc">{</span>n_samples<span class="sc">}</span><span class="ss">.tif'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="read-buffalo-data" class="level2">
<h2 class="anchored" data-anchor-id="read-buffalo-data">Read buffalo data</h2>
<div id="cell-10" class="cell" data-outputid="e5213292-23ed-44e5-fc10-798e99442eb8" data-execution_count="4">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Read the CSV file into a DataFrame</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>buffalo_df <span class="op">=</span> pd.read_csv(csv_file_path)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(buffalo_df.shape)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Lag the values in column 'A' by one index to get the bearing of the previous step</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>buffalo_df[<span class="st">'bearing_tm1'</span>] <span class="op">=</span> buffalo_df[<span class="st">'bearing'</span>].shift(<span class="dv">1</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Pad the missing value with a specified value, e.g., 0</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>buffalo_df[<span class="st">'bearing_tm1'</span>] <span class="op">=</span> buffalo_df[<span class="st">'bearing_tm1'</span>].fillna(<span class="dv">0</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the first few rows of the DataFrame</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(buffalo_df.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(10103, 35)
             x_            y_                    t_    id           x1_  \
0  41969.310875 -1.435671e+06  2018-07-25T01:04:23Z  2005  41969.310875   
1  41921.521939 -1.435654e+06  2018-07-25T02:04:39Z  2005  41921.521939   
2  41779.439594 -1.435601e+06  2018-07-25T03:04:17Z  2005  41779.439594   
3  41841.203272 -1.435635e+06  2018-07-25T04:04:39Z  2005  41841.203272   
4  41655.463332 -1.435604e+06  2018-07-25T05:04:27Z  2005  41655.463332   

            y1_           x2_           y2_     x2_cent    y2_cent  ...  \
0 -1.435671e+06  41921.521939 -1.435654e+06  -47.788936  16.857110  ...   
1 -1.435654e+06  41779.439594 -1.435601e+06 -142.082345  53.568427  ...   
2 -1.435601e+06  41841.203272 -1.435635e+06   61.763677 -34.322938  ...   
3 -1.435635e+06  41655.463332 -1.435604e+06 -185.739939  31.003534  ...   
4 -1.435604e+06  41618.651923 -1.435608e+06  -36.811409  -4.438037  ...   

     cos_ta         x_min         x_max         y_min         y_max  s2_index  \
0  0.201466  40706.810875  43231.810875 -1.436934e+06 -1.434409e+06         7   
1  0.999770  40659.021939  43184.021939 -1.436917e+06 -1.434392e+06         7   
2 -0.989262  40516.939594  43041.939594 -1.436863e+06 -1.434338e+06         7   
3 -0.942144  40578.703272  43103.703272 -1.436898e+06 -1.434373e+06         7   
4  0.959556  40392.963332  42917.963332 -1.436867e+06 -1.434342e+06         7   

   points_vect_cent  year_t2  yday_t2_2018_base  bearing_tm1  
0               NaN     2018                206     0.000000  
1               NaN     2018                206     2.802478  
2               NaN     2018                206     2.781049  
3               NaN     2018                206    -0.507220  
4               NaN     2018                206     2.976198  

[5 rows x 36 columns]</code></pre>
</div>
</div>
</section>
</section>
<section id="spatial-data" class="level1">
<h1>Spatial data</h1>
<section id="ndvi" class="level2">
<h2 class="anchored" data-anchor-id="ndvi">NDVI</h2>
<div id="cell-13" class="cell" data-execution_count="5">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Using rasterio</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> rasterio.<span class="bu">open</span>(ndvi_path) <span class="im">as</span> ndvi:</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Read all layers/channels into a single numpy array</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># rasterio indexes channels starting from 1, hence the range is 1 to src.count + 1</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    ndvi_stack <span class="op">=</span> ndvi.read([i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, ndvi.count <span class="op">+</span> <span class="dv">1</span>)])</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ndvi_stack.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(10103, 101, 101)</code></pre>
</div>
</div>
<section id="normalise-the-layers" class="level3">
<h3 class="anchored" data-anchor-id="normalise-the-layers">Normalise the layers</h3>
<div id="cell-15" class="cell" data-outputid="8e908f67-d5e7-4ce0-94df-d53c02e6b887" data-execution_count="6">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace NaNs in the original array with -1, which represents water</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>ndvi_stack <span class="op">=</span> np.nan_to_num(ndvi_stack, nan<span class="op">=-</span><span class="fl">1.0</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the numpy array to a PyTorch tensor, which is the format required for training the model</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>ndvi_tens <span class="op">=</span> torch.from_numpy(ndvi_stack)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the shape of the PyTorch tensor</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ndvi_tens.shape)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the mean, max, and min values of the NDVI tensor</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>ndvi_mean <span class="op">=</span> torch.mean(ndvi_tens)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>ndvi_max <span class="op">=</span> torch.<span class="bu">max</span>(ndvi_tens)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>ndvi_min <span class="op">=</span> torch.<span class="bu">min</span>(ndvi_tens)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mean = "</span>, ndvi_mean)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Max = "</span>, ndvi_max)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Min = "</span>, ndvi_min)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalizing the data</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>ndvi_tens_norm <span class="op">=</span> (ndvi_tens <span class="op">-</span> ndvi_min) <span class="op">/</span> (ndvi_max <span class="op">-</span> ndvi_min)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mean = "</span>, torch.mean(ndvi_tens_norm))</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Max = "</span>, torch.<span class="bu">max</span>(ndvi_tens_norm))</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Min = "</span>, torch.<span class="bu">min</span>(ndvi_tens_norm))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([10103, 101, 101])
Mean =  tensor(0.3039)
Max =  tensor(0.8220)
Min =  tensor(-0.2772)
Mean =  tensor(0.5287)
Max =  tensor(1.)
Min =  tensor(0.)</code></pre>
</div>
</div>
<p>Plot a single NDVI layer</p>
<div id="cell-17" class="cell" data-outputid="2afa0e46-b2f2-4f96-8f18-4f45d154e06a" data-execution_count="7">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">1</span>):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    plt.imshow(ndvi_tens_norm[i].numpy())</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    plt.colorbar()</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    plt.show() </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="canopy-cover" class="level2">
<h2 class="anchored" data-anchor-id="canopy-cover">Canopy cover</h2>
<div id="cell-19" class="cell" data-execution_count="8">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Using rasterio</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> rasterio.<span class="bu">open</span>(canopy_path) <span class="im">as</span> canopy:</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Read all layers/channels into a single numpy array</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># rasterio indexes channels starting from 1, hence the range is 1 to src.count + 1</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    canopy_stack <span class="op">=</span> canopy.read([i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, canopy.count <span class="op">+</span> <span class="dv">1</span>)])</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(canopy_stack.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(10103, 101, 101)</code></pre>
</div>
</div>
<div id="cell-20" class="cell" data-outputid="001a2b11-8bf7-4528-e555-cf4967805f0f" data-execution_count="9">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the numpy array to a PyTorch tensor, which is the format required for training the model</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>canopy_tens <span class="op">=</span> torch.from_numpy(canopy_stack)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(canopy_tens.shape)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the mean, max, and min values of the canopy tensor</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mean = "</span>, torch.mean(canopy_tens))</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>canopy_max <span class="op">=</span> torch.<span class="bu">max</span>(canopy_tens)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>canopy_min <span class="op">=</span> torch.<span class="bu">min</span>(canopy_tens)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Max = "</span>, canopy_max)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Min = "</span>, canopy_min)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalizing the data</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>canopy_tens_norm <span class="op">=</span> (canopy_tens <span class="op">-</span> canopy_min) <span class="op">/</span> (canopy_max <span class="op">-</span> canopy_min)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mean = "</span>, torch.mean(canopy_tens_norm))</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Max = "</span>, torch.<span class="bu">max</span>(canopy_tens_norm))</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Min = "</span>, torch.<span class="bu">min</span>(canopy_tens_norm))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([10103, 101, 101])
Mean =  tensor(44.3548)
Max =  tensor(82.5000)
Min =  tensor(0.)
Mean =  tensor(0.5376)
Max =  tensor(1.)
Min =  tensor(0.)</code></pre>
</div>
</div>
<div id="cell-21" class="cell" data-execution_count="10">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">1</span>):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    plt.imshow(canopy_tens_norm[i].numpy())</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    plt.colorbar()</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-11-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="herbaceous-vegetation" class="level2">
<h2 class="anchored" data-anchor-id="herbaceous-vegetation">Herbaceous vegetation</h2>
<div id="cell-23" class="cell" data-execution_count="11">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Using rasterio</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> rasterio.<span class="bu">open</span>(herby_path) <span class="im">as</span> herby:</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Read all layers/channels into a single numpy array</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># rasterio indexes channels starting from 1, hence the range is 1 to src.count + 1</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    herby_stack <span class="op">=</span> herby.read([i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, herby.count <span class="op">+</span> <span class="dv">1</span>)])</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(herby_stack.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(10103, 101, 101)</code></pre>
</div>
</div>
<div id="cell-24" class="cell" data-outputid="cfa03e91-0a55-49b1-eccd-f1cc16377397" data-execution_count="12">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the numpy array to a PyTorch tensor, which is the format required for training the model</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>herby_tens <span class="op">=</span> torch.from_numpy(herby_stack)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(herby_tens.shape)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the mean, max, and min values of the herby tensor</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mean = "</span>, torch.mean(herby_tens))</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>herby_max <span class="op">=</span> torch.<span class="bu">max</span>(herby_tens)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>herby_min <span class="op">=</span> torch.<span class="bu">min</span>(herby_tens)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Max = "</span>, herby_max)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Min = "</span>, herby_min)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalizing the data</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>herby_tens_norm <span class="op">=</span> (herby_tens <span class="op">-</span> herby_min) <span class="op">/</span> (herby_max <span class="op">-</span> herby_min)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mean = "</span>, torch.mean(herby_tens_norm))</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Max = "</span>, torch.<span class="bu">max</span>(herby_tens_norm))</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Min = "</span>, torch.<span class="bu">min</span>(herby_tens_norm))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([10103, 101, 101])
Mean =  tensor(0.8069)
Max =  tensor(1.)
Min =  tensor(0.)
Mean =  tensor(0.8069)
Max =  tensor(1.)
Min =  tensor(0.)</code></pre>
</div>
</div>
<div id="cell-25" class="cell" data-outputid="e8079624-1b55-4135-cb41-10d5c4d60b52" data-execution_count="13">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">1</span>):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    plt.imshow(herby_tens_norm[i])</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    plt.colorbar()</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-14-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="slope" class="level2">
<h2 class="anchored" data-anchor-id="slope">Slope</h2>
<div id="cell-27" class="cell" data-outputid="37aa2a70-4ec9-4546-9b23-6a2796fc64c4" data-execution_count="14">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Using rasterio</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> rasterio.<span class="bu">open</span>(slope_path) <span class="im">as</span> slope:</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Read all layers/channels into a single numpy array</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># rasterio indexes channels starting from 1, hence the range is 1 to src.count + 1</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    slope_stack <span class="op">=</span> slope.read([i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, slope.count <span class="op">+</span> <span class="dv">1</span>)])</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(slope_stack.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(10103, 101, 101)</code></pre>
</div>
</div>
<div id="cell-28" class="cell" data-outputid="170f0b68-4f6e-4f55-f45f-fdd727bb423b" data-execution_count="15">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the numpy array to a PyTorch tensor, which is the format required for training the model</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>slope_tens <span class="op">=</span> torch.from_numpy(slope_stack)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(slope_tens.shape)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the mean, max, and min values of the slope tensor</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mean = "</span>, torch.mean(slope_tens))</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>slope_max <span class="op">=</span> torch.<span class="bu">max</span>(slope_tens)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>slope_min <span class="op">=</span> torch.<span class="bu">min</span>(slope_tens)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Max = "</span>, slope_max)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Min = "</span>, slope_min)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalizing the data</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>slope_tens_norm <span class="op">=</span> (slope_tens <span class="op">-</span> slope_min) <span class="op">/</span> (slope_max <span class="op">-</span> slope_min)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mean = "</span>, torch.mean(slope_tens_norm))</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Max = "</span>, torch.<span class="bu">max</span>(slope_tens_norm))</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Min = "</span>, torch.<span class="bu">min</span>(slope_tens_norm))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([10103, 101, 101])
Mean =  tensor(0.7779)
Max =  tensor(12.2981)
Min =  tensor(0.0006)
Mean =  tensor(0.0632)
Max =  tensor(1.)
Min =  tensor(0.)</code></pre>
</div>
</div>
<div id="cell-29" class="cell" data-outputid="cb8fdea7-608e-4ee5-d696-fffb76f80d2f" data-execution_count="16">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">1</span>):</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    plt.imshow(slope_tens_norm[i])</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    plt.colorbar()</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-17-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="presence-records---target-of-model" class="level2">
<h2 class="anchored" data-anchor-id="presence-records---target-of-model">Presence records - target of model</h2>
<p>This is what the model is trying to predict, which is the location of the next step.</p>
<div id="cell-31" class="cell" data-outputid="443f342c-17aa-4daf-a80f-3dcb9297b8e6" data-execution_count="17">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Using rasterio</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> rasterio.<span class="bu">open</span>(pres_path) <span class="im">as</span> pres:</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Read all layers/channels into a single numpy array</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># rasterio indexes channels starting from 1, hence the range is 1 to src.count + 1</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    pres_stack <span class="op">=</span> pres.read([i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, pres.count <span class="op">+</span> <span class="dv">1</span>)])</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pres_stack.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(10103, 101, 101)</code></pre>
</div>
</div>
<div id="cell-32" class="cell" data-outputid="bf12d794-9b6a-469c-bd1c-0b64cab69689" data-execution_count="18">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">1</span>):</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    plt.imshow(pres_stack[i])</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-19-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-33" class="cell" data-outputid="43d21005-6874-4372-c6a5-c8dbffb7067f" data-execution_count="19">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># train on the GPU or on the CPU, if a GPU is not available</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">'cuda'</span>) <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> torch.device(<span class="st">'cpu'</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss"> device"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Using cpu device</code></pre>
</div>
</div>
<section id="combine-the-spatial-layers-into-channels" class="level3">
<h3 class="anchored" data-anchor-id="combine-the-spatial-layers-into-channels">Combine the spatial layers into channels</h3>
<div id="cell-35" class="cell" data-outputid="a167a187-73f3-4c1a-9192-f96d81e27952">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Stack the channels along a new axis; here, 1 is commonly used for the channel axis in PyTorch</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>combined_stack <span class="op">=</span> torch.stack([ndvi_tens_norm, </span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>                              canopy_tens_norm, </span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>                              herby_tens_norm, </span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>                              slope_tens_norm], </span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>                              dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(combined_stack.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([10103, 4, 101, 101])</code></pre>
</div>
</div>
<p>From the size we can see that there are 10103 samples (steps), 4 channels (layers = covariates) and 101x101 pixels.</p>
</section>
</section>
<section id="defining-data-sets-and-data-loaders" class="level2">
<h2 class="anchored" data-anchor-id="defining-data-sets-and-data-loaders">Defining data sets and data loaders</h2>
<section id="creating-a-dataset-class" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-dataset-class">Creating a dataset class</h3>
<p>This custom PyTorch Dataset organizes all your input (spatial data, scalar covariates, bearing, and target) in a single object, allowing you to neatly manage how samples are accessed. The <code>__init__</code> method prepares and stores all the data, <code>__len__</code> returns the total number of samples, and <code>__getitem__</code> retrieves a single sample by indexâ€”enabling straightforward batching and iteration when used with a DataLoader.</p>
<p><img src="../figures/model_diagram_inputs.png" class="img-fluid"></p>
<div id="cell-38" class="cell">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> buffalo_data(Dataset):</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># data loading. Here we are just using the combined_stack as the spatial covariates</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.spatial_data_x <span class="op">=</span> combined_stack</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the scalar data that will be converted to spatial data and added as channels to the spatial covariates</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.scalar_to_grid_data <span class="op">=</span> torch.from_numpy(buffalo_df[[<span class="st">'hour_t2_sin'</span>, </span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>                                                                <span class="st">'hour_t2_cos'</span>, </span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>                                                                <span class="st">'yday_t2_sin'</span>, </span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>                                                                <span class="st">'yday_t2_cos'</span>]].values).<span class="bu">float</span>()</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the bearing data that will be added as a channel to the spatial covariates</span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bearing_x <span class="op">=</span> torch.from_numpy(buffalo_df[[<span class="st">'bearing_tm1'</span>]].values).<span class="bu">float</span>()</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the target data</span></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.target <span class="op">=</span> torch.tensor(pres_stack)</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># number of samples</span></span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_samples <span class="op">=</span> <span class="va">self</span>.spatial_data_x.shape[<span class="dv">0</span>]</span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># allows for the use of len() function</span></span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.n_samples</span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, index):</span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># allows for indexing of the dataset</span></span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.spatial_data_x[index], <span class="va">self</span>.scalar_to_grid_data[index], <span class="va">self</span>.bearing_x[index], <span class="va">self</span>.target[index]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Now we can create an instance of the dataset class and check that is working as expected.</p>
<div id="cell-40" class="cell" data-outputid="5cebb739-d592-4124-e18a-f20fb73eb74b" data-execution_count="22">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an instance of our custom buffalo_data Dataset:</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> buffalo_data()</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the total number of samples loaded (determined by n_samples in the dataset):</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(dataset.n_samples)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Retrieve *all* samples (using the slice dataset[:] invokes __getitem__ on all indices).</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="co"># This returns a tuple of (spatial data, scalar-to-grid data, bearing data, target labels).</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>features1, features2, features3, labels <span class="op">=</span> dataset[:]</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Examine the dimensions of each returned tensor for verification:</span></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Spatial data</span></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(features1.shape)</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Scalar-to-grid data</span></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(features2.shape)</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Bearing data</span></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(features3.shape)</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Target labels</span></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>10103
torch.Size([10103, 4, 101, 101])
torch.Size([10103, 4])
torch.Size([10103, 1])
torch.Size([10103, 101, 101])</code></pre>
</div>
</div>
</section>
<section id="split-into-training-validation-and-test-sets" class="level3">
<h3 class="anchored" data-anchor-id="split-into-training-validation-and-test-sets">Split into training, validation and test sets</h3>
<div id="cell-42" class="cell" data-outputid="a33c1f30-9389-4a5c-ca4c-5c072dc51027">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>training_split <span class="op">=</span> <span class="fl">0.8</span> <span class="co"># 80% of the data will be used for training</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>validation_split <span class="op">=</span> <span class="fl">0.1</span> <span class="co"># 10% of the data will be used for validation (deciding when to stop training)</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>test_split <span class="op">=</span> <span class="fl">0.1</span> <span class="co"># 10% of the data will be used for testing (model evaluation)</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>dataset_train, dataset_val, dataset_test <span class="op">=</span> torch.utils.data.random_split(dataset, [training_split, validation_split, test_split])</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of training samples: "</span>, <span class="bu">len</span>(dataset_train))</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of validatiom samples: "</span>, <span class="bu">len</span>(dataset_val))</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of testing samples: "</span>, <span class="bu">len</span>(dataset_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Number of training samples:  8083
Number of validatiom samples:  1010
Number of testing samples:  1010</code></pre>
</div>
</div>
</section>
<section id="create-dataloaders" class="level3">
<h3 class="anchored" data-anchor-id="create-dataloaders">Create dataloaders</h3>
<p>The DataLoader in PyTorch wraps an iterable around the Dataset to enable easy access to the samples.</p>
<div id="cell-44" class="cell" data-execution_count="24">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the batch size for how many samples to process at once in each step:</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>bs <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataLoader for the training dataset with a batch size of bs, and shuffle samples </span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="co"># so that the model doesn't see data in the same order each epoch.</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>dataloader_train <span class="op">=</span> DataLoader(dataset<span class="op">=</span>dataset_train, </span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>                              batch_size<span class="op">=</span>bs, </span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>                              shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataLoader for the validation dataset, also with a batch size of bs and shuffling.</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Even though it's not always mandatory to shuffle validation data, some users keep the same setting.</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>dataloader_val <span class="op">=</span> DataLoader(dataset<span class="op">=</span>dataset_val, </span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>                            batch_size<span class="op">=</span>bs, </span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>                            shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataLoader for the test dataset, likewise with a batch size of bs and shuffling.</span></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a><span class="co"># As we want to index the testing data for plotting, we will not shuffle the test data.</span></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>dataloader_test <span class="op">=</span> DataLoader(dataset<span class="op">=</span>dataset_test, </span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>                             batch_size<span class="op">=</span>bs, </span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>                             shuffle<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Check that the data loader is working as expected.</p>
<div id="cell-46" class="cell" data-outputid="68d361bd-daf4-4595-fa87-ac9f0e6c7e65" data-execution_count="25">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Display image and label.</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="co"># next(iter(dataloader_train)) returns the next batch of the training data</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>features1, features2, features3, labels <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(dataloader_train))</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Feature 1 batch shape: </span><span class="sc">{</span>features1<span class="sc">.</span>size()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Feature 2 batch shape: </span><span class="sc">{</span>features2<span class="sc">.</span>size()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Feature 3 batch shape: </span><span class="sc">{</span>features3<span class="sc">.</span>size()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Labels batch shape: </span><span class="sc">{</span>labels<span class="sc">.</span>size()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Feature 1 batch shape: torch.Size([32, 4, 101, 101])
Feature 2 batch shape: torch.Size([32, 4])
Feature 3 batch shape: torch.Size([32, 1])
Labels batch shape: torch.Size([32, 101, 101])</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="define-the-model" class="level1">
<h1>Define the model</h1>
<p>Deep learning can be considered as a sequence of <strong>blocks</strong>, each of which perform some (typically nonlinear) transformation on input data to produce some output. Providing each block has the appropriate inputs, they can be combined to build a larger network that is capable of achieving complex and abstract transformations and can be used to represent complex processes.</p>
<p>A block is modular component of a neural network, in our case defined as a Python class (type of object with certain functionality described by its definition) inheriting from <code>torch.nn.Module</code> in PyTorch. A block encapsulates a sequence of operations, including layers (such as fully connected layers or convolutional layers) and activation functions, to process input data. Each block has a forward method (i.e.&nbsp;instructions) that defines the data flow through the network during inference or training.</p>
<section id="convolutional-block-for-the-habitat-selection-subnetwork" class="level2">
<h2 class="anchored" data-anchor-id="convolutional-block-for-the-habitat-selection-subnetwork">Convolutional block for the habitat selection subnetwork</h2>
<p>This block is a convolutional layer that takes in the spatial covariates (including the layers created from the scalar values such as time), goes through a series of convolution operations amd ReLU activation functions and outputs a feature map, which is the habitat selection probability surface.</p>
<p><img src="../figures/model_diagram_hab.png" class="img-fluid" style="width:50.0%"></p>
<div id="cell-49" class="cell" data-execution_count="26">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Conv2d_block_spatial(nn.Module):</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, params):</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Conv2d_block_spatial, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># define the parameters</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_size <span class="op">=</span> params.batch_size</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_channels <span class="op">=</span> params.input_channels</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_channels <span class="op">=</span> params.output_channels</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.kernel_size <span class="op">=</span> params.kernel_size</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.stride <span class="op">=</span> params.stride</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.padding <span class="op">=</span> params.padding</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_dim <span class="op">=</span> params.image_dim</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.device <span class="op">=</span> params.device</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># define the layers - nn.Sequential allows for the definition of layers in a sequential manner</span></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2d <span class="op">=</span> nn.Sequential(</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># convolutional layer 1</span></span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>        nn.Conv2d(in_channels<span class="op">=</span><span class="va">self</span>.input_channels, out_channels<span class="op">=</span><span class="va">self</span>.output_channels, kernel_size<span class="op">=</span><span class="va">self</span>.kernel_size, stride<span class="op">=</span><span class="va">self</span>.stride, padding<span class="op">=</span><span class="va">self</span>.padding),</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ReLU activation function</span></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>        nn.ReLU(),</span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># convolutional layer 2</span></span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>        nn.Conv2d(in_channels<span class="op">=</span><span class="va">self</span>.output_channels, out_channels<span class="op">=</span><span class="va">self</span>.output_channels, kernel_size<span class="op">=</span><span class="va">self</span>.kernel_size, stride<span class="op">=</span><span class="va">self</span>.stride, padding<span class="op">=</span><span class="va">self</span>.padding),</span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ReLU activation function</span></span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a>        nn.ReLU(),</span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># convolutional layer 3, which outputs a single layer, which is the habitat selection map</span></span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a>        nn.Conv2d(in_channels<span class="op">=</span><span class="va">self</span>.output_channels, out_channels<span class="op">=</span><span class="dv">1</span>, kernel_size<span class="op">=</span><span class="va">self</span>.kernel_size, stride<span class="op">=</span><span class="va">self</span>.stride, padding<span class="op">=</span><span class="va">self</span>.padding)</span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-29"><a href="#cb42-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># define the forward pass of the model, i.e. how the data flows through the model</span></span>
<span id="cb42-30"><a href="#cb42-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb42-31"><a href="#cb42-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-32"><a href="#cb42-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># self.conv2d(x) passes the input through the convolutional layers, and the squeeze function removes the channel dimension, resulting in a 2D tensor (habitat selection map)</span></span>
<span id="cb42-33"><a href="#cb42-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print("Shape before squeeze:", self.conv2d(x).shape) # Debugging print</span></span>
<span id="cb42-34"><a href="#cb42-34" aria-hidden="true" tabindex="-1"></a>        conv2d_spatial <span class="op">=</span> <span class="va">self</span>.conv2d(x).squeeze(dim <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb42-35"><a href="#cb42-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb42-36"><a href="#cb42-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># normalise to sum to 1</span></span>
<span id="cb42-37"><a href="#cb42-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print("Shape before logsumexp:", conv2d_spatial.shape) # Debugging print</span></span>
<span id="cb42-38"><a href="#cb42-38" aria-hidden="true" tabindex="-1"></a>        conv2d_spatial <span class="op">=</span> conv2d_spatial <span class="op">-</span> torch.logsumexp(conv2d_spatial, dim <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>), keepdim <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb42-39"><a href="#cb42-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-40"><a href="#cb42-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># output the habitat selection map</span></span>
<span id="cb42-41"><a href="#cb42-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> conv2d_spatial</span>
<span id="cb42-42"><a href="#cb42-42" aria-hidden="true" tabindex="-1"></a>    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="convolutional-block-for-the-movement-subnetwork" class="level2">
<h2 class="anchored" data-anchor-id="convolutional-block-for-the-movement-subnetwork">Convolutional block for the movement subnetwork</h2>
<p>This block is also convolutional layer, with the same inputs, but this block also has max pooling layers to reduce the spatial resolution of the feature maps whilst preserving the most prominent features in the feature maps, and outputs a â€˜flattenedâ€™ feature map. A flattened feature map is a 1D tensor (a vector) that can be used as input to a fully connected layer.</p>
<p><img src="../figures/model_diagram_move.png" class="img-fluid"></p>
<div id="cell-51" class="cell" data-execution_count="27">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Conv2d_block_toFC(nn.Module):</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, params):</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Conv2d_block_toFC, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># define the parameters</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_size <span class="op">=</span> params.batch_size</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_channels <span class="op">=</span> params.input_channels</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_channels <span class="op">=</span> params.output_channels</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.kernel_size <span class="op">=</span> params.kernel_size</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.stride <span class="op">=</span> params.stride</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.kernel_size_mp <span class="op">=</span> params.kernel_size_mp</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.stride_mp <span class="op">=</span> params.stride_mp</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.padding <span class="op">=</span> params.padding</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_dim <span class="op">=</span> params.image_dim</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.device <span class="op">=</span> params.device</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># define the layers - nn.Sequential allows for the definition of layers in a sequential manner</span></span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2d <span class="op">=</span> nn.Sequential(</span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># convolutional layer 1</span></span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>        nn.Conv2d(in_channels<span class="op">=</span><span class="va">self</span>.input_channels, out_channels<span class="op">=</span><span class="va">self</span>.output_channels, kernel_size<span class="op">=</span><span class="va">self</span>.kernel_size, stride<span class="op">=</span><span class="va">self</span>.stride, padding<span class="op">=</span><span class="va">self</span>.padding),</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ReLU activation function</span></span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>        nn.ReLU(),</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># max pooling layer 1 (reduces the spatial dimensions of the data whilst retaining the most important features)</span></span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>        nn.MaxPool2d(kernel_size<span class="op">=</span><span class="va">self</span>.kernel_size_mp, stride<span class="op">=</span><span class="va">self</span>.stride_mp),</span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># convolutional layer 2</span></span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>        nn.Conv2d(in_channels<span class="op">=</span><span class="va">self</span>.output_channels, out_channels<span class="op">=</span><span class="va">self</span>.output_channels, kernel_size<span class="op">=</span><span class="va">self</span>.kernel_size, stride<span class="op">=</span><span class="va">self</span>.stride, padding<span class="op">=</span><span class="va">self</span>.padding),</span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ReLU activation function</span></span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a>        nn.ReLU(),</span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># max pooling layer 2</span></span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a>        nn.MaxPool2d(kernel_size<span class="op">=</span><span class="va">self</span>.kernel_size_mp, stride<span class="op">=</span><span class="va">self</span>.stride_mp),</span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># flatten the data to pass through the fully connected layer</span></span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a>        nn.Flatten())</span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># self.conv2d(x) passes the input through the convolutional layers, and outputs a 1D tensor</span></span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.conv2d(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="fully-connected-block-for-the-movement-subnetwork" class="level2">
<h2 class="anchored" data-anchor-id="fully-connected-block-for-the-movement-subnetwork">Fully connected block for the movement subnetwork</h2>
<p>This block takes in the flattened feature map from the previous block, passes through several fully connected layers, which extracts information from the spatial covariates that is relevant for movement, and outputs the parameters that define the movement kernel.</p>
<div id="cell-53" class="cell" data-execution_count="28">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FCN_block_all_movement(nn.Module):</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, params):</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(FCN_block_all_movement, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># define the parameters</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_size <span class="op">=</span> params.batch_size</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dense_dim_in_all <span class="op">=</span> params.dense_dim_in_all</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dense_dim_hidden <span class="op">=</span> params.dense_dim_hidden</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dense_dim_out <span class="op">=</span> params.dense_dim_out</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_dim <span class="op">=</span> params.image_dim</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.device <span class="op">=</span> params.device</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_movement_params <span class="op">=</span> params.num_movement_params</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> params.dropout</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># define the layers - nn.Sequential allows for the definition of layers in a sequential manner</span></span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ffn <span class="op">=</span> nn.Sequential(</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>            <span class="co"># fully connected layer 1 (the dense_dim_in_all is the number of input features, </span></span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>            <span class="co"># and should match the output of the Conv2d_block_toFC block).</span></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a>            <span class="co"># the dense_dim_hidden is the number of neurons in the hidden layer, and doesn't need to be the same as the input features</span></span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.dense_dim_in_all, <span class="va">self</span>.dense_dim_hidden),</span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a>            <span class="co"># dropout layer (helps to reduce overfitting)</span></span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="va">self</span>.dropout),</span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ReLU activation function</span></span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a>            <span class="co"># fully connected layer 2</span></span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a>            <span class="co"># the number of input neurons should match the output from the previous layer</span></span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.dense_dim_hidden, <span class="va">self</span>.dense_dim_hidden),</span>
<span id="cb44-28"><a href="#cb44-28" aria-hidden="true" tabindex="-1"></a>            <span class="co"># dropout layer</span></span>
<span id="cb44-29"><a href="#cb44-29" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="va">self</span>.dropout),</span>
<span id="cb44-30"><a href="#cb44-30" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ReLU activation function</span></span>
<span id="cb44-31"><a href="#cb44-31" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb44-32"><a href="#cb44-32" aria-hidden="true" tabindex="-1"></a>            <span class="co"># fully connected layer 3</span></span>
<span id="cb44-33"><a href="#cb44-33" aria-hidden="true" tabindex="-1"></a>            <span class="co"># the number of input neurons should match the output from the previous layer, </span></span>
<span id="cb44-34"><a href="#cb44-34" aria-hidden="true" tabindex="-1"></a>            <span class="co"># and the number of output neurons should match the number of movement parameters</span></span>
<span id="cb44-35"><a href="#cb44-35" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.dense_dim_hidden, <span class="va">self</span>.num_movement_params)</span>
<span id="cb44-36"><a href="#cb44-36" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb44-37"><a href="#cb44-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-38"><a href="#cb44-38" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb44-39"><a href="#cb44-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-40"><a href="#cb44-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># self.ffn(x) passes the input through the fully connected layers, and outputs a 1D tensor (vector of movement parameters)</span></span>
<span id="cb44-41"><a href="#cb44-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.ffn(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="block-to-convert-the-movement-parameters-to-a-probability-distribution" class="level2">
<h2 class="anchored" data-anchor-id="block-to-convert-the-movement-parameters-to-a-probability-distribution">Block to convert the movement parameters to a probability distribution</h2>
<section id="what-the-block-does" class="level3">
<h3 class="anchored" data-anchor-id="what-the-block-does">What the block does</h3>
<p>This block is a bit longer and more involved, but there are no parameters in here that need to be learned (estimated). It is just a series of operations that are applied to the movement parameters to convert them to a probability distribution.</p>
<p>This block takes in the movement parameters and converts them to a probability distribution. This essentially just applies the appropriate density functions using the parameter values predicted by the movement blocks, which in our case is a finite mixture of Gamma distributions nad a finite mixture of von Mises distributions.</p>
<p>The formulation of predicting parameters and converting them to a movement kernel ensures that the movement kernel is very flexible, and can be any combination of distributions, which need not all be the same (e.g., a step length distribution may be combination of a Gamma and a log-normal distribution).</p>
</section>
<section id="constraints" class="level3">
<h3 class="anchored" data-anchor-id="constraints">Constraints</h3>
<p>One constraint to ensure that we can perform backpropagation is that the entire forward pass, including the block below that produces the density functions, must be differentiable with respect to the parameters of the model. PyTorchâ€™s torch.distributions module and its special functions (e.g., torch.special) provide differentiable implementations for many common distributions. Examples are the</p>
<ul>
<li>Gamma function for the (log) Gamma distribution, <code>torch.lgamma()</code></li>
<li>The modified Bessel function of the first kind of order 0 for the von Mises distribution, <code>torch.special.i0()</code></li>
</ul>
<p>Some of the movement parameters, such as the shape and scale of the Gamma distribution, must be positive. We therefore exponentiate them in this block to ensure that they are positive. This means that the model is actually learning the log of the shape and scale parameters. For the von Mises <code>mu</code> parameters however, they can be any value, so we do not need to exponentiate them. We could constrain them to be between -pi and pi, but this is not necessary as the von Mises distribution is periodic, so any value will be equivalent to another value that is within the range -pi to pi.</p>
</section>
<section id="notes" class="level3">
<h3 class="anchored" data-anchor-id="notes">Notes</h3>
<p>To help with identifiability, it is possible to fix certain parameter values, such as the mu parameters in the mixture of von Mises distributions to pi and -pi for instance (one would then reduce the number of predicted parameters by the previous block, as these no longer need to be predicted).</p>
<p>We can also transform certain parameters such that they are being estimated in a similar range (analagous to standardising variables in linear regression). In our case we know that the scale parameter of one of the Gamma distributions is around 500. What we can then do after exponentiating is multiply the scale parameter by 500, so the model is learning the log of the scale parameter divided by 500. This will ensure that this parameter is in a similar range to the other parameters, and can help with convergence. To do this we:</p>
<p>Pull out the relevant parameters from the input tensor (output of previous block) - <code>gamma_scale2 = torch.exp(x[:, 4]).unsqueeze(0).unsqueeze(0)</code></p>
<p>Multiply the scale parameter by 500, so the model is learning the log of the scale parameter divided by 500 - <code>gamma_scale2 = gamma_scale2 * 500</code></p>
<div id="cell-55" class="cell">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Params_to_Grid_Block(nn.Module):</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, params):</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Params_to_Grid_Block, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># define the parameters</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_size <span class="op">=</span> params.batch_size</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_dim <span class="op">=</span> params.image_dim</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pixel_size <span class="op">=</span> params.pixel_size</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># create distance and bearing layers</span></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># determine the distance of each pixel from the centre of the image</span></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.center <span class="op">=</span> <span class="va">self</span>.image_dim <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>        y, x <span class="op">=</span> np.indices((<span class="va">self</span>.image_dim, <span class="va">self</span>.image_dim))</span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.distance_layer <span class="op">=</span> torch.from_numpy(np.sqrt((<span class="va">self</span>.pixel_size<span class="op">*</span>(x <span class="op">-</span> <span class="va">self</span>.center))<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> </span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>                                                       (<span class="va">self</span>.pixel_size<span class="op">*</span>(y <span class="op">-</span> <span class="va">self</span>.center))<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># change the centre cell to the average distance from the centre to the edge of the pixel</span></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.distance_layer[<span class="va">self</span>.center, <span class="va">self</span>.center] <span class="op">=</span> <span class="fl">0.56</span><span class="op">*</span><span class="va">self</span>.pixel_size <span class="co"># average distance from the centre to the perimeter of the pixel (accounting for longer distances at the corners)</span></span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># determine the bearing of each pixel from the centre of the image</span></span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bearing_layer <span class="op">=</span> torch.from_numpy(np.arctan2(<span class="va">self</span>.center <span class="op">-</span> y, </span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a>                                                         x <span class="op">-</span> <span class="va">self</span>.center))</span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.device <span class="op">=</span> params.device</span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-25"><a href="#cb45-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Gamma densities (on the log-scale) for the mixture distribution</span></span>
<span id="cb45-26"><a href="#cb45-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> gamma_density(<span class="va">self</span>, x, shape, scale):</span>
<span id="cb45-27"><a href="#cb45-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Ensure all tensors are on the same device as x</span></span>
<span id="cb45-28"><a href="#cb45-28" aria-hidden="true" tabindex="-1"></a>        shape <span class="op">=</span> shape.to(x.device)</span>
<span id="cb45-29"><a href="#cb45-29" aria-hidden="true" tabindex="-1"></a>        scale <span class="op">=</span> scale.to(x.device)</span>
<span id="cb45-30"><a href="#cb45-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="op">-</span><span class="dv">1</span><span class="op">*</span>torch.lgamma(shape) <span class="op">-</span>shape<span class="op">*</span>torch.log(scale) <span class="op">+</span> (shape <span class="op">-</span> <span class="dv">1</span>)<span class="op">*</span>torch.log(x) <span class="op">-</span> x<span class="op">/</span>scale</span>
<span id="cb45-31"><a href="#cb45-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-32"><a href="#cb45-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># log von Mises densities (on the log-scale) for the mixture distribution</span></span>
<span id="cb45-33"><a href="#cb45-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> vonmises_density(<span class="va">self</span>, x, kappa, vm_mu):</span>
<span id="cb45-34"><a href="#cb45-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Ensure all tensors are on the same device as x</span></span>
<span id="cb45-35"><a href="#cb45-35" aria-hidden="true" tabindex="-1"></a>        kappa <span class="op">=</span> kappa.to(x.device)</span>
<span id="cb45-36"><a href="#cb45-36" aria-hidden="true" tabindex="-1"></a>        vm_mu <span class="op">=</span> vm_mu.to(x.device)</span>
<span id="cb45-37"><a href="#cb45-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> kappa<span class="op">*</span>torch.cos(x <span class="op">-</span> vm_mu) <span class="op">-</span> <span class="dv">1</span><span class="op">*</span>(np.log(<span class="dv">2</span><span class="op">*</span>torch.pi) <span class="op">+</span> torch.log(torch.special.i0(kappa)))</span>
<span id="cb45-38"><a href="#cb45-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-39"><a href="#cb45-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-40"><a href="#cb45-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, bearing):</span>
<span id="cb45-41"><a href="#cb45-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-42"><a href="#cb45-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># parameters of the first mixture distribution</span></span>
<span id="cb45-43"><a href="#cb45-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># x are the outputs from the fully connected layers (vector of movement parameters)</span></span>
<span id="cb45-44"><a href="#cb45-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># we therefore need to extract the appropriate parameters </span></span>
<span id="cb45-45"><a href="#cb45-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the locations are not specific to any specific parameters, as long as any aren't extracted more than once </span></span>
<span id="cb45-46"><a href="#cb45-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-47"><a href="#cb45-47" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Gamma distributions</span></span>
<span id="cb45-48"><a href="#cb45-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-49"><a href="#cb45-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># pull out the parameters of the first gamma distribution and exponentiate them to ensure they are positive</span></span>
<span id="cb45-50"><a href="#cb45-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the unsqueeze function adds a new dimension to the tensor</span></span>
<span id="cb45-51"><a href="#cb45-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># we do this twice to match the dimensions of the distance_layer, </span></span>
<span id="cb45-52"><a href="#cb45-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># and then repeat the parameter value across a grid, such that the density can be calculated at every cell/pixel</span></span>
<span id="cb45-53"><a href="#cb45-53" aria-hidden="true" tabindex="-1"></a>        gamma_shape1 <span class="op">=</span> torch.exp(x[:, <span class="dv">0</span>]).unsqueeze(<span class="dv">0</span>).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb45-54"><a href="#cb45-54" aria-hidden="true" tabindex="-1"></a>        gamma_shape1 <span class="op">=</span> gamma_shape1.repeat(<span class="va">self</span>.image_dim, <span class="va">self</span>.image_dim, <span class="dv">1</span>)</span>
<span id="cb45-55"><a href="#cb45-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># this just changes the order of the dimensions to match the distance_layer</span></span>
<span id="cb45-56"><a href="#cb45-56" aria-hidden="true" tabindex="-1"></a>        gamma_shape1 <span class="op">=</span> gamma_shape1.permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb45-57"><a href="#cb45-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-58"><a href="#cb45-58" aria-hidden="true" tabindex="-1"></a>        gamma_scale1 <span class="op">=</span> torch.exp(x[:, <span class="dv">1</span>]).unsqueeze(<span class="dv">0</span>).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb45-59"><a href="#cb45-59" aria-hidden="true" tabindex="-1"></a>        gamma_scale1 <span class="op">=</span> gamma_scale1.repeat(<span class="va">self</span>.image_dim, <span class="va">self</span>.image_dim, <span class="dv">1</span>)</span>
<span id="cb45-60"><a href="#cb45-60" aria-hidden="true" tabindex="-1"></a>        gamma_scale1 <span class="op">=</span> gamma_scale1.permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb45-61"><a href="#cb45-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-62"><a href="#cb45-62" aria-hidden="true" tabindex="-1"></a>        gamma_weight1 <span class="op">=</span> torch.exp(x[:, <span class="dv">2</span>]).unsqueeze(<span class="dv">0</span>).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb45-63"><a href="#cb45-63" aria-hidden="true" tabindex="-1"></a>        gamma_weight1 <span class="op">=</span> gamma_weight1.repeat(<span class="va">self</span>.image_dim, <span class="va">self</span>.image_dim, <span class="dv">1</span>)</span>
<span id="cb45-64"><a href="#cb45-64" aria-hidden="true" tabindex="-1"></a>        gamma_weight1 <span class="op">=</span> gamma_weight1.permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb45-65"><a href="#cb45-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-66"><a href="#cb45-66" aria-hidden="true" tabindex="-1"></a>        <span class="co"># parameters of the second mixture distribution</span></span>
<span id="cb45-67"><a href="#cb45-67" aria-hidden="true" tabindex="-1"></a>        gamma_shape2 <span class="op">=</span> torch.exp(x[:, <span class="dv">3</span>]).unsqueeze(<span class="dv">0</span>).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb45-68"><a href="#cb45-68" aria-hidden="true" tabindex="-1"></a>        gamma_shape2 <span class="op">=</span> gamma_shape2.repeat(<span class="va">self</span>.image_dim, <span class="va">self</span>.image_dim, <span class="dv">1</span>)</span>
<span id="cb45-69"><a href="#cb45-69" aria-hidden="true" tabindex="-1"></a>        gamma_shape2 <span class="op">=</span> gamma_shape2.permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb45-70"><a href="#cb45-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-71"><a href="#cb45-71" aria-hidden="true" tabindex="-1"></a>        gamma_scale2 <span class="op">=</span> torch.exp(x[:, <span class="dv">4</span>]).unsqueeze(<span class="dv">0</span>).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb45-72"><a href="#cb45-72" aria-hidden="true" tabindex="-1"></a>        gamma_scale2 <span class="op">=</span> gamma_scale2 <span class="op">*</span> <span class="dv">500</span> <span class="co">### transform the scale parameter so it can be estimated near the same range as the other parameters</span></span>
<span id="cb45-73"><a href="#cb45-73" aria-hidden="true" tabindex="-1"></a>        gamma_scale2 <span class="op">=</span> gamma_scale2.repeat(<span class="va">self</span>.image_dim, <span class="va">self</span>.image_dim, <span class="dv">1</span>)</span>
<span id="cb45-74"><a href="#cb45-74" aria-hidden="true" tabindex="-1"></a>        gamma_scale2 <span class="op">=</span> gamma_scale2.permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb45-75"><a href="#cb45-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-76"><a href="#cb45-76" aria-hidden="true" tabindex="-1"></a>        gamma_weight2 <span class="op">=</span> torch.exp(x[:, <span class="dv">5</span>]).unsqueeze(<span class="dv">0</span>).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb45-77"><a href="#cb45-77" aria-hidden="true" tabindex="-1"></a>        gamma_weight2 <span class="op">=</span> gamma_weight2.repeat(<span class="va">self</span>.image_dim, <span class="va">self</span>.image_dim, <span class="dv">1</span>)</span>
<span id="cb45-78"><a href="#cb45-78" aria-hidden="true" tabindex="-1"></a>        gamma_weight2 <span class="op">=</span> gamma_weight2.permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb45-79"><a href="#cb45-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-80"><a href="#cb45-80" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply softmax to the mixture weights to ensure they sum to 1</span></span>
<span id="cb45-81"><a href="#cb45-81" aria-hidden="true" tabindex="-1"></a>        gamma_weights <span class="op">=</span> torch.stack([gamma_weight1, gamma_weight2], dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb45-82"><a href="#cb45-82" aria-hidden="true" tabindex="-1"></a>        gamma_weights <span class="op">=</span> torch.nn.functional.softmax(gamma_weights, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb45-83"><a href="#cb45-83" aria-hidden="true" tabindex="-1"></a>        gamma_weight1 <span class="op">=</span> gamma_weights[<span class="dv">0</span>]</span>
<span id="cb45-84"><a href="#cb45-84" aria-hidden="true" tabindex="-1"></a>        gamma_weight2 <span class="op">=</span> gamma_weights[<span class="dv">1</span>]</span>
<span id="cb45-85"><a href="#cb45-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-86"><a href="#cb45-86" aria-hidden="true" tabindex="-1"></a>        <span class="co"># calculation of Gamma densities</span></span>
<span id="cb45-87"><a href="#cb45-87" aria-hidden="true" tabindex="-1"></a>        gamma_density_layer1 <span class="op">=</span> <span class="va">self</span>.gamma_density(<span class="va">self</span>.distance_layer, </span>
<span id="cb45-88"><a href="#cb45-88" aria-hidden="true" tabindex="-1"></a>                                                  gamma_shape1, </span>
<span id="cb45-89"><a href="#cb45-89" aria-hidden="true" tabindex="-1"></a>                                                  gamma_scale1).to(device)</span>
<span id="cb45-90"><a href="#cb45-90" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb45-91"><a href="#cb45-91" aria-hidden="true" tabindex="-1"></a>        gamma_density_layer2 <span class="op">=</span> <span class="va">self</span>.gamma_density(<span class="va">self</span>.distance_layer, </span>
<span id="cb45-92"><a href="#cb45-92" aria-hidden="true" tabindex="-1"></a>                                                  gamma_shape2, </span>
<span id="cb45-93"><a href="#cb45-93" aria-hidden="true" tabindex="-1"></a>                                                  gamma_scale2).to(device)</span>
<span id="cb45-94"><a href="#cb45-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-95"><a href="#cb45-95" aria-hidden="true" tabindex="-1"></a>        <span class="co"># combining both densities to create a mixture distribution using logsumexp</span></span>
<span id="cb45-96"><a href="#cb45-96" aria-hidden="true" tabindex="-1"></a>        logsumexp_gamma_corr <span class="op">=</span> torch.<span class="bu">max</span>(gamma_density_layer1, gamma_density_layer2)</span>
<span id="cb45-97"><a href="#cb45-97" aria-hidden="true" tabindex="-1"></a>        gamma_density_layer <span class="op">=</span> logsumexp_gamma_corr <span class="op">+</span> torch.log(gamma_weight1 <span class="op">*</span> torch.exp(gamma_density_layer1 <span class="op">-</span> logsumexp_gamma_corr) <span class="op">+</span> gamma_weight2 <span class="op">*</span> torch.exp(gamma_density_layer2 <span class="op">-</span> logsumexp_gamma_corr))</span>
<span id="cb45-98"><a href="#cb45-98" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(torch.sum(gamma_density_layer))</span></span>
<span id="cb45-99"><a href="#cb45-99" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(torch.sum(torch.exp(gamma_density_layer)))</span></span>
<span id="cb45-100"><a href="#cb45-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-101"><a href="#cb45-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-102"><a href="#cb45-102" aria-hidden="true" tabindex="-1"></a>        <span class="co">## Von Mises Distributions</span></span>
<span id="cb45-103"><a href="#cb45-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-104"><a href="#cb45-104" aria-hidden="true" tabindex="-1"></a>        <span class="co"># calculate the new bearing from the turning angle</span></span>
<span id="cb45-105"><a href="#cb45-105" aria-hidden="true" tabindex="-1"></a>        <span class="co"># takes in the bearing from the previous step and adds the turning angle, which is estimated by the model</span></span>
<span id="cb45-106"><a href="#cb45-106" aria-hidden="true" tabindex="-1"></a>        <span class="co"># we do not exponentiate the von Mises mu parameters as we want to allow them to be negative</span></span>
<span id="cb45-107"><a href="#cb45-107" aria-hidden="true" tabindex="-1"></a>        bearing_new1 <span class="op">=</span> x[:, <span class="dv">6</span>] <span class="op">+</span> bearing[:, <span class="dv">0</span>]</span>
<span id="cb45-108"><a href="#cb45-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-109"><a href="#cb45-109" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the new bearing becomes the mean of the von Mises distribution</span></span>
<span id="cb45-110"><a href="#cb45-110" aria-hidden="true" tabindex="-1"></a>        vonmises_mu1 <span class="op">=</span> bearing_new1.unsqueeze(<span class="dv">0</span>).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb45-111"><a href="#cb45-111" aria-hidden="true" tabindex="-1"></a>        vonmises_mu1 <span class="op">=</span> vonmises_mu1.repeat(<span class="va">self</span>.image_dim, <span class="va">self</span>.image_dim, <span class="dv">1</span>)</span>
<span id="cb45-112"><a href="#cb45-112" aria-hidden="true" tabindex="-1"></a>        vonmises_mu1 <span class="op">=</span> vonmises_mu1.permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb45-113"><a href="#cb45-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-114"><a href="#cb45-114" aria-hidden="true" tabindex="-1"></a>        <span class="co"># parameters of the first von Mises distribution</span></span>
<span id="cb45-115"><a href="#cb45-115" aria-hidden="true" tabindex="-1"></a>        vonmises_kappa1 <span class="op">=</span> torch.exp(x[:, <span class="dv">7</span>]).unsqueeze(<span class="dv">0</span>).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb45-116"><a href="#cb45-116" aria-hidden="true" tabindex="-1"></a>        vonmises_kappa1 <span class="op">=</span> vonmises_kappa1.repeat(<span class="va">self</span>.image_dim, <span class="va">self</span>.image_dim, <span class="dv">1</span>)</span>
<span id="cb45-117"><a href="#cb45-117" aria-hidden="true" tabindex="-1"></a>        vonmises_kappa1 <span class="op">=</span> vonmises_kappa1.permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb45-118"><a href="#cb45-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-119"><a href="#cb45-119" aria-hidden="true" tabindex="-1"></a>        vonmises_weight1 <span class="op">=</span> torch.exp(x[:, <span class="dv">8</span>]).unsqueeze(<span class="dv">0</span>).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb45-120"><a href="#cb45-120" aria-hidden="true" tabindex="-1"></a>        vonmises_weight1 <span class="op">=</span> vonmises_weight1.repeat(<span class="va">self</span>.image_dim, <span class="va">self</span>.image_dim, <span class="dv">1</span>)</span>
<span id="cb45-121"><a href="#cb45-121" aria-hidden="true" tabindex="-1"></a>        vonmises_weight1 <span class="op">=</span> vonmises_weight1.permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb45-122"><a href="#cb45-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-123"><a href="#cb45-123" aria-hidden="true" tabindex="-1"></a>        <span class="co"># vm_mu and weight for the second von Mises distribution</span></span>
<span id="cb45-124"><a href="#cb45-124" aria-hidden="true" tabindex="-1"></a>        bearing_new2 <span class="op">=</span> x[:, <span class="dv">9</span>] <span class="op">+</span> bearing[:, <span class="dv">0</span>]</span>
<span id="cb45-125"><a href="#cb45-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-126"><a href="#cb45-126" aria-hidden="true" tabindex="-1"></a>        vonmises_mu2 <span class="op">=</span> bearing_new2.unsqueeze(<span class="dv">0</span>).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb45-127"><a href="#cb45-127" aria-hidden="true" tabindex="-1"></a>        vonmises_mu2 <span class="op">=</span> vonmises_mu2.repeat(<span class="va">self</span>.image_dim, <span class="va">self</span>.image_dim, <span class="dv">1</span>)</span>
<span id="cb45-128"><a href="#cb45-128" aria-hidden="true" tabindex="-1"></a>        vonmises_mu2 <span class="op">=</span> vonmises_mu2.permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb45-129"><a href="#cb45-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-130"><a href="#cb45-130" aria-hidden="true" tabindex="-1"></a>        <span class="co"># parameters of the second von Mises distribution</span></span>
<span id="cb45-131"><a href="#cb45-131" aria-hidden="true" tabindex="-1"></a>        vonmises_kappa2 <span class="op">=</span> torch.exp(x[:, <span class="dv">10</span>]).unsqueeze(<span class="dv">0</span>).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb45-132"><a href="#cb45-132" aria-hidden="true" tabindex="-1"></a>        vonmises_kappa2 <span class="op">=</span> vonmises_kappa2.repeat(<span class="va">self</span>.image_dim, <span class="va">self</span>.image_dim, <span class="dv">1</span>)</span>
<span id="cb45-133"><a href="#cb45-133" aria-hidden="true" tabindex="-1"></a>        vonmises_kappa2 <span class="op">=</span> vonmises_kappa2.permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb45-134"><a href="#cb45-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-135"><a href="#cb45-135" aria-hidden="true" tabindex="-1"></a>        vonmises_weight2 <span class="op">=</span> torch.exp(x[:, <span class="dv">11</span>]).unsqueeze(<span class="dv">0</span>).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb45-136"><a href="#cb45-136" aria-hidden="true" tabindex="-1"></a>        vonmises_weight2 <span class="op">=</span> vonmises_weight2.repeat(<span class="va">self</span>.image_dim, <span class="va">self</span>.image_dim, <span class="dv">1</span>)</span>
<span id="cb45-137"><a href="#cb45-137" aria-hidden="true" tabindex="-1"></a>        vonmises_weight2 <span class="op">=</span> vonmises_weight2.permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb45-138"><a href="#cb45-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-139"><a href="#cb45-139" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply softmax to the weights</span></span>
<span id="cb45-140"><a href="#cb45-140" aria-hidden="true" tabindex="-1"></a>        vonmises_weights <span class="op">=</span> torch.stack([vonmises_weight1, vonmises_weight2], dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb45-141"><a href="#cb45-141" aria-hidden="true" tabindex="-1"></a>        vonmises_weights <span class="op">=</span> torch.nn.functional.softmax(vonmises_weights, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb45-142"><a href="#cb45-142" aria-hidden="true" tabindex="-1"></a>        vonmises_weight1 <span class="op">=</span> vonmises_weights[<span class="dv">0</span>]</span>
<span id="cb45-143"><a href="#cb45-143" aria-hidden="true" tabindex="-1"></a>        vonmises_weight2 <span class="op">=</span> vonmises_weights[<span class="dv">1</span>]</span>
<span id="cb45-144"><a href="#cb45-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-145"><a href="#cb45-145" aria-hidden="true" tabindex="-1"></a>        <span class="co"># calculation of von Mises densities</span></span>
<span id="cb45-146"><a href="#cb45-146" aria-hidden="true" tabindex="-1"></a>        vonmises_density_layer1 <span class="op">=</span> <span class="va">self</span>.vonmises_density(<span class="va">self</span>.bearing_layer, </span>
<span id="cb45-147"><a href="#cb45-147" aria-hidden="true" tabindex="-1"></a>                                                        vonmises_kappa1, </span>
<span id="cb45-148"><a href="#cb45-148" aria-hidden="true" tabindex="-1"></a>                                                        vonmises_mu1).to(device)</span>
<span id="cb45-149"><a href="#cb45-149" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb45-150"><a href="#cb45-150" aria-hidden="true" tabindex="-1"></a>        vonmises_density_layer2 <span class="op">=</span> <span class="va">self</span>.vonmises_density(<span class="va">self</span>.bearing_layer, </span>
<span id="cb45-151"><a href="#cb45-151" aria-hidden="true" tabindex="-1"></a>                                                        vonmises_kappa2, </span>
<span id="cb45-152"><a href="#cb45-152" aria-hidden="true" tabindex="-1"></a>                                                        vonmises_mu2).to(device)</span>
<span id="cb45-153"><a href="#cb45-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-154"><a href="#cb45-154" aria-hidden="true" tabindex="-1"></a>        <span class="co"># combining both densities to create a mixture distribution using the logsumexp trick</span></span>
<span id="cb45-155"><a href="#cb45-155" aria-hidden="true" tabindex="-1"></a>        logsumexp_vm_corr <span class="op">=</span> torch.<span class="bu">max</span>(vonmises_density_layer1, vonmises_density_layer2)</span>
<span id="cb45-156"><a href="#cb45-156" aria-hidden="true" tabindex="-1"></a>        vonmises_density_layer <span class="op">=</span> logsumexp_vm_corr <span class="op">+</span> torch.log(vonmises_weight1 <span class="op">*</span> torch.exp(vonmises_density_layer1 <span class="op">-</span> logsumexp_vm_corr) <span class="op">+</span> vonmises_weight2 <span class="op">*</span> torch.exp(vonmises_density_layer2 <span class="op">-</span> logsumexp_vm_corr))</span>
<span id="cb45-157"><a href="#cb45-157" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(torch.sum(vonmises_density_layer))</span></span>
<span id="cb45-158"><a href="#cb45-158" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(torch.sum(torch.exp(vonmises_density_layer)))</span></span>
<span id="cb45-159"><a href="#cb45-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-160"><a href="#cb45-160" aria-hidden="true" tabindex="-1"></a>        <span class="co"># combining the two distributions</span></span>
<span id="cb45-161"><a href="#cb45-161" aria-hidden="true" tabindex="-1"></a>        movement_grid <span class="op">=</span> gamma_density_layer <span class="op">+</span> vonmises_density_layer <span class="co"># Gamma and von Mises densities are on the log-scale</span></span>
<span id="cb45-162"><a href="#cb45-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-163"><a href="#cb45-163" aria-hidden="true" tabindex="-1"></a>        <span class="co"># normalise (on the log-scale using the log-sum-exp trick) before combining with the habitat predictions</span></span>
<span id="cb45-164"><a href="#cb45-164" aria-hidden="true" tabindex="-1"></a>        movement_grid <span class="op">=</span> movement_grid <span class="op">-</span> torch.logsumexp(movement_grid, dim <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>), keepdim <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb45-165"><a href="#cb45-165" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print('Movement grid norm ', torch.sum(movement_grid))</span></span>
<span id="cb45-166"><a href="#cb45-166" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(torch.sum(torch.exp(movement_grid)))</span></span>
<span id="cb45-167"><a href="#cb45-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-168"><a href="#cb45-168" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> movement_grid</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="scalar-to-grid-block" class="level2">
<h2 class="anchored" data-anchor-id="scalar-to-grid-block">Scalar to grid block</h2>
<p>This block takes any scalar value (e.g., time of day, day of year) and converts it to a 2D image, with the same values for all pixels.</p>
<p>This is so that the scalar values can be used as input to the convolutional layers.</p>
<div id="cell-57" class="cell" data-execution_count="30">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Scalar_to_Grid_Block(nn.Module):</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, params):</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Scalar_to_Grid_Block, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># define the parameters</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_size <span class="op">=</span> params.batch_size</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_dim <span class="op">=</span> params.image_dim</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.device <span class="op">=</span> params.device</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># how many scalar values are being passed in</span></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>        num_scalars <span class="op">=</span> x.shape[<span class="dv">1</span>]</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># expand the scalar values to the spatial dimensions of the image</span></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>        scalar_map <span class="op">=</span> x.view(x.shape[<span class="dv">0</span>], num_scalars, <span class="dv">1</span>, <span class="dv">1</span>).expand(x.shape[<span class="dv">0</span>], num_scalars, <span class="va">self</span>.image_dim, <span class="va">self</span>.image_dim)</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># return the scalar maps</span></span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> scalar_map</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="combine-the-blocks-into-the-deepssf-model" class="level2">
<h2 class="anchored" data-anchor-id="combine-the-blocks-into-the-deepssf-model">Combine the blocks into the deepSSF model</h2>
<p>Here is where we combine the blocks into a model. Similarly to the previous blocks, the model is a Python class that inherits from <code>torch.nn.Module</code>, which combines other <code>torch.nn.Module</code> modules.</p>
<p>For example, we can instantiate the habitat selection convolution block using <code>self.conv_habitat = Conv2d_block_spatial(params)</code> in the <code>__init__</code> method (the â€˜constructorâ€™ for a class). We can now access that block using <code>self.conv_habitat</code> in the forward method.</p>
<p>In the forward method, we pass the input data through the habitat selection convolution block using <code>output_habitat = self.conv_habitat(all_spatial)</code>, where <code>all_spatial</code> is the input data, which is a combination of the spatial covariates and the scalar values converted to 2D images.</p>
<p>First we instantiate the blocks, and then define the forward method, which defines the data flow through the network during inference or training.</p>
<div id="cell-59" class="cell" data-execution_count="31">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ConvJointModel(nn.Module):</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, params):</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="co">        ConvJointModel:</span></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co">        - Initializes blocks for scalar-to-grid transformation, </span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="co">          habitat convolution, movement convolution + movement fully connected, and final parameter-to-grid transformation.</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a><span class="co">        - Accepts parameters from the params object, which we will define later.</span></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(ConvJointModel, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Block to convert scalar features into grid-like (spatial) features</span></span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.scalar_grid_output <span class="op">=</span> Scalar_to_Grid_Block(params)</span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convolutional block for habitat selection</span></span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv_habitat <span class="op">=</span> Conv2d_block_spatial(params)</span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convolutional block for movement extraction (output fed into fully connected layers)</span></span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv_movement <span class="op">=</span> Conv2d_block_toFC(params)</span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fully connected block for movement</span></span>
<span id="cb47-21"><a href="#cb47-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fcn_movement_all <span class="op">=</span> FCN_block_all_movement(params)</span>
<span id="cb47-22"><a href="#cb47-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-23"><a href="#cb47-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Converts movement distribution parameters into a grid (the 2D movement kernel)</span></span>
<span id="cb47-24"><a href="#cb47-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.movement_grid_output <span class="op">=</span> Params_to_Grid_Block(params)</span>
<span id="cb47-25"><a href="#cb47-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-26"><a href="#cb47-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Device information from params (e.g., CPU or GPU)</span></span>
<span id="cb47-27"><a href="#cb47-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.device <span class="op">=</span> params.device</span>
<span id="cb47-28"><a href="#cb47-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-29"><a href="#cb47-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb47-30"><a href="#cb47-30" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb47-31"><a href="#cb47-31" aria-hidden="true" tabindex="-1"></a><span class="co">        Forward pass:</span></span>
<span id="cb47-32"><a href="#cb47-32" aria-hidden="true" tabindex="-1"></a><span class="co">        1. Extract scalar data and convert to grid features.</span></span>
<span id="cb47-33"><a href="#cb47-33" aria-hidden="true" tabindex="-1"></a><span class="co">        2. Concatenate the newly created scalar-based grids with spatial data.</span></span>
<span id="cb47-34"><a href="#cb47-34" aria-hidden="true" tabindex="-1"></a><span class="co">        3. Pass this combined input through separate sub-networks for habitat and movement.</span></span>
<span id="cb47-35"><a href="#cb47-35" aria-hidden="true" tabindex="-1"></a><span class="co">        4. Convert movement parameters to a grid, then stack the habitat and movement outputs.</span></span>
<span id="cb47-36"><a href="#cb47-36" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb47-37"><a href="#cb47-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># x contains:</span></span>
<span id="cb47-38"><a href="#cb47-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># - spatial_data_x (image-like layers)</span></span>
<span id="cb47-39"><a href="#cb47-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># - scalars_to_grid (scalar features needing conversion)</span></span>
<span id="cb47-40"><a href="#cb47-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># - bearing_x (the bearing from the previous time step, the turning angle is estimated as the deviation from this)</span></span>
<span id="cb47-41"><a href="#cb47-41" aria-hidden="true" tabindex="-1"></a>        spatial_data_x <span class="op">=</span> x[<span class="dv">0</span>]</span>
<span id="cb47-42"><a href="#cb47-42" aria-hidden="true" tabindex="-1"></a>        scalars_to_grid <span class="op">=</span> x[<span class="dv">1</span>]</span>
<span id="cb47-43"><a href="#cb47-43" aria-hidden="true" tabindex="-1"></a>        bearing_x <span class="op">=</span> x[<span class="dv">2</span>]</span>
<span id="cb47-44"><a href="#cb47-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-45"><a href="#cb47-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert scalar data to spatial (grid) form</span></span>
<span id="cb47-46"><a href="#cb47-46" aria-hidden="true" tabindex="-1"></a>        scalar_grids <span class="op">=</span> <span class="va">self</span>.scalar_grid_output(scalars_to_grid)</span>
<span id="cb47-47"><a href="#cb47-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-48"><a href="#cb47-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Combine the original spatial data with the newly generated scalar grids</span></span>
<span id="cb47-49"><a href="#cb47-49" aria-hidden="true" tabindex="-1"></a>        all_spatial <span class="op">=</span> torch.cat([spatial_data_x, scalar_grids], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb47-50"><a href="#cb47-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-51"><a href="#cb47-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># HABITAT SUBNETWORK</span></span>
<span id="cb47-52"><a href="#cb47-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convolutional feature extraction for habitat selection</span></span>
<span id="cb47-53"><a href="#cb47-53" aria-hidden="true" tabindex="-1"></a>        output_habitat <span class="op">=</span> <span class="va">self</span>.conv_habitat(all_spatial)</span>
<span id="cb47-54"><a href="#cb47-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-55"><a href="#cb47-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># MOVEMENT SUBNETWORK</span></span>
<span id="cb47-56"><a href="#cb47-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convolutional feature extraction (different architecture for movement)</span></span>
<span id="cb47-57"><a href="#cb47-57" aria-hidden="true" tabindex="-1"></a>        conv_movement <span class="op">=</span> <span class="va">self</span>.conv_movement(all_spatial)</span>
<span id="cb47-58"><a href="#cb47-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-59"><a href="#cb47-59" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fully connected layers for movement (processing both spatial features and any extras)</span></span>
<span id="cb47-60"><a href="#cb47-60" aria-hidden="true" tabindex="-1"></a>        output_movement <span class="op">=</span> <span class="va">self</span>.fcn_movement_all(conv_movement)</span>
<span id="cb47-61"><a href="#cb47-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-62"><a href="#cb47-62" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Transform the movement parameters into a grid, using bearing information</span></span>
<span id="cb47-63"><a href="#cb47-63" aria-hidden="true" tabindex="-1"></a>        output_movement <span class="op">=</span> <span class="va">self</span>.movement_grid_output(output_movement, bearing_x)</span>
<span id="cb47-64"><a href="#cb47-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-65"><a href="#cb47-65" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Combine (stack) habitat and movement outputs without merging them</span></span>
<span id="cb47-66"><a href="#cb47-66" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> torch.stack((output_habitat, output_movement), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb47-67"><a href="#cb47-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-68"><a href="#cb47-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="set-the-parameters-for-the-model-which-will-be-specified-in-a-dictionary" class="level2">
<h2 class="anchored" data-anchor-id="set-the-parameters-for-the-model-which-will-be-specified-in-a-dictionary">Set the parameters for the model which will be specified in a dictionary</h2>
<p>This Python class serves as a simple parameter container for a model that involves both spatial (e.g., convolutional layers) and non-spatial inputs. It captures all relevant hyperparameters and settingsâ€”such as image dimensions, kernel sizes, and fully connected layer dimensionsâ€”along with the target device (CPU or GPU). This structure allows easy configuration of the model without scattering parameters throughout the code.</p>
<div id="cell-61" class="cell" data-execution_count="32">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ModelParams():</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dict_params):</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_size <span class="op">=</span> dict_params[<span class="st">"batch_size"</span>]</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_dim <span class="op">=</span> dict_params[<span class="st">"image_dim"</span>]</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pixel_size <span class="op">=</span> dict_params[<span class="st">"pixel_size"</span>]</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_size <span class="op">=</span> dict_params[<span class="st">"batch_size"</span>]</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dim_in_nonspatial_to_grid <span class="op">=</span> dict_params[<span class="st">"dim_in_nonspatial_to_grid"</span>]</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dense_dim_in_nonspatial <span class="op">=</span> dict_params[<span class="st">"dense_dim_in_nonspatial"</span>]</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dense_dim_hidden <span class="op">=</span> dict_params[<span class="st">"dense_dim_hidden"</span>]</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dense_dim_out <span class="op">=</span> dict_params[<span class="st">"dense_dim_out"</span>]</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_size <span class="op">=</span> dict_params[<span class="st">"batch_size"</span>]</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dense_dim_in_all <span class="op">=</span> dict_params[<span class="st">"dense_dim_in_all"</span>]</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dense_dim_hidden <span class="op">=</span> dict_params[<span class="st">"dense_dim_hidden"</span>]</span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dense_dim_out <span class="op">=</span> dict_params[<span class="st">"dense_dim_out"</span>]</span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_size <span class="op">=</span> dict_params[<span class="st">"batch_size"</span>]</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_channels <span class="op">=</span> dict_params[<span class="st">"input_channels"</span>]</span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_channels <span class="op">=</span> dict_params[<span class="st">"output_channels"</span>]</span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.kernel_size <span class="op">=</span> dict_params[<span class="st">"kernel_size"</span>]</span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.stride <span class="op">=</span> dict_params[<span class="st">"stride"</span>]</span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.kernel_size_mp <span class="op">=</span> dict_params[<span class="st">"kernel_size_mp"</span>]</span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.stride_mp <span class="op">=</span> dict_params[<span class="st">"stride_mp"</span>]</span>
<span id="cb48-22"><a href="#cb48-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.padding <span class="op">=</span> dict_params[<span class="st">"padding"</span>]</span>
<span id="cb48-23"><a href="#cb48-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_dim <span class="op">=</span> dict_params[<span class="st">"image_dim"</span>]</span>
<span id="cb48-24"><a href="#cb48-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_movement_params <span class="op">=</span> dict_params[<span class="st">"num_movement_params"</span>]</span>
<span id="cb48-25"><a href="#cb48-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> dict_params[<span class="st">"dropout"</span>]</span>
<span id="cb48-26"><a href="#cb48-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.device <span class="op">=</span> dict_params[<span class="st">"device"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="define-the-parameters-for-the-model" class="level2">
<h2 class="anchored" data-anchor-id="define-the-parameters-for-the-model">Define the parameters for the model</h2>
<p>Here we enter the specific parameter values and hyperparameters for the model. These are the values that will be used to instantiate the model.</p>
<div id="cell-63" class="cell" data-execution_count="33">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>params_dict <span class="op">=</span> {<span class="st">"batch_size"</span>: <span class="dv">32</span>, <span class="co">#number of samples in each batch</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>               <span class="st">"image_dim"</span>: <span class="dv">101</span>, <span class="co">#number of pixels along the edge of each local patch/image</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>               <span class="st">"pixel_size"</span>: <span class="dv">25</span>, <span class="co">#number of metres along the edge of a pixel</span></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>               <span class="st">"dim_in_nonspatial_to_grid"</span>: <span class="dv">4</span>, <span class="co">#the number of scalar predictors that are converted to a grid and appended to the spatial features</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>               <span class="st">"dense_dim_in_nonspatial"</span>: <span class="dv">4</span>, <span class="co">#change this to however many other scalar predictors you have (bearing, velocity etc)</span></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>               <span class="st">"dense_dim_hidden"</span>: <span class="dv">128</span>, <span class="co">#number of nodes in the hidden layers</span></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>               <span class="st">"dense_dim_out"</span>: <span class="dv">128</span>, <span class="co">#number of nodes in the output of the fully connected block (FCN)</span></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>               <span class="st">"dense_dim_in_all"</span>: <span class="dv">2500</span>,<span class="co"># + 128, #number of inputs entering the fully connected block once the nonspatial features have been concatenated to the spatial features</span></span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>               <span class="st">"input_channels"</span>: <span class="dv">4</span> <span class="op">+</span> <span class="dv">4</span>, <span class="co">#number of spatial layers in each image + number of scalar layers that are converted to a grid</span></span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>               <span class="st">"output_channels"</span>: <span class="dv">4</span>, <span class="co">#number of filters to learn</span></span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>               <span class="st">"kernel_size"</span>: <span class="dv">3</span>, <span class="co">#the size of the 2D moving windows / kernels that are being learned</span></span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>               <span class="st">"stride"</span>: <span class="dv">1</span>, <span class="co">#the stride used when applying the kernel.  This reduces the dimension of the output if set to greater than 1</span></span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>               <span class="st">"kernel_size_mp"</span>: <span class="dv">2</span>, <span class="co">#the size of the kernel that is used in max pooling operations</span></span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>               <span class="st">"stride_mp"</span>: <span class="dv">2</span>, <span class="co">#the stride that is used in max pooling operations</span></span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a>               <span class="st">"padding"</span>: <span class="dv">1</span>, <span class="co">#the amount of padding to apply to images prior to applying the 2D convolution</span></span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>               <span class="st">"num_movement_params"</span>: <span class="dv">12</span>, <span class="co">#number of parameters used to parameterise the movement kernel</span></span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a>               <span class="st">"dropout"</span>: <span class="fl">0.1</span>, <span class="co">#the proportion of nodes that are dropped out in the dropout layers</span></span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a>               <span class="st">"device"</span>: device</span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a>               }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="note-about-the-model" class="level2">
<h2 class="anchored" data-anchor-id="note-about-the-model">Note about the model</h2>
<p>In future scripts (such as when simulating from the deepSSF model or training the model on Sentinel-2 data) we want to load the same model, so to prevent copying and pasting, we will save the model definition to a Python file and import it into future scripts.</p>
<p>We do this by copying the model definition above to a Python file named <code>deepSSF_model.py</code>, which can be imported into future scripts using <code>import deepSSF_model</code>.</p>
<p>Ideally we would just use that file to define the model in this script, but we include it here as itâ€™s helpful to test components of the model and see how it all works.</p>
<p>Just remember that if you make changes to the model in this script, you will have to copy them across the <code>deepSSF_model.py</code> file, or just change the model definition in the <code>deepSSF_model.py</code> file and call that directly from here to train it.</p>
<p>To call it you would uncomment the lines in the next cell.</p>
<div id="cell-65" class="cell" data-execution_count="34">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># # Import the functions in the deepSSF_model.py file</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="co"># import deepSSF_model</span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="co"># # Create an instance of the ModelParams class using the params_dict</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="co"># params = deepSSF_model.ModelParams(deepSSF_model.params_dict)</span></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a><span class="co"># # Create an instance of the ConvJointModel class using the params</span></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a><span class="co"># model = deepSSF_model.ConvJointModel(params).to(device)</span></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a><span class="co"># # Print the model architecture to check that it worked</span></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a><span class="co"># print(model)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="instantiate-the-model" class="level2">
<h2 class="anchored" data-anchor-id="instantiate-the-model">Instantiate the model</h2>
<p>Here we instantiate the model using the parameters defined above.</p>
<div id="cell-67" class="cell" data-execution_count="124">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the parameter container using the parameters defined in 'params_dict'</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> ModelParams(params_dict)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an instance of the ConvJointModel using the parameters, </span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a><span class="co"># and move the model to the specified device (e.g., CPU or GPU)</span></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ConvJointModel(params).to(device)</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the model architecture</span></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>ConvJointModel(
  (scalar_grid_output): Scalar_to_Grid_Block()
  (conv_habitat): Conv2d_block_spatial(
    (conv2d): Sequential(
      (0): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(4, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (conv_movement): Conv2d_block_toFC(
    (conv2d): Sequential(
      (0): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (3): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): ReLU()
      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (6): Flatten(start_dim=1, end_dim=-1)
    )
  )
  (fcn_movement_all): FCN_block_all_movement(
    (ffn): Sequential(
      (0): Linear(in_features=2500, out_features=128, bias=True)
      (1): Dropout(p=0.1, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=128, bias=True)
      (4): Dropout(p=0.1, inplace=False)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=12, bias=True)
    )
  )
  (movement_grid_output): Params_to_Grid_Block()
)</code></pre>
</div>
</div>
</section>
</section>
<section id="testing-model-components" class="level1">
<h1>Testing model components</h1>
<p>As weâ€™ve defined the model, we can now test the components to ensure that they are working as expected.</p>
<p>We can do this block by block, or we can test the entire model.</p>
<p>Weâ€™ll start by testing a few of the blocks.</p>
<section id="testing-the-movement-parameter-to-probability-distribution-block" class="level2">
<h2 class="anchored" data-anchor-id="testing-the-movement-parameter-to-probability-distribution-block">Testing the movement parameter to probability distribution block</h2>
<p>Change any of the values to try out different movement kernels.</p>
<div id="cell-70" class="cell" data-execution_count="36">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a bearing tensor (e.g., 0 radians) on the desired device</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>test_bearing <span class="op">=</span> torch.tensor([[<span class="fl">0.0</span>]], device<span class="op">=</span>device)</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiate the Params_to_Grid_Block using the given parameters</span></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>test_block <span class="op">=</span> Params_to_Grid_Block(params)</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the parameters for the movement density</span></span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a><span class="co"># These are the parameters that the model will learn to predict</span></span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a><span class="co"># First Gamma distribution</span></span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>gamma_shape1 <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>gamma_scale1 <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>gamma_weight1 <span class="op">=</span> <span class="fl">0.25</span></span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Second Gamma distribution</span></span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a>gamma_shape2 <span class="op">=</span> <span class="fl">1.5</span></span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a>gamma_scale2 <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a>gamma_scale2 <span class="op">=</span> gamma_scale2 <span class="op">/</span> <span class="dv">500</span> <span class="co"># divide this by 500 (as this is what the model predicts)</span></span>
<span id="cb53-19"><a href="#cb53-19" aria-hidden="true" tabindex="-1"></a>gamma_weight2 <span class="op">=</span> <span class="fl">0.75</span></span>
<span id="cb53-20"><a href="#cb53-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-21"><a href="#cb53-21" aria-hidden="true" tabindex="-1"></a><span class="co"># First von Mises distribution</span></span>
<span id="cb53-22"><a href="#cb53-22" aria-hidden="true" tabindex="-1"></a>vonmises_mu1 <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb53-23"><a href="#cb53-23" aria-hidden="true" tabindex="-1"></a>vonmises_kappa1 <span class="op">=</span> <span class="fl">2.5</span></span>
<span id="cb53-24"><a href="#cb53-24" aria-hidden="true" tabindex="-1"></a>vonmises_weight1 <span class="op">=</span> <span class="fl">0.75</span></span>
<span id="cb53-25"><a href="#cb53-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-26"><a href="#cb53-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Second von Mises distribution</span></span>
<span id="cb53-27"><a href="#cb53-27" aria-hidden="true" tabindex="-1"></a>vonmises_mu2 <span class="op">=</span> <span class="op">-</span>np.pi</span>
<span id="cb53-28"><a href="#cb53-28" aria-hidden="true" tabindex="-1"></a>vonmises_kappa2 <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb53-29"><a href="#cb53-29" aria-hidden="true" tabindex="-1"></a>vonmises_weight2 <span class="op">=</span> <span class="fl">0.25</span></span>
<span id="cb53-30"><a href="#cb53-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-31"><a href="#cb53-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Provide parameters on a log-scale (since the block exponentiates them internally)</span></span>
<span id="cb53-32"><a href="#cb53-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Here, each group of three values represents a Gamma distribution's shape, scale, and weight, respectively.</span></span>
<span id="cb53-33"><a href="#cb53-33" aria-hidden="true" tabindex="-1"></a>movement_density <span class="op">=</span> test_block(</span>
<span id="cb53-34"><a href="#cb53-34" aria-hidden="true" tabindex="-1"></a>    torch.tensor(</span>
<span id="cb53-35"><a href="#cb53-35" aria-hidden="true" tabindex="-1"></a>        [[</span>
<span id="cb53-36"><a href="#cb53-36" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Gamma 1</span></span>
<span id="cb53-37"><a href="#cb53-37" aria-hidden="true" tabindex="-1"></a>            np.log(gamma_shape1),   np.log(gamma_scale1),   np.log(gamma_weight1), <span class="co"># Gamma 1 shape, scale, and weight</span></span>
<span id="cb53-38"><a href="#cb53-38" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Gamma 2</span></span>
<span id="cb53-39"><a href="#cb53-39" aria-hidden="true" tabindex="-1"></a>            np.log(gamma_shape2),   np.log(gamma_scale2),   np.log(gamma_weight2), <span class="co"># Gamma 2 shape, scale, and weight</span></span>
<span id="cb53-40"><a href="#cb53-40" aria-hidden="true" tabindex="-1"></a>            <span class="co"># von Mises 1</span></span>
<span id="cb53-41"><a href="#cb53-41" aria-hidden="true" tabindex="-1"></a>            vonmises_mu1,           np.log(vonmises_kappa1), np.log(vonmises_weight1), <span class="co"># von Mises 1 mu, kappa, and weight</span></span>
<span id="cb53-42"><a href="#cb53-42" aria-hidden="true" tabindex="-1"></a>            <span class="co"># von Mises 2</span></span>
<span id="cb53-43"><a href="#cb53-43" aria-hidden="true" tabindex="-1"></a>            vonmises_mu2,           np.log(vonmises_kappa2), np.log(vonmises_weight2) <span class="co"># von Mises 2 mu, kappa, and weight</span></span>
<span id="cb53-44"><a href="#cb53-44" aria-hidden="true" tabindex="-1"></a>        ]],</span>
<span id="cb53-45"><a href="#cb53-45" aria-hidden="true" tabindex="-1"></a>        device<span class="op">=</span>device</span>
<span id="cb53-46"><a href="#cb53-46" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb53-47"><a href="#cb53-47" aria-hidden="true" tabindex="-1"></a>    test_bearing</span>
<span id="cb53-48"><a href="#cb53-48" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb53-49"><a href="#cb53-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-50"><a href="#cb53-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternatively, if you had direct (non-log) values as the model sees them:</span></span>
<span id="cb53-51"><a href="#cb53-51" aria-hidden="true" tabindex="-1"></a><span class="co"># movement_density = test_block(torch.tensor([[-.5, -.5, -.5, -.5]], device=device))</span></span>
<span id="cb53-52"><a href="#cb53-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-53"><a href="#cb53-53" aria-hidden="true" tabindex="-1"></a><span class="co"># print(movement_density)</span></span>
<span id="cb53-54"><a href="#cb53-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(movement_density.shape)</span>
<span id="cb53-55"><a href="#cb53-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-56"><a href="#cb53-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the resulting movement density as an image</span></span>
<span id="cb53-57"><a href="#cb53-57" aria-hidden="true" tabindex="-1"></a>plt.imshow(movement_density.detach().cpu().numpy()[<span class="dv">0</span>])</span>
<span id="cb53-58"><a href="#cb53-58" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb53-59"><a href="#cb53-59" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([1, 101, 101])</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-37-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="pull-out-some-testing-data" class="level2">
<h2 class="anchored" data-anchor-id="pull-out-some-testing-data">Pull out some testing data</h2>
<p>To test the other blocks, and the full model, we will need some data. We can pull that out from the training set.</p>
<p>As the test set is shuffled, the <code>iteration_index</code> is arbitrary and can be changed to any value between 0 and the number of samples in the test set.</p>
<div id="cell-72" class="cell" data-execution_count="115">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of samples in the test dataset</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of samples in the test dataset: "</span>, <span class="bu">len</span>(dataloader_test.dataset))</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Select an index from the test dataset to retrieve a sample, between 0 and number of samples</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>iteration_index <span class="op">=</span> <span class="dv">7</span></span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Retrieve a single sample (features and label) from the test dataset at the specified index</span></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>test_data <span class="op">=</span> x1, x2, x3, labels <span class="op">=</span> dataloader_test.dataset[iteration_index]</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Reshape data tensors to add a batch dimension (since the model expects batches)</span></span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>x1_sample <span class="op">=</span> x1.unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>x2_sample <span class="op">=</span> x2.unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a>x3_sample <span class="op">=</span> x3.unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> labels.unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x1_sample.shape, x2_sample.shape, x3_sample.shape, labels.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Number of samples in the test dataset:  1010
torch.Size([1, 4, 101, 101]) torch.Size([1, 4]) torch.Size([1, 1]) torch.Size([1, 101, 101])</code></pre>
</div>
</div>
<section id="for-visualisation-we-can-return-the-scale-of-the-covariates-to-their-original-values." class="level3">
<h3 class="anchored" data-anchor-id="for-visualisation-we-can-return-the-scale-of-the-covariates-to-their-original-values.">For visualisation, we can return the scale of the covariates to their original values.</h3>
<div id="cell-74" class="cell" data-execution_count="116">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. NDVI (Normalized Difference Vegetation Index)</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>ndvi_norm <span class="op">=</span> x1_sample.detach().cpu()[<span class="dv">0</span>, <span class="dv">0</span>, :, :]</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>ndvi_natural <span class="op">=</span> (ndvi_norm <span class="op">*</span> (ndvi_max <span class="op">-</span> ndvi_min)) <span class="op">+</span> ndvi_min</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Canopy cover</span></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>canopy_norm <span class="op">=</span> x1_sample.detach().cpu()[<span class="dv">0</span>, <span class="dv">1</span>, :, :]</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>canopy_natural <span class="op">=</span> (canopy_norm <span class="op">*</span> (canopy_max <span class="op">-</span> canopy_min)) <span class="op">+</span> canopy_min</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Herbaceous vegetation</span></span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>herby_norm <span class="op">=</span> x1_sample.detach().cpu()[<span class="dv">0</span>, <span class="dv">2</span>, :, :]</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>herby_natural <span class="op">=</span> (herby_norm <span class="op">*</span> (herby_max <span class="op">-</span> herby_min)) <span class="op">+</span> herby_min</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Slope</span></span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a>slope_norm <span class="op">=</span> x1_sample.detach().cpu()[<span class="dv">0</span>, <span class="dv">3</span>, :, :]</span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a>slope_natural <span class="op">=</span> (slope_norm <span class="op">*</span> (slope_max <span class="op">-</span> slope_min)) <span class="op">+</span> slope_min</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="pull-out-the-scalar-values" class="level3">
<h3 class="anchored" data-anchor-id="pull-out-the-scalar-values">Pull out the scalar values</h3>
<div id="cell-76" class="cell" data-execution_count="117">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the PyTorch tensor x2 to a NumPy array:</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="co">#   1) Detach from the computation graph so no gradients are tracked.</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="co">#   2) Move to CPU memory.</span></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   3) Convert to NumPy.</span></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Then extract the first sample (index 0) and its respective channel for each variable:</span></span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>hour_t2_sin <span class="op">=</span> x2_sample.detach().cpu().numpy()[<span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>hour_t2_cos <span class="op">=</span> x2_sample.detach().cpu().numpy()[<span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>yday_t2_sin <span class="op">=</span> x2_sample.detach().cpu().numpy()[<span class="dv">0</span>, <span class="dv">2</span>]</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>yday_t2_cos <span class="op">=</span> x2_sample.detach().cpu().numpy()[<span class="dv">0</span>, <span class="dv">3</span>]</span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert x3 similarly and extract the bearing from the first sample and channel:</span></span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>bearing <span class="op">=</span> x3_sample.detach().cpu().numpy()[<span class="dv">0</span>, <span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="helper-functions" class="level3">
<h3 class="anchored" data-anchor-id="helper-functions">Helper functions</h3>
<p>To return the hour and day of the year to their original values, we can use the following functions.</p>
<div id="cell-78" class="cell" data-execution_count="118">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> recover_hour(sin_term, cos_term):</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the angle theta</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>    theta <span class="op">=</span> np.arctan2(sin_term, cos_term)</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate hour_t2</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>    hour <span class="op">=</span> (<span class="dv">12</span> <span class="op">*</span> theta) <span class="op">/</span> np.pi <span class="op">%</span> <span class="dv">24</span></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> hour</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> recover_yday(sin_term, cos_term):</span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the angle theta</span></span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a>    theta <span class="op">=</span> np.arctan2(sin_term, cos_term)</span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate hour_t2</span></span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a>    yday <span class="op">=</span> (<span class="dv">365</span> <span class="op">*</span> theta) <span class="op">/</span> (<span class="dv">2</span> <span class="op">*</span> np.pi)  <span class="op">%</span> <span class="dv">365</span></span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> yday</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="calculate-the-hour-day-of-year-and-previous-bearing-of-the-test-sample" class="level3">
<h3 class="anchored" data-anchor-id="calculate-the-hour-day-of-year-and-previous-bearing-of-the-test-sample">Calculate the hour, day of year and previous bearing of the test sample</h3>
<div id="cell-80" class="cell" data-execution_count="119">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>hour_t2 <span class="op">=</span> recover_hour(hour_t2_sin, hour_t2_cos)</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>hour_t2_integer <span class="op">=</span> <span class="bu">int</span>(hour_t2)  <span class="co"># Convert to integer</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Hour: </span><span class="sc">{</span>hour_t2_integer<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>yday_t2 <span class="op">=</span> recover_yday(yday_t2_sin, yday_t2_cos)</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>yday_t2_integer <span class="op">=</span> <span class="bu">int</span>(yday_t2)  <span class="co"># Convert to integer</span></span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Day of the year: </span><span class="sc">{</span>yday_t2_integer<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>bearing_degrees <span class="op">=</span> np.degrees(bearing) <span class="op">%</span> <span class="dv">360</span></span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a>bearing_degrees <span class="op">=</span> <span class="bu">round</span>(bearing_degrees, <span class="dv">1</span>)  <span class="co"># Round to 2 decimal places</span></span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a>bearing_degrees <span class="op">=</span> <span class="bu">int</span>(bearing_degrees)  <span class="co"># Convert to integer</span></span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Bearing (radians): </span><span class="sc">{</span>bearing<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Bearing (degrees): </span><span class="sc">{</span>bearing_degrees<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Hour: 12
Day of the year: 7
Bearing (radians): -2.4189999103546143
Bearing (degrees): 221</code></pre>
</div>
</div>
</section>
<section id="grab-the-row-and-column-of-the-observed-next-step-label-or-target" class="level3">
<h3 class="anchored" data-anchor-id="grab-the-row-and-column-of-the-observed-next-step-label-or-target">Grab the row and column of the observed next step (label or target)</h3>
<div id="cell-82" class="cell" data-execution_count="120">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the coordinates of the element that is 1</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> labels.detach().cpu().numpy()[<span class="dv">0</span>,:,:]</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>coordinates <span class="op">=</span> np.where(target <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the coordinates</span></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>row, column <span class="op">=</span> coordinates[<span class="dv">0</span>][<span class="dv">0</span>], coordinates[<span class="dv">1</span>][<span class="dv">0</span>]</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The location of the next step is (row, column): (</span><span class="sc">{</span>row<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>column<span class="sc">}</span><span class="ss">)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The location of the next step is (row, column): (49, 67)</code></pre>
</div>
</div>
</section>
<section id="plot-the-sample-covariates" class="level3">
<h3 class="anchored" data-anchor-id="plot-the-sample-covariates">Plot the sample covariates</h3>
<div id="cell-84" class="cell" data-execution_count="121">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the covariates</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="fl">7.5</span>))</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot NDVI</span></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>im1 <span class="op">=</span> axs[<span class="dv">0</span>, <span class="dv">0</span>].imshow(ndvi_natural.numpy(), cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="st">'NDVI'</span>)</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>fig.colorbar(im1, ax<span class="op">=</span>axs[<span class="dv">0</span>, <span class="dv">0</span>])</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Canopy cover</span></span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>im2 <span class="op">=</span> axs[<span class="dv">0</span>, <span class="dv">1</span>].imshow(canopy_natural.numpy(), cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>, <span class="dv">1</span>].set_title(<span class="st">'Canopy cover'</span>)</span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a>fig.colorbar(im2, ax<span class="op">=</span>axs[<span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Herbaceous vegetation</span></span>
<span id="cb64-15"><a href="#cb64-15" aria-hidden="true" tabindex="-1"></a>im3 <span class="op">=</span> axs[<span class="dv">1</span>, <span class="dv">0</span>].imshow(herby_natural.numpy(), cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb64-16"><a href="#cb64-16" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>, <span class="dv">0</span>].set_title(<span class="st">'Herbaceous vegetation'</span>)</span>
<span id="cb64-17"><a href="#cb64-17" aria-hidden="true" tabindex="-1"></a>fig.colorbar(im3, ax<span class="op">=</span>axs[<span class="dv">1</span>, <span class="dv">0</span>])</span>
<span id="cb64-18"><a href="#cb64-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-19"><a href="#cb64-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Slope</span></span>
<span id="cb64-20"><a href="#cb64-20" aria-hidden="true" tabindex="-1"></a>im4 <span class="op">=</span> axs[<span class="dv">1</span>, <span class="dv">1</span>].imshow(slope_natural.numpy(), cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb64-21"><a href="#cb64-21" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>, <span class="dv">1</span>].set_title(<span class="st">'Slope'</span>)</span>
<span id="cb64-22"><a href="#cb64-22" aria-hidden="true" tabindex="-1"></a>fig.colorbar(im4, ax<span class="op">=</span>axs[<span class="dv">1</span>, <span class="dv">1</span>])</span>
<span id="cb64-23"><a href="#cb64-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-24"><a href="#cb64-24" aria-hidden="true" tabindex="-1"></a>filename_covs <span class="op">=</span> <span class="ss">f'outputs/model_training_local/covs_id</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_yday</span><span class="sc">{</span>yday_t2_integer<span class="sc">}</span><span class="ss">_hour</span><span class="sc">{</span>hour_t2_integer<span class="sc">}</span><span class="ss">_bearing</span><span class="sc">{</span>bearing_degrees<span class="sc">}</span><span class="ss">_next_r</span><span class="sc">{</span>row<span class="sc">}</span><span class="ss">_c</span><span class="sc">{</span>column<span class="sc">}</span><span class="ss">.png'</span></span>
<span id="cb64-25"><a href="#cb64-25" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb64-26"><a href="#cb64-26" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.savefig(filename_covs, dpi=600, bbox_inches='tight') # if we want to save the figure</span></span>
<span id="cb64-27"><a href="#cb64-27" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb64-28"><a href="#cb64-28" aria-hidden="true" tabindex="-1"></a>plt.close()  <span class="co"># Close the figure to free memory</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-44-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="plot-the-target-location-of-the-next-step" class="level2">
<h2 class="anchored" data-anchor-id="plot-the-target-location-of-the-next-step">Plot the target (location of the next step)</h2>
<div id="cell-86" class="cell" data-execution_count="122">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>plt.imshow(target)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-45-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="testing-the-scalar-to-grid-function" class="level2">
<h2 class="anchored" data-anchor-id="testing-the-scalar-to-grid-function">Testing the scalar to grid function</h2>
<p>This should just create a grid with the same value for all pixels.</p>
<div id="cell-89" class="cell" data-outputid="fd76bdee-f64e-48f6-8468-d5fab3cab580" data-execution_count="123">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># x2 contains the scalar inputs</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x2_sample.shape)  <span class="co"># Check the shape of the scalar input</span></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x2_sample[<span class="dv">0</span>, :])  <span class="co"># Print out the first set of scalars</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an instance of the scalar-to-grid block using model parameters</span></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>test_block <span class="op">=</span> Scalar_to_Grid_Block(params)</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert scalars into spatial grid representation</span></span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>scalar_maps <span class="op">=</span> test_block(x2_sample)</span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a><span class="co"># print(scalar_maps)  # Optionally, to inspect raw output</span></span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(scalar_maps.shape)  <span class="co"># Check the shape of the generated spatial maps</span></span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize one channel of the first example's scalar map</span></span>
<span id="cb66-14"><a href="#cb66-14" aria-hidden="true" tabindex="-1"></a><span class="co"># (Values are should be repeated across the grid for each scalar)</span></span>
<span id="cb66-15"><a href="#cb66-15" aria-hidden="true" tabindex="-1"></a>scalar_index <span class="op">=</span> <span class="dv">2</span>  <span class="co"># Change this index to visualize other scalar maps</span></span>
<span id="cb66-16"><a href="#cb66-16" aria-hidden="true" tabindex="-1"></a>plt.imshow(scalar_maps[<span class="dv">0</span>, scalar_index]) <span class="co"># change the second index to see the other scalar maps</span></span>
<span id="cb66-17"><a href="#cb66-17" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb66-18"><a href="#cb66-18" aria-hidden="true" tabindex="-1"></a>plt.clim(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="co"># Set the color limits to match the range of the scalar values (sine and cosine of temporal parameters)</span></span>
<span id="cb66-19"><a href="#cb66-19" aria-hidden="true" tabindex="-1"></a>plt.text(scalar_maps.shape[<span class="dv">2</span>] <span class="op">//</span> <span class="dv">2</span>, scalar_maps.shape[<span class="dv">3</span>] <span class="op">//</span> <span class="dv">2</span>, </span>
<span id="cb66-20"><a href="#cb66-20" aria-hidden="true" tabindex="-1"></a>         <span class="ss">f'Value: </span><span class="sc">{</span><span class="bu">round</span>(x2_sample[<span class="dv">0</span>, scalar_index].item(), <span class="dv">2</span>)<span class="sc">}</span><span class="ss">'</span>, </span>
<span id="cb66-21"><a href="#cb66-21" aria-hidden="true" tabindex="-1"></a>         ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'center'</span>, color<span class="op">=</span><span class="st">'white'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb66-22"><a href="#cb66-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([1, 4])
tensor([ 1.2246e-16, -1.0000e+00,  1.3719e-01,  9.9055e-01])
torch.Size([1, 4, 101, 101])</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-46-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="test-the-full-model" class="level1">
<h1>Test the full model</h1>
<p>The model is initialised with random weights and hasnâ€™t been trained yet, so the output will not be meaningful. However, we can check that the model runs without errors and that the output is the correct shape.</p>
<div id="cell-92" class="cell" data-outputid="cdce2576-10f6-46e1-c5ab-cf72f46d0f9b" data-execution_count="125">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Put the model in evaluation mode (affects layers like dropout, batch norm, etc.)</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Pass the data through the model</span></span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> model((x1_sample, x2_sample, x3_sample))</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the shape of the output</span></span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([1, 101, 101, 2])</code></pre>
</div>
</div>
<section id="habitat-predictions" class="level2">
<h2 class="anchored" data-anchor-id="habitat-predictions">Habitat predictions</h2>
<div id="cell-94" class="cell" data-execution_count="126">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>plt.imshow(test.detach().cpu().numpy()[<span class="dv">0</span>,:,:,<span class="dv">0</span>])</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-48-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="movement-predictions" class="level2">
<h2 class="anchored" data-anchor-id="movement-predictions">Movement predictions</h2>
<div id="cell-96" class="cell" data-execution_count="127">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print input bearing</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Bearing (radians): </span><span class="sc">{</span>bearing<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Bearing (degrees): </span><span class="sc">{</span>bearing_degrees<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the movement density on the log-scale</span></span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>plt.imshow(test.detach().cpu().numpy()[<span class="dv">0</span>,:,:,<span class="dv">1</span>])</span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the movement density on the natural scale</span></span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a>plt.imshow(np.exp(test.detach().cpu().numpy()[<span class="dv">0</span>,:,:,<span class="dv">1</span>]))</span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Bearing (radians): -2.4189999103546143
Bearing (degrees): 221</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-49-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-49-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="next-step-probability-distribution" class="level2">
<h2 class="anchored" data-anchor-id="next-step-probability-distribution">Next-step probability distribution</h2>
<div id="cell-98" class="cell" data-execution_count="128">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine the habitat selection and the movement probabilities (unnormalised)</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>next_step <span class="op">=</span> (test[:, :, :, <span class="dv">0</span>] <span class="op">+</span> test[:, :, :, <span class="dv">1</span>])</span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the combined output</span></span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>plt.imshow(next_step.detach().cpu().numpy()[<span class="dv">0</span>,:,:])</span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-50-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="prepare-for-training" class="level1">
<h1>Prepare for training</h1>
<section id="loss-function" class="level2">
<h2 class="anchored" data-anchor-id="loss-function">Loss function</h2>
<p>We use a custom negative log likelihood loss function. Essentially what this does is extracts the next-step log-probability at the location of the observed next step, and then takes the negative of this value. This is the loss that we want to minimise, as we want to maximise the probability of the observed next step.</p>
<p>We will also save this loss function in a script called <code>deepSSF_loss.py</code> so that we can import it into future scripts.</p>
<div id="cell-100" class="cell">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> negativeLogLikeLoss(nn.Module):</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Custom negative log-likelihood loss that operates on a 4D prediction tensor </span></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a><span class="co">    (batch, height, width, channels). The forward pass:</span></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a><span class="co">    1. Sums across channel 3 (two log-densities, habitat selection and movement predictions) to obtain a combined log-density.</span></span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a><span class="co">    2. Multiplies this log-density by the target, which is 0 everywhere except for at the location of the next step, effectively extracting that value, </span></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a><span class="co">    then multiplies by -1 such that the function can be minimised (and the probabilities maximised).</span></span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a><span class="co">    3. Applies the user-specified reduction (mean, sum, or none).</span></span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, reduction<span class="op">=</span><span class="st">'mean'</span>):</span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb74-14"><a href="#cb74-14" aria-hidden="true" tabindex="-1"></a><span class="co">            reduction (str): Specifies the reduction to apply to the output:</span></span>
<span id="cb74-15"><a href="#cb74-15" aria-hidden="true" tabindex="-1"></a><span class="co">                             'mean', 'sum', or 'none'.</span></span>
<span id="cb74-16"><a href="#cb74-16" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb74-17"><a href="#cb74-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(negativeLogLikeLoss, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb74-18"><a href="#cb74-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> reduction <span class="kw">in</span> [<span class="st">'mean'</span>, <span class="st">'sum'</span>, <span class="st">'none'</span>], <span class="op">\</span></span>
<span id="cb74-19"><a href="#cb74-19" aria-hidden="true" tabindex="-1"></a>            <span class="st">"reduction should be 'mean', 'sum', or 'none'"</span></span>
<span id="cb74-20"><a href="#cb74-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.reduction <span class="op">=</span> reduction</span>
<span id="cb74-21"><a href="#cb74-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-22"><a href="#cb74-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, predict, target):</span>
<span id="cb74-23"><a href="#cb74-23" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb74-24"><a href="#cb74-24" aria-hidden="true" tabindex="-1"></a><span class="co">        Forward pass of the negative log-likelihood loss.</span></span>
<span id="cb74-25"><a href="#cb74-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-26"><a href="#cb74-26" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb74-27"><a href="#cb74-27" aria-hidden="true" tabindex="-1"></a><span class="co">            predict (Tensor): A tensor of shape (B, H, W, 2) with log-densities </span></span>
<span id="cb74-28"><a href="#cb74-28" aria-hidden="true" tabindex="-1"></a><span class="co">                              across two channels to be summed.</span></span>
<span id="cb74-29"><a href="#cb74-29" aria-hidden="true" tabindex="-1"></a><span class="co">            target  (Tensor): A tensor of the same spatial dimensions (B, H, W) </span></span>
<span id="cb74-30"><a href="#cb74-30" aria-hidden="true" tabindex="-1"></a><span class="co">                              indicating where the log-densities should be evaluated.</span></span>
<span id="cb74-31"><a href="#cb74-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-32"><a href="#cb74-32" aria-hidden="true" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb74-33"><a href="#cb74-33" aria-hidden="true" tabindex="-1"></a><span class="co">            Tensor: The computed negative log-likelihood loss. Shape depends on </span></span>
<span id="cb74-34"><a href="#cb74-34" aria-hidden="true" tabindex="-1"></a><span class="co">                    the reduction method.</span></span>
<span id="cb74-35"><a href="#cb74-35" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb74-36"><a href="#cb74-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Sum the log-densities from the two channels</span></span>
<span id="cb74-37"><a href="#cb74-37" aria-hidden="true" tabindex="-1"></a>        predict_prod <span class="op">=</span> predict[:, :, :, <span class="dv">0</span>] <span class="op">+</span> predict[:, :, :, <span class="dv">1</span>]</span>
<span id="cb74-38"><a href="#cb74-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-39"><a href="#cb74-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check for NaNs in the combined predictions</span></span>
<span id="cb74-40"><a href="#cb74-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> torch.isnan(predict_prod).<span class="bu">any</span>():</span>
<span id="cb74-41"><a href="#cb74-41" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"NaNs detected in predict_prod"</span>)</span>
<span id="cb74-42"><a href="#cb74-42" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"predict_prod:"</span>, predict_prod)</span>
<span id="cb74-43"><a href="#cb74-43" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"NaNs detected in predict_prod"</span>)</span>
<span id="cb74-44"><a href="#cb74-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-45"><a href="#cb74-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Normalise the next-step log-densities using the log-sum-exp trick</span></span>
<span id="cb74-46"><a href="#cb74-46" aria-hidden="true" tabindex="-1"></a>        predict_prod <span class="op">=</span> predict_prod <span class="op">-</span> torch.logsumexp(predict_prod, dim <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>), keepdim <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb74-47"><a href="#cb74-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-48"><a href="#cb74-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute negative log-likelihood by multiplying log-densities with target</span></span>
<span id="cb74-49"><a href="#cb74-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># and then flipping the sign</span></span>
<span id="cb74-50"><a href="#cb74-50" aria-hidden="true" tabindex="-1"></a>        negLogLike <span class="op">=</span> <span class="op">-</span><span class="dv">1</span> <span class="op">*</span> (predict_prod <span class="op">*</span> target)</span>
<span id="cb74-51"><a href="#cb74-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-52"><a href="#cb74-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check for NaNs after computing negative log-likelihood</span></span>
<span id="cb74-53"><a href="#cb74-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> torch.isnan(negLogLike).<span class="bu">any</span>():</span>
<span id="cb74-54"><a href="#cb74-54" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"NaNs detected in negLogLike"</span>)</span>
<span id="cb74-55"><a href="#cb74-55" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"negLogLike:"</span>, negLogLike)</span>
<span id="cb74-56"><a href="#cb74-56" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"NaNs detected in negLogLike"</span>)</span>
<span id="cb74-57"><a href="#cb74-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-58"><a href="#cb74-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply the specified reduction</span></span>
<span id="cb74-59"><a href="#cb74-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.reduction <span class="op">==</span> <span class="st">'mean'</span>:</span>
<span id="cb74-60"><a href="#cb74-60" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> torch.mean(negLogLike)</span>
<span id="cb74-61"><a href="#cb74-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="va">self</span>.reduction <span class="op">==</span> <span class="st">'sum'</span>:</span>
<span id="cb74-62"><a href="#cb74-62" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> torch.<span class="bu">sum</span>(negLogLike)</span>
<span id="cb74-63"><a href="#cb74-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="va">self</span>.reduction <span class="op">==</span> <span class="st">'none'</span>:</span>
<span id="cb74-64"><a href="#cb74-64" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> negLogLike</span>
<span id="cb74-65"><a href="#cb74-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-66"><a href="#cb74-66" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Default return (though it should never reach here without hitting an if)</span></span>
<span id="cb74-67"><a href="#cb74-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> negLogLike</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="early-stopping-code" class="level2">
<h2 class="anchored" data-anchor-id="early-stopping-code">Early stopping code</h2>
<p>This code will be used to stop training if the validation loss does not improve after a certain number of epochs.</p>
<p>When the loss of the validation data (which is held out from the training data) decreases (i.e.&nbsp;the model improves), the model weights are saved. Each time the validation loss does not decrease, a counter is incremented. If the counter reaches the patience value, the training loop will break and the model will stop training. The â€˜finalâ€™ model is then the model that had the lowest validation loss.</p>
<p>We have saved this code in a script called <code>deepSSF_early_stopping.py</code> so that we can import it into future scripts.</p>
<div id="cell-102" class="cell" data-execution_count="51">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EarlyStopping:</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, patience<span class="op">=</span><span class="dv">5</span>, verbose<span class="op">=</span><span class="va">False</span>, delta<span class="op">=</span><span class="dv">0</span>, path<span class="op">=</span><span class="st">'checkpoint.pt'</span>, trace_func<span class="op">=</span><span class="bu">print</span>):</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a><span class="co">            patience (int): How long to wait after last time validation loss improved.</span></span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a><span class="co">                            Default: 5</span></span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a><span class="co">            verbose (bool): If True, prints a message for each validation loss improvement.</span></span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a><span class="co">                            Default: False</span></span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a><span class="co">            delta (float): Minimum change in the monitored quantity to qualify as an improvement.</span></span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a><span class="co">                            Default: 0</span></span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a><span class="co">            path (str): Path for the checkpoint to be saved to.</span></span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a><span class="co">                            Default: 'checkpoint.pt'</span></span>
<span id="cb75-13"><a href="#cb75-13" aria-hidden="true" tabindex="-1"></a><span class="co">            trace_func (function): trace print function.</span></span>
<span id="cb75-14"><a href="#cb75-14" aria-hidden="true" tabindex="-1"></a><span class="co">                            Default: print</span></span>
<span id="cb75-15"><a href="#cb75-15" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb75-16"><a href="#cb75-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb75-17"><a href="#cb75-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.patience <span class="op">=</span> patience</span>
<span id="cb75-18"><a href="#cb75-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.verbose <span class="op">=</span> verbose</span>
<span id="cb75-19"><a href="#cb75-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb75-20"><a href="#cb75-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.best_score <span class="op">=</span> <span class="va">None</span></span>
<span id="cb75-21"><a href="#cb75-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.early_stop <span class="op">=</span> <span class="va">False</span></span>
<span id="cb75-22"><a href="#cb75-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.val_loss_min <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb75-23"><a href="#cb75-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.delta <span class="op">=</span> delta</span>
<span id="cb75-24"><a href="#cb75-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.path <span class="op">=</span> path</span>
<span id="cb75-25"><a href="#cb75-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.trace_func <span class="op">=</span> trace_func</span>
<span id="cb75-26"><a href="#cb75-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-27"><a href="#cb75-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, val_loss, model):</span>
<span id="cb75-28"><a href="#cb75-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-29"><a href="#cb75-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># takes the validation loss and the model as inputs</span></span>
<span id="cb75-30"><a href="#cb75-30" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> <span class="op">-</span>val_loss</span>
<span id="cb75-31"><a href="#cb75-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-32"><a href="#cb75-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># save the model's weights if the validation loss decreases</span></span>
<span id="cb75-33"><a href="#cb75-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.best_score <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb75-34"><a href="#cb75-34" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.best_score <span class="op">=</span> score</span>
<span id="cb75-35"><a href="#cb75-35" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.save_checkpoint(val_loss, model)</span>
<span id="cb75-36"><a href="#cb75-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-37"><a href="#cb75-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># if the validation loss does not decrease, increment the counter</span></span>
<span id="cb75-38"><a href="#cb75-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> score <span class="op">&lt;</span> <span class="va">self</span>.best_score <span class="op">+</span> <span class="va">self</span>.delta:</span>
<span id="cb75-39"><a href="#cb75-39" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.counter <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb75-40"><a href="#cb75-40" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.trace_func(<span class="ss">f'EarlyStopping counter: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>counter<span class="sc">}</span><span class="ss"> out of </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>patience<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb75-41"><a href="#cb75-41" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.counter <span class="op">&gt;=</span> <span class="va">self</span>.patience:</span>
<span id="cb75-42"><a href="#cb75-42" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.early_stop <span class="op">=</span> <span class="va">True</span></span>
<span id="cb75-43"><a href="#cb75-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb75-44"><a href="#cb75-44" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.best_score <span class="op">=</span> score</span>
<span id="cb75-45"><a href="#cb75-45" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.save_checkpoint(val_loss, model)</span>
<span id="cb75-46"><a href="#cb75-46" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb75-47"><a href="#cb75-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-48"><a href="#cb75-48" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> save_checkpoint(<span class="va">self</span>, val_loss, model):</span>
<span id="cb75-49"><a href="#cb75-49" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''Saves model when validation loss decrease.'''</span></span>
<span id="cb75-50"><a href="#cb75-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.verbose:</span>
<span id="cb75-51"><a href="#cb75-51" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.trace_func(<span class="ss">f'Validation loss decreased (</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>val_loss_min<span class="sc">:.6f}</span><span class="ss"> --&gt; </span><span class="sc">{</span>val_loss<span class="sc">:.6f}</span><span class="ss">).  Saving model ...'</span>)</span>
<span id="cb75-52"><a href="#cb75-52" aria-hidden="true" tabindex="-1"></a>        torch.save(model.state_dict(), <span class="va">self</span>.path)</span>
<span id="cb75-53"><a href="#cb75-53" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.val_loss_min <span class="op">=</span> val_loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="set-the-learning-rate" class="level2">
<h2 class="anchored" data-anchor-id="set-the-learning-rate">Set the learning rate</h2>
<p>The learning rate is a hyperparameter that controls how much we are adjusting the weights of our network with respect to the loss gradient. A larger learning rate means that the optimiser will take larger steps, but it may overshoot the minimum. A smaller learning rate means that the optimiser will take smaller steps, but it may take a long time to converge.</p>
<p>We can therefore use an adaptive learning rate, which will adjust the learning rate during training. If the loss does not decrease after a certain number of epochs (also called the patience), the learning rate will be reduced by a factor of 10.</p>
<p>The patience of the learning rate should be less than the patience of the early stopping code, as we want to reduce the learning rate before we stop training.</p>
<div id="cell-104" class="cell" data-execution_count="52">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">1e-4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="path-to-save-the-model-weights" class="level3">
<h3 class="anchored" data-anchor-id="path-to-save-the-model-weights">Path to save the model weights</h3>
<div id="cell-106" class="cell" data-execution_count="53">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>path_save_weights <span class="op">=</span> <span class="ss">f'model_checkpoints/checkpoint_CNN_buffalo</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>today_date<span class="sc">}</span><span class="ss">.pt'</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(path_save_weights)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>model_checkpoints/checkpoint_CNN_buffalo2005_2025-02-04.pt</code></pre>
</div>
</div>
</section>
</section>
<section id="instantiate-the-loss-function-optimiser-learning-rate-scheduler-and-early-stopping-code" class="level2">
<h2 class="anchored" data-anchor-id="instantiate-the-loss-function-optimiser-learning-rate-scheduler-and-early-stopping-code">Instantiate the loss function, optimiser, learning rate scheduler and early stopping code</h2>
<p>In this chunk, we set up all the components needed for training and validating a neural network model:</p>
<ol type="1">
<li>Loss Function: Uses a negative log-likelihood loss (negativeLogLikeLoss) with mean reduction.</li>
<li>Optimizer: Implements the Adam optimization algorithm, updating model parameters based on the computed gradients and a specified learning rate.</li>
<li>Scheduler: Automatically reduces the learning rate when the monitored metric (e.g., validation loss) stops improving.</li>
<li>Early Stopping: Monitors validation performance and stops training if the metric fails to improve after a certain number of epochs (patience).</li>
</ol>
<div id="cell-108" class="cell">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the negative log-likelihood loss function with mean reduction</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> negativeLogLikeLoss(reduction<span class="op">=</span><span class="st">'mean'</span>)</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up the Adam optimizer for updating the model's parameters</span></span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>optimiser <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a learning rate scheduler that reduces the LR by a factor of 0.1 </span></span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a><span class="co">#    if validation loss has not improved for 'patience=5' epochs</span></span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>scheduler <span class="op">=</span> torch.optim.lr_scheduler.ReduceLROnPlateau(</span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a>    optimiser,  <span class="co"># The optimizer whose learning rate will be adjusted</span></span>
<span id="cb79-11"><a href="#cb79-11" aria-hidden="true" tabindex="-1"></a>    mode<span class="op">=</span><span class="st">'min'</span>, <span class="co"># The metric to be minimized (e.g., validation loss)</span></span>
<span id="cb79-12"><a href="#cb79-12" aria-hidden="true" tabindex="-1"></a>    factor<span class="op">=</span><span class="fl">0.1</span>, <span class="co"># Factor by which the learning rate will be reduced</span></span>
<span id="cb79-13"><a href="#cb79-13" aria-hidden="true" tabindex="-1"></a>    patience<span class="op">=</span><span class="dv">3</span>  <span class="co"># Number of epochs with no improvement before learning rate reduces</span></span>
<span id="cb79-14"><a href="#cb79-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb79-15"><a href="#cb79-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-16"><a href="#cb79-16" aria-hidden="true" tabindex="-1"></a><span class="co"># EarlyStopping stops training after 'patience=10' epochs with no improvement, </span></span>
<span id="cb79-17"><a href="#cb79-17" aria-hidden="true" tabindex="-1"></a><span class="co">#    optionally saving the best model weights</span></span>
<span id="cb79-18"><a href="#cb79-18" aria-hidden="true" tabindex="-1"></a>early_stopping <span class="op">=</span> EarlyStopping(patience<span class="op">=</span><span class="dv">10</span>, verbose<span class="op">=</span><span class="va">True</span>, path<span class="op">=</span>path_save_weights)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="training-loop" class="level2">
<h2 class="anchored" data-anchor-id="training-loop">Training loop</h2>
<p>This code defines the main training loop for a single epoch. It iterates over batches from the training dataloader, moves the data to the correct device (e.g., CPU or GPU), calculates the loss, and performs backpropagation to update the model parameters. It also prints periodic updates of the current loss.</p>
<div id="cell-110" class="cell">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_loop(dataloader_train, model, loss_fn, optimiser):</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Runs the training process for one epoch using the given dataloader, model, </span></span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a><span class="co">    loss function, and optimizer. Prints progress updates every few batches.</span></span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Total number of training examples</span></span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a>    size <span class="op">=</span> <span class="bu">len</span>(dataloader_train.dataset)</span>
<span id="cb80-9"><a href="#cb80-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-10"><a href="#cb80-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Put model in training mode (affects layers like dropout, batchnorm)</span></span>
<span id="cb80-11"><a href="#cb80-11" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb80-12"><a href="#cb80-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-13"><a href="#cb80-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Variable to accumulate the total loss over the epoch</span></span>
<span id="cb80-14"><a href="#cb80-14" aria-hidden="true" tabindex="-1"></a>    epoch_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb80-15"><a href="#cb80-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-16"><a href="#cb80-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4. Loop over batches in the training dataloader</span></span>
<span id="cb80-17"><a href="#cb80-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch, (x1, x2, x3, y) <span class="kw">in</span> <span class="bu">enumerate</span>(dataloader_train):</span>
<span id="cb80-18"><a href="#cb80-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-19"><a href="#cb80-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Move the batch of data to the specified device (CPU/GPU)</span></span>
<span id="cb80-20"><a href="#cb80-20" aria-hidden="true" tabindex="-1"></a>        x1 <span class="op">=</span> x1.to(device)</span>
<span id="cb80-21"><a href="#cb80-21" aria-hidden="true" tabindex="-1"></a>        x2 <span class="op">=</span> x2.to(device)</span>
<span id="cb80-22"><a href="#cb80-22" aria-hidden="true" tabindex="-1"></a>        x3 <span class="op">=</span> x3.to(device)</span>
<span id="cb80-23"><a href="#cb80-23" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> y.to(device)</span>
<span id="cb80-24"><a href="#cb80-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-25"><a href="#cb80-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Forward pass: compute the model output and loss</span></span>
<span id="cb80-26"><a href="#cb80-26" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_fn(model((x1, x2, x3)), y)</span>
<span id="cb80-27"><a href="#cb80-27" aria-hidden="true" tabindex="-1"></a>        epoch_loss <span class="op">+=</span> loss</span>
<span id="cb80-28"><a href="#cb80-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-29"><a href="#cb80-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Backpropagation: compute gradients and update parameters</span></span>
<span id="cb80-30"><a href="#cb80-30" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb80-31"><a href="#cb80-31" aria-hidden="true" tabindex="-1"></a>        optimiser.step()</span>
<span id="cb80-32"><a href="#cb80-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-33"><a href="#cb80-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Reset gradients before the next iteration</span></span>
<span id="cb80-34"><a href="#cb80-34" aria-hidden="true" tabindex="-1"></a>        optimiser.zero_grad()</span>
<span id="cb80-35"><a href="#cb80-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-36"><a href="#cb80-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print an update every 5 batches to keep track of training progress</span></span>
<span id="cb80-37"><a href="#cb80-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> batch <span class="op">%</span> <span class="dv">5</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb80-38"><a href="#cb80-38" aria-hidden="true" tabindex="-1"></a>            loss_val <span class="op">=</span> loss.item()</span>
<span id="cb80-39"><a href="#cb80-39" aria-hidden="true" tabindex="-1"></a>            current <span class="op">=</span> batch <span class="op">*</span> bs <span class="op">+</span> <span class="bu">len</span>(x1)</span>
<span id="cb80-40"><a href="#cb80-40" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"loss: </span><span class="sc">{</span>loss_val<span class="sc">:&gt;15f}</span><span class="ss">  [</span><span class="sc">{</span>current<span class="sc">:&gt;5d}</span><span class="ss">/</span><span class="sc">{</span>size<span class="sc">:&gt;5d}</span><span class="ss">]"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="test-loop" class="level2">
<h2 class="anchored" data-anchor-id="test-loop">Test loop</h2>
<p>The test loop is similar to the training loop, but it does not perform backpropagation. It calculates the loss on the test set and returns the average loss.</p>
<div id="cell-112" class="cell">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_loop(dataloader_test, model, loss_fn):</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Evaluates the model on the provided test dataset by computing </span></span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a><span class="co">    the average loss over all batches. </span></span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a><span class="co">    No gradients are computed during this process (torch.no_grad()).</span></span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Set the model to evaluation mode (affects layers like dropout, batchnorm).</span></span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb81-10"><a href="#cb81-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-11"><a href="#cb81-11" aria-hidden="true" tabindex="-1"></a>    size <span class="op">=</span> <span class="bu">len</span>(dataloader_test.dataset)</span>
<span id="cb81-12"><a href="#cb81-12" aria-hidden="true" tabindex="-1"></a>    num_batches <span class="op">=</span> <span class="bu">len</span>(dataloader_test)</span>
<span id="cb81-13"><a href="#cb81-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb81-14"><a href="#cb81-14" aria-hidden="true" tabindex="-1"></a>    test_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb81-15"><a href="#cb81-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-16"><a href="#cb81-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Disable gradient computation to speed up evaluation and reduce memory usage</span></span>
<span id="cb81-17"><a href="#cb81-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb81-18"><a href="#cb81-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 3. Loop through each batch in the test dataloader</span></span>
<span id="cb81-19"><a href="#cb81-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> x1, x2, x3, y <span class="kw">in</span> dataloader_test:</span>
<span id="cb81-20"><a href="#cb81-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-21"><a href="#cb81-21" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Move the batch of data to the appropriate device (CPU/GPU)</span></span>
<span id="cb81-22"><a href="#cb81-22" aria-hidden="true" tabindex="-1"></a>            x1 <span class="op">=</span> x1.to(device)</span>
<span id="cb81-23"><a href="#cb81-23" aria-hidden="true" tabindex="-1"></a>            x2 <span class="op">=</span> x2.to(device)</span>
<span id="cb81-24"><a href="#cb81-24" aria-hidden="true" tabindex="-1"></a>            x3 <span class="op">=</span> x3.to(device)</span>
<span id="cb81-25"><a href="#cb81-25" aria-hidden="true" tabindex="-1"></a>            y <span class="op">=</span> y.to(device)</span>
<span id="cb81-26"><a href="#cb81-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-27"><a href="#cb81-27" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute the loss on the test set (no backward pass needed)</span></span>
<span id="cb81-28"><a href="#cb81-28" aria-hidden="true" tabindex="-1"></a>            test_loss <span class="op">+=</span> loss_fn(model((x1, x2, x3)), y)</span>
<span id="cb81-29"><a href="#cb81-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-30"><a href="#cb81-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4. Compute average test loss over all batches</span></span>
<span id="cb81-31"><a href="#cb81-31" aria-hidden="true" tabindex="-1"></a>    test_loss <span class="op">/=</span> num_batches</span>
<span id="cb81-32"><a href="#cb81-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-33"><a href="#cb81-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print the average test loss</span></span>
<span id="cb81-34"><a href="#cb81-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Avg test loss: </span><span class="sc">{</span>test_loss<span class="sc">:&gt;15f}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="train-the-model" class="level1">
<h1>Train the model</h1>
<p>Here we have the main training process that loops over multiple epochs. Each epoch involves:</p>
<ol type="1">
<li>Training the model on a training dataset.</li>
<li>Validating the model on a validation dataset to monitor its performance and adjust the learning rate (via scheduler).</li>
<li>Checking for early stopping conditions. If triggered, the best model weights are restored, and a test evaluation is performed.</li>
</ol>
<p>Additionally, commented-out code at the end shows how you might visualise and save intermediate training results (such as predicted probability surfaces) for diagnostic or research purposes. The saved images can then be combined into an animation.</p>
<div id="cell-114" class="cell" data-outputid="a6d9ba93-8dec-4b4c-cc4d-f89f5b25c6b4">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>val_losses <span class="op">=</span> []   <span class="co"># Track validation losses across epochs</span></span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>    val_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>    num_batches <span class="op">=</span> <span class="bu">len</span>(dataloader_test)</span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>t<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ch">\n</span><span class="ss">-------------------------------"</span>)</span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-10"><a href="#cb82-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Run the training loop for one epoch using the training dataloader</span></span>
<span id="cb82-11"><a href="#cb82-11" aria-hidden="true" tabindex="-1"></a>    train_loop(dataloader_train, model, loss_fn, optimiser)</span>
<span id="cb82-12"><a href="#cb82-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-13"><a href="#cb82-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Evaluate model performance on the validation dataset</span></span>
<span id="cb82-14"><a href="#cb82-14" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()  <span class="co"># Switch to evaluation mode for proper layer behavior</span></span>
<span id="cb82-15"><a href="#cb82-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb82-16"><a href="#cb82-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb82-17"><a href="#cb82-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> x1, x2, x3, y <span class="kw">in</span> dataloader_val:</span>
<span id="cb82-18"><a href="#cb82-18" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Move data to the chosen device (CPU/GPU)</span></span>
<span id="cb82-19"><a href="#cb82-19" aria-hidden="true" tabindex="-1"></a>            x1 <span class="op">=</span> x1.to(device)</span>
<span id="cb82-20"><a href="#cb82-20" aria-hidden="true" tabindex="-1"></a>            x2 <span class="op">=</span> x2.to(device)</span>
<span id="cb82-21"><a href="#cb82-21" aria-hidden="true" tabindex="-1"></a>            x3 <span class="op">=</span> x3.to(device)</span>
<span id="cb82-22"><a href="#cb82-22" aria-hidden="true" tabindex="-1"></a>            y <span class="op">=</span> y.to(device)</span>
<span id="cb82-23"><a href="#cb82-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-24"><a href="#cb82-24" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Accumulate validation loss</span></span>
<span id="cb82-25"><a href="#cb82-25" aria-hidden="true" tabindex="-1"></a>            val_loss <span class="op">+=</span> loss_fn(model((x1, x2, x3)), y)</span>
<span id="cb82-26"><a href="#cb82-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-27"><a href="#cb82-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Step the scheduler based on the validation loss (adjusts learning rate if needed)</span></span>
<span id="cb82-28"><a href="#cb82-28" aria-hidden="true" tabindex="-1"></a>    scheduler.step(val_loss)</span>
<span id="cb82-29"><a href="#cb82-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-30"><a href="#cb82-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4. Compute the average validation loss and print it, along with the current learning rate</span></span>
<span id="cb82-31"><a href="#cb82-31" aria-hidden="true" tabindex="-1"></a>    val_loss <span class="op">/=</span> num_batches</span>
<span id="cb82-32"><a href="#cb82-32" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Avg validation loss: </span><span class="sc">{</span>val_loss<span class="sc">:&gt;15f}</span><span class="ss">"</span>)</span>
<span id="cb82-33"><a href="#cb82-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Learning rate: </span><span class="sc">{</span>scheduler<span class="sc">.</span>get_last_lr()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb82-34"><a href="#cb82-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-35"><a href="#cb82-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 5. Track the validation loss for plotting or monitoring</span></span>
<span id="cb82-36"><a href="#cb82-36" aria-hidden="true" tabindex="-1"></a>    val_losses.append(val_loss)</span>
<span id="cb82-37"><a href="#cb82-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-38"><a href="#cb82-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 6. Early stopping: if no improvement in validation loss for a set patience, stop training</span></span>
<span id="cb82-39"><a href="#cb82-39" aria-hidden="true" tabindex="-1"></a>    early_stopping(val_loss, model)</span>
<span id="cb82-40"><a href="#cb82-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> early_stopping.early_stop:</span>
<span id="cb82-41"><a href="#cb82-41" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Early stopping"</span>)</span>
<span id="cb82-42"><a href="#cb82-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Restore the best model weights saved by EarlyStopping</span></span>
<span id="cb82-43"><a href="#cb82-43" aria-hidden="true" tabindex="-1"></a>        model.load_state_dict(torch.load(path_save_weights, weights_only<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb82-44"><a href="#cb82-44" aria-hidden="true" tabindex="-1"></a>        test_loop(dataloader_test, model, loss_fn)  <span class="co"># Evaluate on test set once training stops</span></span>
<span id="cb82-45"><a href="#cb82-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb82-46"><a href="#cb82-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb82-47"><a href="#cb82-47" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb82-48"><a href="#cb82-48" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb82-49"><a href="#cb82-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-50"><a href="#cb82-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-51"><a href="#cb82-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # ----------------------------------------------------</span></span>
<span id="cb82-52"><a href="#cb82-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # The following code demonstrates how </span></span>
<span id="cb82-53"><a href="#cb82-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # to optionally visualize or save intermediate results </span></span>
<span id="cb82-54"><a href="#cb82-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # (e.g., habitat probability surface, movement probability,</span></span>
<span id="cb82-55"><a href="#cb82-55" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # and next-step probability surfaces).</span></span>
<span id="cb82-56"><a href="#cb82-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-57"><a href="#cb82-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # uncomment the code all in one go to run it (it should be inside the training loop)</span></span>
<span id="cb82-58"><a href="#cb82-58" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # ----------------------------------------------------</span></span>
<span id="cb82-59"><a href="#cb82-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-60"><a href="#cb82-60" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # -----------------------------------------------------------</span></span>
<span id="cb82-61"><a href="#cb82-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # 1. Retrieve a single test example (covariates and labels) </span></span>
<span id="cb82-62"><a href="#cb82-62" aria-hidden="true" tabindex="-1"></a>    <span class="co"># #    at the specified 'iteration_index' from the test dataset</span></span>
<span id="cb82-63"><a href="#cb82-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # -----------------------------------------------------------</span></span>
<span id="cb82-64"><a href="#cb82-64" aria-hidden="true" tabindex="-1"></a>    <span class="co"># x1, x2, x3, labels = dataloader_test.dataset[iteration_index]</span></span>
<span id="cb82-65"><a href="#cb82-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-66"><a href="#cb82-66" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # -----------------------------------------------------------</span></span>
<span id="cb82-67"><a href="#cb82-67" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # 2. Add a batch dimension and move tensors to the device </span></span>
<span id="cb82-68"><a href="#cb82-68" aria-hidden="true" tabindex="-1"></a>    <span class="co"># #    for model inference</span></span>
<span id="cb82-69"><a href="#cb82-69" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # -----------------------------------------------------------</span></span>
<span id="cb82-70"><a href="#cb82-70" aria-hidden="true" tabindex="-1"></a>    <span class="co"># x1 = x1.unsqueeze(0).to(device)</span></span>
<span id="cb82-71"><a href="#cb82-71" aria-hidden="true" tabindex="-1"></a>    <span class="co"># x2 = x2.unsqueeze(0).to(device)</span></span>
<span id="cb82-72"><a href="#cb82-72" aria-hidden="true" tabindex="-1"></a>    <span class="co"># x3 = x3.unsqueeze(0).to(device)</span></span>
<span id="cb82-73"><a href="#cb82-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-74"><a href="#cb82-74" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # -----------------------------------------------------------</span></span>
<span id="cb82-75"><a href="#cb82-75" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # 3. Run the model on the single test example</span></span>
<span id="cb82-76"><a href="#cb82-76" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # -----------------------------------------------------------</span></span>
<span id="cb82-77"><a href="#cb82-77" aria-hidden="true" tabindex="-1"></a>    <span class="co"># test = model((x1, x2, x3))</span></span>
<span id="cb82-78"><a href="#cb82-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-79"><a href="#cb82-79" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # -----------------------------------------------------------</span></span>
<span id="cb82-80"><a href="#cb82-80" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # 4. Extract habitat and movement outputs; </span></span>
<span id="cb82-81"><a href="#cb82-81" aria-hidden="true" tabindex="-1"></a>    <span class="co"># #    convert them to NumPy arrays for visualization</span></span>
<span id="cb82-82"><a href="#cb82-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # -----------------------------------------------------------</span></span>
<span id="cb82-83"><a href="#cb82-83" aria-hidden="true" tabindex="-1"></a>    <span class="co"># hab_density = test.detach().cpu().numpy()[0, :, :, 0]</span></span>
<span id="cb82-84"><a href="#cb82-84" aria-hidden="true" tabindex="-1"></a>    <span class="co"># movement_density = test.detach().cpu().numpy()[0, :, :, 1]</span></span>
<span id="cb82-85"><a href="#cb82-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-86"><a href="#cb82-86" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # -----------------------------------------------------------</span></span>
<span id="cb82-87"><a href="#cb82-87" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # 5. Generate masks to exclude certain border cells for </span></span>
<span id="cb82-88"><a href="#cb82-88" aria-hidden="true" tabindex="-1"></a>    <span class="co"># #    color scale reasons (setting them to -inf).</span></span>
<span id="cb82-89"><a href="#cb82-89" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # -----------------------------------------------------------</span></span>
<span id="cb82-90"><a href="#cb82-90" aria-hidden="true" tabindex="-1"></a>    <span class="co"># x_mask = np.ones_like(hab_density)</span></span>
<span id="cb82-91"><a href="#cb82-91" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y_mask = np.ones_like(hab_density)</span></span>
<span id="cb82-92"><a href="#cb82-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-93"><a href="#cb82-93" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # Mask out a few columns (0-2 and 98-end) and rows (0-2 and 98-end)</span></span>
<span id="cb82-94"><a href="#cb82-94" aria-hidden="true" tabindex="-1"></a>    <span class="co"># x_mask[:, :3] = -np.inf</span></span>
<span id="cb82-95"><a href="#cb82-95" aria-hidden="true" tabindex="-1"></a>    <span class="co"># x_mask[:, 98:] = -np.inf</span></span>
<span id="cb82-96"><a href="#cb82-96" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y_mask[:3, :] = -np.inf</span></span>
<span id="cb82-97"><a href="#cb82-97" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y_mask[98:, :] = -np.inf</span></span>
<span id="cb82-98"><a href="#cb82-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-99"><a href="#cb82-99" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # Apply the masks to habitat density</span></span>
<span id="cb82-100"><a href="#cb82-100" aria-hidden="true" tabindex="-1"></a>    <span class="co"># hab_density_mask = hab_density * x_mask * y_mask</span></span>
<span id="cb82-101"><a href="#cb82-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-102"><a href="#cb82-102" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # Combine habitat and movement densities to represent </span></span>
<span id="cb82-103"><a href="#cb82-103" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # next-step probability</span></span>
<span id="cb82-104"><a href="#cb82-104" aria-hidden="true" tabindex="-1"></a>    <span class="co"># step_density = hab_density + movement_density</span></span>
<span id="cb82-105"><a href="#cb82-105" aria-hidden="true" tabindex="-1"></a>    <span class="co"># step_density_mask = step_density * x_mask * y_mask</span></span>
<span id="cb82-106"><a href="#cb82-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-107"><a href="#cb82-107" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # -----------------------------------------------------------</span></span>
<span id="cb82-108"><a href="#cb82-108" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # 6. Plot and save the habitat probability surface</span></span>
<span id="cb82-109"><a href="#cb82-109" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # -----------------------------------------------------------</span></span>
<span id="cb82-110"><a href="#cb82-110" aria-hidden="true" tabindex="-1"></a>    <span class="co"># filename_hab = f'outputs/model_training_local/hab_log_prob_covs_id{buffalo_id}_yday{yday_t2_integer}_hour{hour_t2_integer}_bearing{bearing_degrees}_next_r{row}_c{column}_{today_date}_epoch{t}.png'</span></span>
<span id="cb82-111"><a href="#cb82-111" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.figure()</span></span>
<span id="cb82-112"><a href="#cb82-112" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.imshow(hab_density_mask)</span></span>
<span id="cb82-113"><a href="#cb82-113" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.colorbar()</span></span>
<span id="cb82-114"><a href="#cb82-114" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.draw()  # Render the plot before saving</span></span>
<span id="cb82-115"><a href="#cb82-115" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.savefig(filename_hab, dpi=600, bbox_inches='tight')</span></span>
<span id="cb82-116"><a href="#cb82-116" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.close()  # Close the figure to free memory</span></span>
<span id="cb82-117"><a href="#cb82-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-118"><a href="#cb82-118" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # -----------------------------------------------------------</span></span>
<span id="cb82-119"><a href="#cb82-119" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # 7. Plot and save the movement probability surface</span></span>
<span id="cb82-120"><a href="#cb82-120" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # -----------------------------------------------------------</span></span>
<span id="cb82-121"><a href="#cb82-121" aria-hidden="true" tabindex="-1"></a>    <span class="co"># filename_move = f'outputs/model_training_local/move_log_prob_covs_id{buffalo_id}_yday{yday_t2_integer}_hour{hour_t2_integer}_bearing{bearing_degrees}_next_r{row}_c{column}_{today_date}_epoch{t}.png'</span></span>
<span id="cb82-122"><a href="#cb82-122" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.figure()</span></span>
<span id="cb82-123"><a href="#cb82-123" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.imshow(movement_density)</span></span>
<span id="cb82-124"><a href="#cb82-124" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.colorbar()</span></span>
<span id="cb82-125"><a href="#cb82-125" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.draw()</span></span>
<span id="cb82-126"><a href="#cb82-126" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.savefig(filename_move, dpi=600, bbox_inches='tight')</span></span>
<span id="cb82-127"><a href="#cb82-127" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.close()</span></span>
<span id="cb82-128"><a href="#cb82-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-129"><a href="#cb82-129" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # -----------------------------------------------------------</span></span>
<span id="cb82-130"><a href="#cb82-130" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # 8. Plot and save the combined (next-step) probability surface</span></span>
<span id="cb82-131"><a href="#cb82-131" aria-hidden="true" tabindex="-1"></a>    <span class="co"># # -----------------------------------------------------------</span></span>
<span id="cb82-132"><a href="#cb82-132" aria-hidden="true" tabindex="-1"></a>    <span class="co"># filename_step = f'outputs/model_training_local/step_log_prob_covs_id{buffalo_id}_yday{yday_t2_integer}_hour{hour_t2_integer}_bearing{bearing_degrees}_next_r{row}_c{column}_{today_date}_epoch{t}.png'</span></span>
<span id="cb82-133"><a href="#cb82-133" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.figure()</span></span>
<span id="cb82-134"><a href="#cb82-134" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.imshow(step_density_mask)</span></span>
<span id="cb82-135"><a href="#cb82-135" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.colorbar()</span></span>
<span id="cb82-136"><a href="#cb82-136" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.draw()</span></span>
<span id="cb82-137"><a href="#cb82-137" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.savefig(filename_step, dpi=600, bbox_inches='tight')</span></span>
<span id="cb82-138"><a href="#cb82-138" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.close()</span></span>
<span id="cb82-139"><a href="#cb82-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-140"><a href="#cb82-140" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Done!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1
-------------------------------
loss:        0.000780  [   32/ 8083]
loss:        0.000759  [  192/ 8083]
loss:        0.000739  [  352/ 8083]
loss:        0.000735  [  512/ 8083]
loss:        0.000717  [  672/ 8083]
loss:        0.000703  [  832/ 8083]
loss:        0.000679  [  992/ 8083]
loss:        0.000691  [ 1152/ 8083]
loss:        0.000584  [ 1312/ 8083]
loss:        0.000592  [ 1472/ 8083]
loss:        0.000686  [ 1632/ 8083]
loss:        0.000615  [ 1792/ 8083]
loss:        0.000607  [ 1952/ 8083]
loss:        0.000618  [ 2112/ 8083]
loss:        0.000582  [ 2272/ 8083]
loss:        0.000623  [ 2432/ 8083]
loss:        0.000636  [ 2592/ 8083]
loss:        0.000552  [ 2752/ 8083]
loss:        0.000595  [ 2912/ 8083]
loss:        0.000602  [ 3072/ 8083]
loss:        0.000639  [ 3232/ 8083]
loss:        0.000537  [ 3392/ 8083]
loss:        0.000568  [ 3552/ 8083]
loss:        0.000587  [ 3712/ 8083]
loss:        0.000514  [ 3872/ 8083]
loss:        0.000528  [ 4032/ 8083]
loss:        0.000573  [ 4192/ 8083]
loss:        0.000504  [ 4352/ 8083]
loss:        0.000547  [ 4512/ 8083]
loss:        0.000556  [ 4672/ 8083]
loss:        0.000601  [ 4832/ 8083]
loss:        0.000476  [ 4992/ 8083]
loss:        0.000562  [ 5152/ 8083]
loss:        0.000528  [ 5312/ 8083]
loss:        0.000569  [ 5472/ 8083]
loss:        0.000570  [ 5632/ 8083]
loss:        0.000574  [ 5792/ 8083]
loss:        0.000506  [ 5952/ 8083]
loss:        0.000673  [ 6112/ 8083]
loss:        0.000609  [ 6272/ 8083]
loss:        0.000490  [ 6432/ 8083]
loss:        0.000640  [ 6592/ 8083]
loss:        0.000590  [ 6752/ 8083]
loss:        0.000652  [ 6912/ 8083]
loss:        0.000576  [ 7072/ 8083]
loss:        0.000470  [ 7232/ 8083]
loss:        0.000514  [ 7392/ 8083]
loss:        0.000588  [ 7552/ 8083]
loss:        0.000658  [ 7712/ 8083]
loss:        0.000515  [ 7872/ 8083]
loss:        0.000531  [ 8032/ 8083]

Avg validation loss:        0.000538
Learning rate: [0.0001]
Validation loss decreased (inf --&gt; 0.000538).  Saving model ...


Epoch 2
-------------------------------
loss:        0.000551  [   32/ 8083]
loss:        0.000541  [  192/ 8083]
loss:        0.000505  [  352/ 8083]
loss:        0.000476  [  512/ 8083]
loss:        0.000459  [  672/ 8083]
loss:        0.000577  [  832/ 8083]
loss:        0.000519  [  992/ 8083]
loss:        0.000523  [ 1152/ 8083]
loss:        0.000465  [ 1312/ 8083]
loss:        0.000529  [ 1472/ 8083]
loss:        0.000552  [ 1632/ 8083]
loss:        0.000652  [ 1792/ 8083]
loss:        0.000495  [ 1952/ 8083]
loss:        0.000481  [ 2112/ 8083]
loss:        0.000470  [ 2272/ 8083]
loss:        0.000548  [ 2432/ 8083]
loss:        0.000596  [ 2592/ 8083]
loss:        0.000515  [ 2752/ 8083]
loss:        0.000575  [ 2912/ 8083]
loss:        0.000614  [ 3072/ 8083]
loss:        0.000597  [ 3232/ 8083]
loss:        0.000624  [ 3392/ 8083]
loss:        0.000508  [ 3552/ 8083]
loss:        0.000534  [ 3712/ 8083]
loss:        0.000558  [ 3872/ 8083]
loss:        0.000611  [ 4032/ 8083]
loss:        0.000546  [ 4192/ 8083]
loss:        0.000475  [ 4352/ 8083]
loss:        0.000451  [ 4512/ 8083]
loss:        0.000539  [ 4672/ 8083]
loss:        0.000587  [ 4832/ 8083]
loss:        0.000586  [ 4992/ 8083]
loss:        0.000549  [ 5152/ 8083]
loss:        0.000538  [ 5312/ 8083]
loss:        0.000483  [ 5472/ 8083]
loss:        0.000611  [ 5632/ 8083]
loss:        0.000596  [ 5792/ 8083]
loss:        0.000590  [ 5952/ 8083]
loss:        0.000613  [ 6112/ 8083]
loss:        0.000506  [ 6272/ 8083]
loss:        0.000521  [ 6432/ 8083]
loss:        0.000621  [ 6592/ 8083]
loss:        0.000560  [ 6752/ 8083]
loss:        0.000469  [ 6912/ 8083]
loss:        0.000542  [ 7072/ 8083]
loss:        0.000437  [ 7232/ 8083]
loss:        0.000566  [ 7392/ 8083]
loss:        0.000485  [ 7552/ 8083]
loss:        0.000645  [ 7712/ 8083]
loss:        0.000529  [ 7872/ 8083]
loss:        0.000541  [ 8032/ 8083]

Avg validation loss:        0.000536
Learning rate: [0.0001]
Validation loss decreased (0.000538 --&gt; 0.000536).  Saving model ...


Epoch 3
-------------------------------
loss:        0.000449  [   32/ 8083]
loss:        0.000514  [  192/ 8083]
loss:        0.000549  [  352/ 8083]
loss:        0.000424  [  512/ 8083]
loss:        0.000526  [  672/ 8083]
loss:        0.000496  [  832/ 8083]
loss:        0.000704  [  992/ 8083]
loss:        0.000535  [ 1152/ 8083]
loss:        0.000532  [ 1312/ 8083]
loss:        0.000510  [ 1472/ 8083]
loss:        0.000501  [ 1632/ 8083]
loss:        0.000576  [ 1792/ 8083]
loss:        0.000549  [ 1952/ 8083]
loss:        0.000632  [ 2112/ 8083]
loss:        0.000458  [ 2272/ 8083]
loss:        0.000488  [ 2432/ 8083]
loss:        0.000467  [ 2592/ 8083]
loss:        0.000632  [ 2752/ 8083]
loss:        0.000487  [ 2912/ 8083]
loss:        0.000466  [ 3072/ 8083]
loss:        0.000553  [ 3232/ 8083]
loss:        0.000575  [ 3392/ 8083]
loss:        0.000511  [ 3552/ 8083]
loss:        0.000543  [ 3712/ 8083]
loss:        0.000468  [ 3872/ 8083]
loss:        0.000475  [ 4032/ 8083]
loss:        0.000577  [ 4192/ 8083]
loss:        0.000460  [ 4352/ 8083]
loss:        0.000470  [ 4512/ 8083]
loss:        0.000557  [ 4672/ 8083]
loss:        0.000557  [ 4832/ 8083]
loss:        0.000555  [ 4992/ 8083]
loss:        0.000484  [ 5152/ 8083]
loss:        0.000554  [ 5312/ 8083]
loss:        0.000476  [ 5472/ 8083]
loss:        0.000538  [ 5632/ 8083]
loss:        0.000537  [ 5792/ 8083]
loss:        0.000572  [ 5952/ 8083]
loss:        0.000576  [ 6112/ 8083]
loss:        0.000566  [ 6272/ 8083]
loss:        0.000524  [ 6432/ 8083]
loss:        0.000512  [ 6592/ 8083]
loss:        0.000566  [ 6752/ 8083]
loss:        0.000590  [ 6912/ 8083]
loss:        0.000567  [ 7072/ 8083]
loss:        0.000531  [ 7232/ 8083]
loss:        0.000656  [ 7392/ 8083]
loss:        0.000556  [ 7552/ 8083]
loss:        0.000517  [ 7712/ 8083]
loss:        0.000541  [ 7872/ 8083]
loss:        0.000522  [ 8032/ 8083]

Avg validation loss:        0.000536
Learning rate: [0.0001]
Validation loss decreased (0.000536 --&gt; 0.000536).  Saving model ...


Epoch 4
-------------------------------
loss:        0.000592  [   32/ 8083]
loss:        0.000519  [  192/ 8083]
loss:        0.000507  [  352/ 8083]
loss:        0.000447  [  512/ 8083]
loss:        0.000437  [  672/ 8083]
loss:        0.000507  [  832/ 8083]
loss:        0.000645  [  992/ 8083]
loss:        0.000542  [ 1152/ 8083]
loss:        0.000560  [ 1312/ 8083]
loss:        0.000653  [ 1472/ 8083]
loss:        0.000594  [ 1632/ 8083]
loss:        0.000549  [ 1792/ 8083]
loss:        0.000569  [ 1952/ 8083]
loss:        0.000506  [ 2112/ 8083]
loss:        0.000659  [ 2272/ 8083]
loss:        0.000526  [ 2432/ 8083]
loss:        0.000508  [ 2592/ 8083]
loss:        0.000511  [ 2752/ 8083]
loss:        0.000533  [ 2912/ 8083]
loss:        0.000605  [ 3072/ 8083]
loss:        0.000530  [ 3232/ 8083]
loss:        0.000631  [ 3392/ 8083]
loss:        0.000530  [ 3552/ 8083]
loss:        0.000571  [ 3712/ 8083]
loss:        0.000499  [ 3872/ 8083]
loss:        0.000567  [ 4032/ 8083]
loss:        0.000562  [ 4192/ 8083]
loss:        0.000585  [ 4352/ 8083]
loss:        0.000552  [ 4512/ 8083]
loss:        0.000535  [ 4672/ 8083]
loss:        0.000488  [ 4832/ 8083]
loss:        0.000520  [ 4992/ 8083]
loss:        0.000492  [ 5152/ 8083]
loss:        0.000602  [ 5312/ 8083]
loss:        0.000545  [ 5472/ 8083]
loss:        0.000533  [ 5632/ 8083]
loss:        0.000574  [ 5792/ 8083]
loss:        0.000615  [ 5952/ 8083]
loss:        0.000486  [ 6112/ 8083]
loss:        0.000535  [ 6272/ 8083]
loss:        0.000501  [ 6432/ 8083]
loss:        0.000512  [ 6592/ 8083]
loss:        0.000554  [ 6752/ 8083]
loss:        0.000537  [ 6912/ 8083]
loss:        0.000565  [ 7072/ 8083]
loss:        0.000600  [ 7232/ 8083]
loss:        0.000552  [ 7392/ 8083]
loss:        0.000542  [ 7552/ 8083]
loss:        0.000508  [ 7712/ 8083]
loss:        0.000546  [ 7872/ 8083]
loss:        0.000578  [ 8032/ 8083]

Avg validation loss:        0.000537
Learning rate: [0.0001]
EarlyStopping counter: 1 out of 10


Epoch 5
-------------------------------
loss:        0.000464  [   32/ 8083]
loss:        0.000601  [  192/ 8083]
loss:        0.000457  [  352/ 8083]
loss:        0.000483  [  512/ 8083]
loss:        0.000558  [  672/ 8083]
loss:        0.000507  [  832/ 8083]
loss:        0.000494  [  992/ 8083]
loss:        0.000457  [ 1152/ 8083]
loss:        0.000584  [ 1312/ 8083]
loss:        0.000593  [ 1472/ 8083]
loss:        0.000584  [ 1632/ 8083]
loss:        0.000522  [ 1792/ 8083]
loss:        0.000486  [ 1952/ 8083]
loss:        0.000577  [ 2112/ 8083]
loss:        0.000553  [ 2272/ 8083]
loss:        0.000511  [ 2432/ 8083]
loss:        0.000624  [ 2592/ 8083]
loss:        0.000506  [ 2752/ 8083]
loss:        0.000613  [ 2912/ 8083]
loss:        0.000478  [ 3072/ 8083]
loss:        0.000535  [ 3232/ 8083]
loss:        0.000571  [ 3392/ 8083]
loss:        0.000477  [ 3552/ 8083]
loss:        0.000579  [ 3712/ 8083]
loss:        0.000558  [ 3872/ 8083]
loss:        0.000580  [ 4032/ 8083]
loss:        0.000548  [ 4192/ 8083]
loss:        0.000614  [ 4352/ 8083]
loss:        0.000484  [ 4512/ 8083]
loss:        0.000498  [ 4672/ 8083]
loss:        0.000536  [ 4832/ 8083]
loss:        0.000543  [ 4992/ 8083]
loss:        0.000481  [ 5152/ 8083]
loss:        0.000552  [ 5312/ 8083]
loss:        0.000560  [ 5472/ 8083]
loss:        0.000568  [ 5632/ 8083]
loss:        0.000550  [ 5792/ 8083]
loss:        0.000559  [ 5952/ 8083]
loss:        0.000542  [ 6112/ 8083]
loss:        0.000553  [ 6272/ 8083]
loss:        0.000412  [ 6432/ 8083]
loss:        0.000505  [ 6592/ 8083]
loss:        0.000499  [ 6752/ 8083]
loss:        0.000498  [ 6912/ 8083]
loss:        0.000537  [ 7072/ 8083]
loss:        0.000515  [ 7232/ 8083]
loss:        0.000471  [ 7392/ 8083]
loss:        0.000523  [ 7552/ 8083]
loss:        0.000530  [ 7712/ 8083]
loss:        0.000507  [ 7872/ 8083]
loss:        0.000608  [ 8032/ 8083]

Avg validation loss:        0.000539
Learning rate: [0.0001]
EarlyStopping counter: 2 out of 10


Epoch 6
-------------------------------
loss:        0.000546  [   32/ 8083]
loss:        0.000572  [  192/ 8083]
loss:        0.000507  [  352/ 8083]
loss:        0.000521  [  512/ 8083]
loss:        0.000535  [  672/ 8083]
loss:        0.000493  [  832/ 8083]
loss:        0.000396  [  992/ 8083]
loss:        0.000559  [ 1152/ 8083]
loss:        0.000450  [ 1312/ 8083]
loss:        0.000593  [ 1472/ 8083]
loss:        0.000596  [ 1632/ 8083]
loss:        0.000576  [ 1792/ 8083]
loss:        0.000405  [ 1952/ 8083]
loss:        0.000545  [ 2112/ 8083]
loss:        0.000493  [ 2272/ 8083]
loss:        0.000576  [ 2432/ 8083]
loss:        0.000631  [ 2592/ 8083]
loss:        0.000628  [ 2752/ 8083]
loss:        0.000520  [ 2912/ 8083]
loss:        0.000454  [ 3072/ 8083]
loss:        0.000562  [ 3232/ 8083]
loss:        0.000545  [ 3392/ 8083]
loss:        0.000594  [ 3552/ 8083]
loss:        0.000509  [ 3712/ 8083]
loss:        0.000548  [ 3872/ 8083]
loss:        0.000608  [ 4032/ 8083]
loss:        0.000546  [ 4192/ 8083]
loss:        0.000463  [ 4352/ 8083]
loss:        0.000510  [ 4512/ 8083]
loss:        0.000541  [ 4672/ 8083]
loss:        0.000441  [ 4832/ 8083]
loss:        0.000587  [ 4992/ 8083]
loss:        0.000607  [ 5152/ 8083]
loss:        0.000528  [ 5312/ 8083]
loss:        0.000547  [ 5472/ 8083]
loss:        0.000614  [ 5632/ 8083]
loss:        0.000552  [ 5792/ 8083]
loss:        0.000570  [ 5952/ 8083]
loss:        0.000544  [ 6112/ 8083]
loss:        0.000464  [ 6272/ 8083]
loss:        0.000489  [ 6432/ 8083]
loss:        0.000520  [ 6592/ 8083]
loss:        0.000545  [ 6752/ 8083]
loss:        0.000571  [ 6912/ 8083]
loss:        0.000600  [ 7072/ 8083]
loss:        0.000451  [ 7232/ 8083]
loss:        0.000571  [ 7392/ 8083]
loss:        0.000548  [ 7552/ 8083]
loss:        0.000486  [ 7712/ 8083]
loss:        0.000529  [ 7872/ 8083]
loss:        0.000535  [ 8032/ 8083]

Avg validation loss:        0.000539
Learning rate: [0.0001]
EarlyStopping counter: 3 out of 10


Epoch 7
-------------------------------
loss:        0.000535  [   32/ 8083]
loss:        0.000493  [  192/ 8083]
loss:        0.000674  [  352/ 8083]
loss:        0.000590  [  512/ 8083]
loss:        0.000561  [  672/ 8083]
loss:        0.000432  [  832/ 8083]
loss:        0.000551  [  992/ 8083]
loss:        0.000468  [ 1152/ 8083]
loss:        0.000511  [ 1312/ 8083]
loss:        0.000553  [ 1472/ 8083]
loss:        0.000493  [ 1632/ 8083]
loss:        0.000488  [ 1792/ 8083]
loss:        0.000564  [ 1952/ 8083]
loss:        0.000596  [ 2112/ 8083]
loss:        0.000496  [ 2272/ 8083]
loss:        0.000580  [ 2432/ 8083]
loss:        0.000580  [ 2592/ 8083]
loss:        0.000609  [ 2752/ 8083]
loss:        0.000526  [ 2912/ 8083]
loss:        0.000620  [ 3072/ 8083]
loss:        0.000529  [ 3232/ 8083]
loss:        0.000467  [ 3392/ 8083]
loss:        0.000614  [ 3552/ 8083]
loss:        0.000436  [ 3712/ 8083]
loss:        0.000501  [ 3872/ 8083]
loss:        0.000589  [ 4032/ 8083]
loss:        0.000477  [ 4192/ 8083]
loss:        0.000562  [ 4352/ 8083]
loss:        0.000580  [ 4512/ 8083]
loss:        0.000550  [ 4672/ 8083]
loss:        0.000587  [ 4832/ 8083]
loss:        0.000498  [ 4992/ 8083]
loss:        0.000466  [ 5152/ 8083]
loss:        0.000529  [ 5312/ 8083]
loss:        0.000491  [ 5472/ 8083]
loss:        0.000523  [ 5632/ 8083]
loss:        0.000576  [ 5792/ 8083]
loss:        0.000466  [ 5952/ 8083]
loss:        0.000424  [ 6112/ 8083]
loss:        0.000574  [ 6272/ 8083]
loss:        0.000553  [ 6432/ 8083]
loss:        0.000514  [ 6592/ 8083]
loss:        0.000579  [ 6752/ 8083]
loss:        0.000430  [ 6912/ 8083]
loss:        0.000577  [ 7072/ 8083]
loss:        0.000545  [ 7232/ 8083]
loss:        0.000456  [ 7392/ 8083]
loss:        0.000511  [ 7552/ 8083]
loss:        0.000490  [ 7712/ 8083]
loss:        0.000605  [ 7872/ 8083]
loss:        0.000523  [ 8032/ 8083]

Avg validation loss:        0.000534
Learning rate: [0.0001]
Validation loss decreased (0.000536 --&gt; 0.000534).  Saving model ...


Epoch 8
-------------------------------
loss:        0.000455  [   32/ 8083]
loss:        0.000422  [  192/ 8083]
loss:        0.000513  [  352/ 8083]
loss:        0.000549  [  512/ 8083]
loss:        0.000591  [  672/ 8083]
loss:        0.000603  [  832/ 8083]
loss:        0.000574  [  992/ 8083]
loss:        0.000532  [ 1152/ 8083]
loss:        0.000633  [ 1312/ 8083]
loss:        0.000661  [ 1472/ 8083]
loss:        0.000576  [ 1632/ 8083]
loss:        0.000538  [ 1792/ 8083]
loss:        0.000445  [ 1952/ 8083]
loss:        0.000564  [ 2112/ 8083]
loss:        0.000616  [ 2272/ 8083]
loss:        0.000539  [ 2432/ 8083]
loss:        0.000549  [ 2592/ 8083]
loss:        0.000484  [ 2752/ 8083]
loss:        0.000573  [ 2912/ 8083]
loss:        0.000510  [ 3072/ 8083]
loss:        0.000497  [ 3232/ 8083]
loss:        0.000480  [ 3392/ 8083]
loss:        0.000646  [ 3552/ 8083]
loss:        0.000552  [ 3712/ 8083]
loss:        0.000553  [ 3872/ 8083]
loss:        0.000506  [ 4032/ 8083]
loss:        0.000529  [ 4192/ 8083]
loss:        0.000644  [ 4352/ 8083]
loss:        0.000497  [ 4512/ 8083]
loss:        0.000528  [ 4672/ 8083]
loss:        0.000660  [ 4832/ 8083]
loss:        0.000485  [ 4992/ 8083]
loss:        0.000575  [ 5152/ 8083]
loss:        0.000541  [ 5312/ 8083]
loss:        0.000581  [ 5472/ 8083]
loss:        0.000541  [ 5632/ 8083]
loss:        0.000497  [ 5792/ 8083]
loss:        0.000638  [ 5952/ 8083]
loss:        0.000554  [ 6112/ 8083]
loss:        0.000436  [ 6272/ 8083]
loss:        0.000607  [ 6432/ 8083]
loss:        0.000604  [ 6592/ 8083]
loss:        0.000579  [ 6752/ 8083]
loss:        0.000464  [ 6912/ 8083]
loss:        0.000396  [ 7072/ 8083]
loss:        0.000488  [ 7232/ 8083]
loss:        0.000573  [ 7392/ 8083]
loss:        0.000511  [ 7552/ 8083]
loss:        0.000585  [ 7712/ 8083]
loss:        0.000628  [ 7872/ 8083]
loss:        0.000464  [ 8032/ 8083]

Avg validation loss:        0.000530
Learning rate: [0.0001]
Validation loss decreased (0.000534 --&gt; 0.000530).  Saving model ...


Epoch 9
-------------------------------
loss:        0.000605  [   32/ 8083]
loss:        0.000527  [  192/ 8083]
loss:        0.000506  [  352/ 8083]
loss:        0.000598  [  512/ 8083]
loss:        0.000576  [  672/ 8083]
loss:        0.000497  [  832/ 8083]
loss:        0.000520  [  992/ 8083]
loss:        0.000543  [ 1152/ 8083]
loss:        0.000544  [ 1312/ 8083]
loss:        0.000559  [ 1472/ 8083]
loss:        0.000504  [ 1632/ 8083]
loss:        0.000489  [ 1792/ 8083]
loss:        0.000497  [ 1952/ 8083]
loss:        0.000431  [ 2112/ 8083]
loss:        0.000465  [ 2272/ 8083]
loss:        0.000525  [ 2432/ 8083]
loss:        0.000477  [ 2592/ 8083]
loss:        0.000567  [ 2752/ 8083]
loss:        0.000521  [ 2912/ 8083]
loss:        0.000725  [ 3072/ 8083]
loss:        0.000484  [ 3232/ 8083]
loss:        0.000494  [ 3392/ 8083]
loss:        0.000664  [ 3552/ 8083]
loss:        0.000505  [ 3712/ 8083]
loss:        0.000619  [ 3872/ 8083]
loss:        0.000461  [ 4032/ 8083]
loss:        0.000560  [ 4192/ 8083]
loss:        0.000444  [ 4352/ 8083]
loss:        0.000618  [ 4512/ 8083]
loss:        0.000509  [ 4672/ 8083]
loss:        0.000603  [ 4832/ 8083]
loss:        0.000509  [ 4992/ 8083]
loss:        0.000546  [ 5152/ 8083]
loss:        0.000521  [ 5312/ 8083]
loss:        0.000478  [ 5472/ 8083]
loss:        0.000576  [ 5632/ 8083]
loss:        0.000555  [ 5792/ 8083]
loss:        0.000554  [ 5952/ 8083]
loss:        0.000367  [ 6112/ 8083]
loss:        0.000549  [ 6272/ 8083]
loss:        0.000521  [ 6432/ 8083]
loss:        0.000501  [ 6592/ 8083]
loss:        0.000527  [ 6752/ 8083]
loss:        0.000482  [ 6912/ 8083]
loss:        0.000532  [ 7072/ 8083]
loss:        0.000500  [ 7232/ 8083]
loss:        0.000602  [ 7392/ 8083]
loss:        0.000530  [ 7552/ 8083]
loss:        0.000487  [ 7712/ 8083]
loss:        0.000592  [ 7872/ 8083]
loss:        0.000470  [ 8032/ 8083]

Avg validation loss:        0.000531
Learning rate: [0.0001]
EarlyStopping counter: 1 out of 10


Epoch 10
-------------------------------
loss:        0.000533  [   32/ 8083]
loss:        0.000563  [  192/ 8083]
loss:        0.000423  [  352/ 8083]
loss:        0.000471  [  512/ 8083]
loss:        0.000488  [  672/ 8083]
loss:        0.000499  [  832/ 8083]
loss:        0.000610  [  992/ 8083]
loss:        0.000576  [ 1152/ 8083]
loss:        0.000560  [ 1312/ 8083]
loss:        0.000597  [ 1472/ 8083]
loss:        0.000511  [ 1632/ 8083]
loss:        0.000558  [ 1792/ 8083]
loss:        0.000579  [ 1952/ 8083]
loss:        0.000570  [ 2112/ 8083]
loss:        0.000561  [ 2272/ 8083]
loss:        0.000468  [ 2432/ 8083]
loss:        0.000555  [ 2592/ 8083]
loss:        0.000572  [ 2752/ 8083]
loss:        0.000467  [ 2912/ 8083]
loss:        0.000494  [ 3072/ 8083]
loss:        0.000601  [ 3232/ 8083]
loss:        0.000392  [ 3392/ 8083]
loss:        0.000471  [ 3552/ 8083]
loss:        0.000529  [ 3712/ 8083]
loss:        0.000539  [ 3872/ 8083]
loss:        0.000642  [ 4032/ 8083]
loss:        0.000504  [ 4192/ 8083]
loss:        0.000604  [ 4352/ 8083]
loss:        0.000484  [ 4512/ 8083]
loss:        0.000491  [ 4672/ 8083]
loss:        0.000529  [ 4832/ 8083]
loss:        0.000584  [ 4992/ 8083]
loss:        0.000456  [ 5152/ 8083]
loss:        0.000517  [ 5312/ 8083]
loss:        0.000606  [ 5472/ 8083]
loss:        0.000532  [ 5632/ 8083]
loss:        0.000490  [ 5792/ 8083]
loss:        0.000599  [ 5952/ 8083]
loss:        0.000559  [ 6112/ 8083]
loss:        0.000564  [ 6272/ 8083]
loss:        0.000507  [ 6432/ 8083]
loss:        0.000533  [ 6592/ 8083]
loss:        0.000494  [ 6752/ 8083]
loss:        0.000365  [ 6912/ 8083]
loss:        0.000437  [ 7072/ 8083]
loss:        0.000457  [ 7232/ 8083]
loss:        0.000452  [ 7392/ 8083]
loss:        0.000484  [ 7552/ 8083]
loss:        0.000571  [ 7712/ 8083]
loss:        0.000512  [ 7872/ 8083]
loss:        0.000394  [ 8032/ 8083]

Avg validation loss:        0.000526
Learning rate: [0.0001]
Validation loss decreased (0.000530 --&gt; 0.000526).  Saving model ...


Epoch 11
-------------------------------
loss:        0.000549  [   32/ 8083]
loss:        0.000517  [  192/ 8083]
loss:        0.000492  [  352/ 8083]
loss:        0.000546  [  512/ 8083]
loss:        0.000471  [  672/ 8083]
loss:        0.000492  [  832/ 8083]
loss:        0.000493  [  992/ 8083]
loss:        0.000622  [ 1152/ 8083]
loss:        0.000531  [ 1312/ 8083]
loss:        0.000558  [ 1472/ 8083]
loss:        0.000476  [ 1632/ 8083]
loss:        0.000607  [ 1792/ 8083]
loss:        0.000565  [ 1952/ 8083]
loss:        0.000463  [ 2112/ 8083]
loss:        0.000551  [ 2272/ 8083]
loss:        0.000686  [ 2432/ 8083]
loss:        0.000425  [ 2592/ 8083]
loss:        0.000463  [ 2752/ 8083]
loss:        0.000516  [ 2912/ 8083]
loss:        0.000436  [ 3072/ 8083]
loss:        0.000501  [ 3232/ 8083]
loss:        0.000561  [ 3392/ 8083]
loss:        0.000506  [ 3552/ 8083]
loss:        0.000516  [ 3712/ 8083]
loss:        0.000609  [ 3872/ 8083]
loss:        0.000556  [ 4032/ 8083]
loss:        0.000592  [ 4192/ 8083]
loss:        0.000449  [ 4352/ 8083]
loss:        0.000515  [ 4512/ 8083]
loss:        0.000624  [ 4672/ 8083]
loss:        0.000519  [ 4832/ 8083]
loss:        0.000612  [ 4992/ 8083]
loss:        0.000604  [ 5152/ 8083]
loss:        0.000548  [ 5312/ 8083]
loss:        0.000484  [ 5472/ 8083]
loss:        0.000415  [ 5632/ 8083]
loss:        0.000528  [ 5792/ 8083]
loss:        0.000534  [ 5952/ 8083]
loss:        0.000546  [ 6112/ 8083]
loss:        0.000543  [ 6272/ 8083]
loss:        0.000475  [ 6432/ 8083]
loss:        0.000623  [ 6592/ 8083]
loss:        0.000419  [ 6752/ 8083]
loss:        0.000549  [ 6912/ 8083]
loss:        0.000670  [ 7072/ 8083]
loss:        0.000557  [ 7232/ 8083]
loss:        0.000607  [ 7392/ 8083]
loss:        0.000595  [ 7552/ 8083]
loss:        0.000511  [ 7712/ 8083]
loss:        0.000477  [ 7872/ 8083]
loss:        0.000484  [ 8032/ 8083]

Avg validation loss:        0.000527
Learning rate: [0.0001]
EarlyStopping counter: 1 out of 10


Epoch 12
-------------------------------
loss:        0.000469  [   32/ 8083]
loss:        0.000569  [  192/ 8083]
loss:        0.000547  [  352/ 8083]
loss:        0.000546  [  512/ 8083]
loss:        0.000668  [  672/ 8083]
loss:        0.000540  [  832/ 8083]
loss:        0.000548  [  992/ 8083]
loss:        0.000518  [ 1152/ 8083]
loss:        0.000496  [ 1312/ 8083]
loss:        0.000618  [ 1472/ 8083]
loss:        0.000523  [ 1632/ 8083]
loss:        0.000510  [ 1792/ 8083]
loss:        0.000435  [ 1952/ 8083]
loss:        0.000551  [ 2112/ 8083]
loss:        0.000528  [ 2272/ 8083]
loss:        0.000473  [ 2432/ 8083]
loss:        0.000487  [ 2592/ 8083]
loss:        0.000586  [ 2752/ 8083]
loss:        0.000520  [ 2912/ 8083]
loss:        0.000511  [ 3072/ 8083]
loss:        0.000552  [ 3232/ 8083]
loss:        0.000548  [ 3392/ 8083]
loss:        0.000546  [ 3552/ 8083]
loss:        0.000527  [ 3712/ 8083]
loss:        0.000511  [ 3872/ 8083]
loss:        0.000553  [ 4032/ 8083]
loss:        0.000455  [ 4192/ 8083]
loss:        0.000518  [ 4352/ 8083]
loss:        0.000585  [ 4512/ 8083]
loss:        0.000655  [ 4672/ 8083]
loss:        0.000540  [ 4832/ 8083]
loss:        0.000513  [ 4992/ 8083]
loss:        0.000544  [ 5152/ 8083]
loss:        0.000604  [ 5312/ 8083]
loss:        0.000523  [ 5472/ 8083]
loss:        0.000530  [ 5632/ 8083]
loss:        0.000512  [ 5792/ 8083]
loss:        0.000506  [ 5952/ 8083]
loss:        0.000537  [ 6112/ 8083]
loss:        0.000620  [ 6272/ 8083]
loss:        0.000414  [ 6432/ 8083]
loss:        0.000494  [ 6592/ 8083]
loss:        0.000594  [ 6752/ 8083]
loss:        0.000533  [ 6912/ 8083]
loss:        0.000519  [ 7072/ 8083]
loss:        0.000567  [ 7232/ 8083]
loss:        0.000545  [ 7392/ 8083]
loss:        0.000498  [ 7552/ 8083]
loss:        0.000525  [ 7712/ 8083]
loss:        0.000529  [ 7872/ 8083]
loss:        0.000553  [ 8032/ 8083]

Avg validation loss:        0.000530
Learning rate: [0.0001]
EarlyStopping counter: 2 out of 10


Epoch 13
-------------------------------
loss:        0.000539  [   32/ 8083]
loss:        0.000483  [  192/ 8083]
loss:        0.000554  [  352/ 8083]
loss:        0.000473  [  512/ 8083]
loss:        0.000392  [  672/ 8083]
loss:        0.000421  [  832/ 8083]
loss:        0.000420  [  992/ 8083]
loss:        0.000631  [ 1152/ 8083]
loss:        0.000528  [ 1312/ 8083]
loss:        0.000560  [ 1472/ 8083]
loss:        0.000606  [ 1632/ 8083]
loss:        0.000542  [ 1792/ 8083]
loss:        0.000509  [ 1952/ 8083]
loss:        0.000458  [ 2112/ 8083]
loss:        0.000553  [ 2272/ 8083]
loss:        0.000522  [ 2432/ 8083]
loss:        0.000508  [ 2592/ 8083]
loss:        0.000480  [ 2752/ 8083]
loss:        0.000548  [ 2912/ 8083]
loss:        0.000579  [ 3072/ 8083]
loss:        0.000510  [ 3232/ 8083]
loss:        0.000548  [ 3392/ 8083]
loss:        0.000638  [ 3552/ 8083]
loss:        0.000597  [ 3712/ 8083]
loss:        0.000579  [ 3872/ 8083]
loss:        0.000554  [ 4032/ 8083]
loss:        0.000552  [ 4192/ 8083]
loss:        0.000558  [ 4352/ 8083]
loss:        0.000486  [ 4512/ 8083]
loss:        0.000551  [ 4672/ 8083]
loss:        0.000598  [ 4832/ 8083]
loss:        0.000595  [ 4992/ 8083]
loss:        0.000474  [ 5152/ 8083]
loss:        0.000521  [ 5312/ 8083]
loss:        0.000472  [ 5472/ 8083]
loss:        0.000544  [ 5632/ 8083]
loss:        0.000561  [ 5792/ 8083]
loss:        0.000585  [ 5952/ 8083]
loss:        0.000437  [ 6112/ 8083]
loss:        0.000456  [ 6272/ 8083]
loss:        0.000507  [ 6432/ 8083]
loss:        0.000564  [ 6592/ 8083]
loss:        0.000435  [ 6752/ 8083]
loss:        0.000500  [ 6912/ 8083]
loss:        0.000459  [ 7072/ 8083]
loss:        0.000648  [ 7232/ 8083]
loss:        0.000597  [ 7392/ 8083]
loss:        0.000453  [ 7552/ 8083]
loss:        0.000578  [ 7712/ 8083]
loss:        0.000562  [ 7872/ 8083]
loss:        0.000458  [ 8032/ 8083]

Avg validation loss:        0.000526
Learning rate: [0.0001]
EarlyStopping counter: 3 out of 10


Epoch 14
-------------------------------
loss:        0.000518  [   32/ 8083]
loss:        0.000615  [  192/ 8083]
loss:        0.000469  [  352/ 8083]
loss:        0.000559  [  512/ 8083]
loss:        0.000508  [  672/ 8083]
loss:        0.000612  [  832/ 8083]
loss:        0.000524  [  992/ 8083]
loss:        0.000558  [ 1152/ 8083]
loss:        0.000591  [ 1312/ 8083]
loss:        0.000503  [ 1472/ 8083]
loss:        0.000470  [ 1632/ 8083]
loss:        0.000489  [ 1792/ 8083]
loss:        0.000389  [ 1952/ 8083]
loss:        0.000419  [ 2112/ 8083]
loss:        0.000586  [ 2272/ 8083]
loss:        0.000492  [ 2432/ 8083]
loss:        0.000489  [ 2592/ 8083]
loss:        0.000528  [ 2752/ 8083]
loss:        0.000553  [ 2912/ 8083]
loss:        0.000502  [ 3072/ 8083]
loss:        0.000445  [ 3232/ 8083]
loss:        0.000522  [ 3392/ 8083]
loss:        0.000611  [ 3552/ 8083]
loss:        0.000445  [ 3712/ 8083]
loss:        0.000530  [ 3872/ 8083]
loss:        0.000524  [ 4032/ 8083]
loss:        0.000386  [ 4192/ 8083]
loss:        0.000561  [ 4352/ 8083]
loss:        0.000431  [ 4512/ 8083]
loss:        0.000558  [ 4672/ 8083]
loss:        0.000474  [ 4832/ 8083]
loss:        0.000579  [ 4992/ 8083]
loss:        0.000485  [ 5152/ 8083]
loss:        0.000459  [ 5312/ 8083]
loss:        0.000599  [ 5472/ 8083]
loss:        0.000478  [ 5632/ 8083]
loss:        0.000519  [ 5792/ 8083]
loss:        0.000577  [ 5952/ 8083]
loss:        0.000529  [ 6112/ 8083]
loss:        0.000569  [ 6272/ 8083]
loss:        0.000527  [ 6432/ 8083]
loss:        0.000358  [ 6592/ 8083]
loss:        0.000537  [ 6752/ 8083]
loss:        0.000563  [ 6912/ 8083]
loss:        0.000378  [ 7072/ 8083]
loss:        0.000427  [ 7232/ 8083]
loss:        0.000507  [ 7392/ 8083]
loss:        0.000550  [ 7552/ 8083]
loss:        0.000506  [ 7712/ 8083]
loss:        0.000446  [ 7872/ 8083]
loss:        0.000478  [ 8032/ 8083]

Avg validation loss:        0.000527
Learning rate: [1e-05]
EarlyStopping counter: 4 out of 10


Epoch 15
-------------------------------
loss:        0.000564  [   32/ 8083]
loss:        0.000472  [  192/ 8083]
loss:        0.000436  [  352/ 8083]
loss:        0.000568  [  512/ 8083]
loss:        0.000548  [  672/ 8083]
loss:        0.000483  [  832/ 8083]
loss:        0.000545  [  992/ 8083]
loss:        0.000569  [ 1152/ 8083]
loss:        0.000539  [ 1312/ 8083]
loss:        0.000572  [ 1472/ 8083]
loss:        0.000562  [ 1632/ 8083]
loss:        0.000492  [ 1792/ 8083]
loss:        0.000552  [ 1952/ 8083]
loss:        0.000433  [ 2112/ 8083]
loss:        0.000532  [ 2272/ 8083]
loss:        0.000539  [ 2432/ 8083]
loss:        0.000452  [ 2592/ 8083]
loss:        0.000458  [ 2752/ 8083]
loss:        0.000480  [ 2912/ 8083]
loss:        0.000531  [ 3072/ 8083]
loss:        0.000458  [ 3232/ 8083]
loss:        0.000532  [ 3392/ 8083]
loss:        0.000492  [ 3552/ 8083]
loss:        0.000536  [ 3712/ 8083]
loss:        0.000511  [ 3872/ 8083]
loss:        0.000548  [ 4032/ 8083]
loss:        0.000611  [ 4192/ 8083]
loss:        0.000538  [ 4352/ 8083]
loss:        0.000564  [ 4512/ 8083]
loss:        0.000378  [ 4672/ 8083]
loss:        0.000560  [ 4832/ 8083]
loss:        0.000538  [ 4992/ 8083]
loss:        0.000575  [ 5152/ 8083]
loss:        0.000504  [ 5312/ 8083]
loss:        0.000529  [ 5472/ 8083]
loss:        0.000567  [ 5632/ 8083]
loss:        0.000518  [ 5792/ 8083]
loss:        0.000554  [ 5952/ 8083]
loss:        0.000613  [ 6112/ 8083]
loss:        0.000599  [ 6272/ 8083]
loss:        0.000547  [ 6432/ 8083]
loss:        0.000487  [ 6592/ 8083]
loss:        0.000417  [ 6752/ 8083]
loss:        0.000443  [ 6912/ 8083]
loss:        0.000444  [ 7072/ 8083]
loss:        0.000480  [ 7232/ 8083]
loss:        0.000489  [ 7392/ 8083]
loss:        0.000485  [ 7552/ 8083]
loss:        0.000506  [ 7712/ 8083]
loss:        0.000522  [ 7872/ 8083]
loss:        0.000597  [ 8032/ 8083]

Avg validation loss:        0.000526
Learning rate: [1e-05]
Validation loss decreased (0.000526 --&gt; 0.000526).  Saving model ...


Epoch 16
-------------------------------
loss:        0.000515  [   32/ 8083]
loss:        0.000473  [  192/ 8083]
loss:        0.000567  [  352/ 8083]
loss:        0.000617  [  512/ 8083]
loss:        0.000466  [  672/ 8083]
loss:        0.000611  [  832/ 8083]
loss:        0.000455  [  992/ 8083]
loss:        0.000614  [ 1152/ 8083]
loss:        0.000509  [ 1312/ 8083]
loss:        0.000658  [ 1472/ 8083]
loss:        0.000521  [ 1632/ 8083]
loss:        0.000554  [ 1792/ 8083]
loss:        0.000517  [ 1952/ 8083]
loss:        0.000509  [ 2112/ 8083]
loss:        0.000472  [ 2272/ 8083]
loss:        0.000495  [ 2432/ 8083]
loss:        0.000620  [ 2592/ 8083]
loss:        0.000550  [ 2752/ 8083]
loss:        0.000514  [ 2912/ 8083]
loss:        0.000579  [ 3072/ 8083]
loss:        0.000497  [ 3232/ 8083]
loss:        0.000588  [ 3392/ 8083]
loss:        0.000599  [ 3552/ 8083]
loss:        0.000507  [ 3712/ 8083]
loss:        0.000451  [ 3872/ 8083]
loss:        0.000543  [ 4032/ 8083]
loss:        0.000545  [ 4192/ 8083]
loss:        0.000365  [ 4352/ 8083]
loss:        0.000586  [ 4512/ 8083]
loss:        0.000496  [ 4672/ 8083]
loss:        0.000521  [ 4832/ 8083]
loss:        0.000459  [ 4992/ 8083]
loss:        0.000495  [ 5152/ 8083]
loss:        0.000484  [ 5312/ 8083]
loss:        0.000535  [ 5472/ 8083]
loss:        0.000557  [ 5632/ 8083]
loss:        0.000544  [ 5792/ 8083]
loss:        0.000521  [ 5952/ 8083]
loss:        0.000480  [ 6112/ 8083]
loss:        0.000533  [ 6272/ 8083]
loss:        0.000471  [ 6432/ 8083]
loss:        0.000528  [ 6592/ 8083]
loss:        0.000474  [ 6752/ 8083]
loss:        0.000659  [ 6912/ 8083]
loss:        0.000542  [ 7072/ 8083]
loss:        0.000469  [ 7232/ 8083]
loss:        0.000469  [ 7392/ 8083]
loss:        0.000471  [ 7552/ 8083]
loss:        0.000525  [ 7712/ 8083]
loss:        0.000549  [ 7872/ 8083]
loss:        0.000527  [ 8032/ 8083]

Avg validation loss:        0.000526
Learning rate: [1e-05]
EarlyStopping counter: 1 out of 10


Epoch 17
-------------------------------
loss:        0.000547  [   32/ 8083]
loss:        0.000574  [  192/ 8083]
loss:        0.000516  [  352/ 8083]
loss:        0.000578  [  512/ 8083]
loss:        0.000448  [  672/ 8083]
loss:        0.000432  [  832/ 8083]
loss:        0.000508  [  992/ 8083]
loss:        0.000557  [ 1152/ 8083]
loss:        0.000565  [ 1312/ 8083]
loss:        0.000479  [ 1472/ 8083]
loss:        0.000538  [ 1632/ 8083]
loss:        0.000509  [ 1792/ 8083]
loss:        0.000589  [ 1952/ 8083]
loss:        0.000496  [ 2112/ 8083]
loss:        0.000476  [ 2272/ 8083]
loss:        0.000543  [ 2432/ 8083]
loss:        0.000574  [ 2592/ 8083]
loss:        0.000611  [ 2752/ 8083]
loss:        0.000494  [ 2912/ 8083]
loss:        0.000589  [ 3072/ 8083]
loss:        0.000552  [ 3232/ 8083]
loss:        0.000490  [ 3392/ 8083]
loss:        0.000578  [ 3552/ 8083]
loss:        0.000512  [ 3712/ 8083]
loss:        0.000631  [ 3872/ 8083]
loss:        0.000568  [ 4032/ 8083]
loss:        0.000547  [ 4192/ 8083]
loss:        0.000540  [ 4352/ 8083]
loss:        0.000560  [ 4512/ 8083]
loss:        0.000515  [ 4672/ 8083]
loss:        0.000565  [ 4832/ 8083]
loss:        0.000499  [ 4992/ 8083]
loss:        0.000584  [ 5152/ 8083]
loss:        0.000551  [ 5312/ 8083]
loss:        0.000422  [ 5472/ 8083]
loss:        0.000521  [ 5632/ 8083]
loss:        0.000560  [ 5792/ 8083]
loss:        0.000514  [ 5952/ 8083]
loss:        0.000530  [ 6112/ 8083]
loss:        0.000497  [ 6272/ 8083]
loss:        0.000557  [ 6432/ 8083]
loss:        0.000542  [ 6592/ 8083]
loss:        0.000645  [ 6752/ 8083]
loss:        0.000470  [ 6912/ 8083]
loss:        0.000525  [ 7072/ 8083]
loss:        0.000522  [ 7232/ 8083]
loss:        0.000473  [ 7392/ 8083]
loss:        0.000620  [ 7552/ 8083]
loss:        0.000487  [ 7712/ 8083]
loss:        0.000465  [ 7872/ 8083]
loss:        0.000528  [ 8032/ 8083]

Avg validation loss:        0.000528
Learning rate: [1e-05]
EarlyStopping counter: 2 out of 10


Epoch 18
-------------------------------
loss:        0.000600  [   32/ 8083]
loss:        0.000421  [  192/ 8083]
loss:        0.000429  [  352/ 8083]
loss:        0.000610  [  512/ 8083]
loss:        0.000400  [  672/ 8083]
loss:        0.000600  [  832/ 8083]
loss:        0.000540  [  992/ 8083]
loss:        0.000505  [ 1152/ 8083]
loss:        0.000479  [ 1312/ 8083]
loss:        0.000489  [ 1472/ 8083]
loss:        0.000469  [ 1632/ 8083]
loss:        0.000412  [ 1792/ 8083]
loss:        0.000463  [ 1952/ 8083]
loss:        0.000610  [ 2112/ 8083]
loss:        0.000573  [ 2272/ 8083]
loss:        0.000473  [ 2432/ 8083]
loss:        0.000498  [ 2592/ 8083]
loss:        0.000493  [ 2752/ 8083]
loss:        0.000499  [ 2912/ 8083]
loss:        0.000586  [ 3072/ 8083]
loss:        0.000530  [ 3232/ 8083]
loss:        0.000590  [ 3392/ 8083]
loss:        0.000590  [ 3552/ 8083]
loss:        0.000519  [ 3712/ 8083]
loss:        0.000543  [ 3872/ 8083]
loss:        0.000570  [ 4032/ 8083]
loss:        0.000586  [ 4192/ 8083]
loss:        0.000575  [ 4352/ 8083]
loss:        0.000531  [ 4512/ 8083]
loss:        0.000530  [ 4672/ 8083]
loss:        0.000571  [ 4832/ 8083]
loss:        0.000498  [ 4992/ 8083]
loss:        0.000446  [ 5152/ 8083]
loss:        0.000612  [ 5312/ 8083]
loss:        0.000527  [ 5472/ 8083]
loss:        0.000462  [ 5632/ 8083]
loss:        0.000644  [ 5792/ 8083]
loss:        0.000541  [ 5952/ 8083]
loss:        0.000465  [ 6112/ 8083]
loss:        0.000403  [ 6272/ 8083]
loss:        0.000461  [ 6432/ 8083]
loss:        0.000583  [ 6592/ 8083]
loss:        0.000522  [ 6752/ 8083]
loss:        0.000562  [ 6912/ 8083]
loss:        0.000528  [ 7072/ 8083]
loss:        0.000562  [ 7232/ 8083]
loss:        0.000501  [ 7392/ 8083]
loss:        0.000611  [ 7552/ 8083]
loss:        0.000481  [ 7712/ 8083]
loss:        0.000509  [ 7872/ 8083]
loss:        0.000519  [ 8032/ 8083]

Avg validation loss:        0.000527
Learning rate: [1e-05]
EarlyStopping counter: 3 out of 10


Epoch 19
-------------------------------
loss:        0.000391  [   32/ 8083]
loss:        0.000492  [  192/ 8083]
loss:        0.000577  [  352/ 8083]
loss:        0.000487  [  512/ 8083]
loss:        0.000491  [  672/ 8083]
loss:        0.000409  [  832/ 8083]
loss:        0.000440  [  992/ 8083]
loss:        0.000476  [ 1152/ 8083]
loss:        0.000496  [ 1312/ 8083]
loss:        0.000627  [ 1472/ 8083]
loss:        0.000527  [ 1632/ 8083]
loss:        0.000410  [ 1792/ 8083]
loss:        0.000513  [ 1952/ 8083]
loss:        0.000559  [ 2112/ 8083]
loss:        0.000567  [ 2272/ 8083]
loss:        0.000568  [ 2432/ 8083]
loss:        0.000442  [ 2592/ 8083]
loss:        0.000513  [ 2752/ 8083]
loss:        0.000438  [ 2912/ 8083]
loss:        0.000546  [ 3072/ 8083]
loss:        0.000557  [ 3232/ 8083]
loss:        0.000524  [ 3392/ 8083]
loss:        0.000496  [ 3552/ 8083]
loss:        0.000403  [ 3712/ 8083]
loss:        0.000540  [ 3872/ 8083]
loss:        0.000534  [ 4032/ 8083]
loss:        0.000445  [ 4192/ 8083]
loss:        0.000401  [ 4352/ 8083]
loss:        0.000442  [ 4512/ 8083]
loss:        0.000503  [ 4672/ 8083]
loss:        0.000510  [ 4832/ 8083]
loss:        0.000517  [ 4992/ 8083]
loss:        0.000548  [ 5152/ 8083]
loss:        0.000603  [ 5312/ 8083]
loss:        0.000543  [ 5472/ 8083]
loss:        0.000530  [ 5632/ 8083]
loss:        0.000533  [ 5792/ 8083]
loss:        0.000549  [ 5952/ 8083]
loss:        0.000517  [ 6112/ 8083]
loss:        0.000577  [ 6272/ 8083]
loss:        0.000512  [ 6432/ 8083]
loss:        0.000625  [ 6592/ 8083]
loss:        0.000630  [ 6752/ 8083]
loss:        0.000546  [ 6912/ 8083]
loss:        0.000584  [ 7072/ 8083]
loss:        0.000478  [ 7232/ 8083]
loss:        0.000502  [ 7392/ 8083]
loss:        0.000539  [ 7552/ 8083]
loss:        0.000585  [ 7712/ 8083]
loss:        0.000422  [ 7872/ 8083]
loss:        0.000494  [ 8032/ 8083]

Avg validation loss:        0.000528
Learning rate: [1.0000000000000002e-06]
EarlyStopping counter: 4 out of 10


Epoch 20
-------------------------------
loss:        0.000488  [   32/ 8083]
loss:        0.000418  [  192/ 8083]
loss:        0.000510  [  352/ 8083]
loss:        0.000523  [  512/ 8083]
loss:        0.000505  [  672/ 8083]
loss:        0.000482  [  832/ 8083]
loss:        0.000490  [  992/ 8083]
loss:        0.000552  [ 1152/ 8083]
loss:        0.000613  [ 1312/ 8083]
loss:        0.000507  [ 1472/ 8083]
loss:        0.000591  [ 1632/ 8083]
loss:        0.000546  [ 1792/ 8083]
loss:        0.000477  [ 1952/ 8083]
loss:        0.000545  [ 2112/ 8083]
loss:        0.000579  [ 2272/ 8083]
loss:        0.000533  [ 2432/ 8083]
loss:        0.000634  [ 2592/ 8083]
loss:        0.000564  [ 2752/ 8083]
loss:        0.000511  [ 2912/ 8083]
loss:        0.000498  [ 3072/ 8083]
loss:        0.000451  [ 3232/ 8083]
loss:        0.000431  [ 3392/ 8083]
loss:        0.000581  [ 3552/ 8083]
loss:        0.000554  [ 3712/ 8083]
loss:        0.000518  [ 3872/ 8083]
loss:        0.000494  [ 4032/ 8083]
loss:        0.000595  [ 4192/ 8083]
loss:        0.000525  [ 4352/ 8083]
loss:        0.000490  [ 4512/ 8083]
loss:        0.000525  [ 4672/ 8083]
loss:        0.000584  [ 4832/ 8083]
loss:        0.000559  [ 4992/ 8083]
loss:        0.000537  [ 5152/ 8083]
loss:        0.000412  [ 5312/ 8083]
loss:        0.000594  [ 5472/ 8083]
loss:        0.000537  [ 5632/ 8083]
loss:        0.000509  [ 5792/ 8083]
loss:        0.000548  [ 5952/ 8083]
loss:        0.000617  [ 6112/ 8083]
loss:        0.000610  [ 6272/ 8083]
loss:        0.000517  [ 6432/ 8083]
loss:        0.000516  [ 6592/ 8083]
loss:        0.000388  [ 6752/ 8083]
loss:        0.000414  [ 6912/ 8083]
loss:        0.000525  [ 7072/ 8083]
loss:        0.000483  [ 7232/ 8083]
loss:        0.000523  [ 7392/ 8083]
loss:        0.000631  [ 7552/ 8083]
loss:        0.000596  [ 7712/ 8083]
loss:        0.000571  [ 7872/ 8083]
loss:        0.000484  [ 8032/ 8083]

Avg validation loss:        0.000525
Learning rate: [1.0000000000000002e-06]
Validation loss decreased (0.000526 --&gt; 0.000525).  Saving model ...


Epoch 21
-------------------------------
loss:        0.000486  [   32/ 8083]
loss:        0.000561  [  192/ 8083]
loss:        0.000487  [  352/ 8083]
loss:        0.000578  [  512/ 8083]
loss:        0.000634  [  672/ 8083]
loss:        0.000368  [  832/ 8083]
loss:        0.000474  [  992/ 8083]
loss:        0.000591  [ 1152/ 8083]
loss:        0.000628  [ 1312/ 8083]
loss:        0.000568  [ 1472/ 8083]
loss:        0.000600  [ 1632/ 8083]
loss:        0.000640  [ 1792/ 8083]
loss:        0.000422  [ 1952/ 8083]
loss:        0.000475  [ 2112/ 8083]
loss:        0.000565  [ 2272/ 8083]
loss:        0.000500  [ 2432/ 8083]
loss:        0.000613  [ 2592/ 8083]
loss:        0.000433  [ 2752/ 8083]
loss:        0.000498  [ 2912/ 8083]
loss:        0.000648  [ 3072/ 8083]
loss:        0.000524  [ 3232/ 8083]
loss:        0.000388  [ 3392/ 8083]
loss:        0.000496  [ 3552/ 8083]
loss:        0.000543  [ 3712/ 8083]
loss:        0.000516  [ 3872/ 8083]
loss:        0.000530  [ 4032/ 8083]
loss:        0.000405  [ 4192/ 8083]
loss:        0.000540  [ 4352/ 8083]
loss:        0.000503  [ 4512/ 8083]
loss:        0.000474  [ 4672/ 8083]
loss:        0.000449  [ 4832/ 8083]
loss:        0.000571  [ 4992/ 8083]
loss:        0.000478  [ 5152/ 8083]
loss:        0.000471  [ 5312/ 8083]
loss:        0.000534  [ 5472/ 8083]
loss:        0.000612  [ 5632/ 8083]
loss:        0.000489  [ 5792/ 8083]
loss:        0.000415  [ 5952/ 8083]
loss:        0.000578  [ 6112/ 8083]
loss:        0.000455  [ 6272/ 8083]
loss:        0.000526  [ 6432/ 8083]
loss:        0.000674  [ 6592/ 8083]
loss:        0.000574  [ 6752/ 8083]
loss:        0.000492  [ 6912/ 8083]
loss:        0.000525  [ 7072/ 8083]
loss:        0.000575  [ 7232/ 8083]
loss:        0.000593  [ 7392/ 8083]
loss:        0.000533  [ 7552/ 8083]
loss:        0.000511  [ 7712/ 8083]
loss:        0.000386  [ 7872/ 8083]
loss:        0.000589  [ 8032/ 8083]

Avg validation loss:        0.000527
Learning rate: [1.0000000000000002e-06]
EarlyStopping counter: 1 out of 10


Epoch 22
-------------------------------
loss:        0.000576  [   32/ 8083]
loss:        0.000463  [  192/ 8083]
loss:        0.000436  [  352/ 8083]
loss:        0.000439  [  512/ 8083]
loss:        0.000555  [  672/ 8083]
loss:        0.000520  [  832/ 8083]
loss:        0.000541  [  992/ 8083]
loss:        0.000417  [ 1152/ 8083]
loss:        0.000543  [ 1312/ 8083]
loss:        0.000449  [ 1472/ 8083]
loss:        0.000538  [ 1632/ 8083]
loss:        0.000650  [ 1792/ 8083]
loss:        0.000435  [ 1952/ 8083]
loss:        0.000593  [ 2112/ 8083]
loss:        0.000583  [ 2272/ 8083]
loss:        0.000528  [ 2432/ 8083]
loss:        0.000584  [ 2592/ 8083]
loss:        0.000411  [ 2752/ 8083]
loss:        0.000518  [ 2912/ 8083]
loss:        0.000515  [ 3072/ 8083]
loss:        0.000521  [ 3232/ 8083]
loss:        0.000425  [ 3392/ 8083]
loss:        0.000528  [ 3552/ 8083]
loss:        0.000651  [ 3712/ 8083]
loss:        0.000497  [ 3872/ 8083]
loss:        0.000476  [ 4032/ 8083]
loss:        0.000631  [ 4192/ 8083]
loss:        0.000547  [ 4352/ 8083]
loss:        0.000598  [ 4512/ 8083]
loss:        0.000515  [ 4672/ 8083]
loss:        0.000619  [ 4832/ 8083]
loss:        0.000516  [ 4992/ 8083]
loss:        0.000445  [ 5152/ 8083]
loss:        0.000593  [ 5312/ 8083]
loss:        0.000553  [ 5472/ 8083]
loss:        0.000461  [ 5632/ 8083]
loss:        0.000667  [ 5792/ 8083]
loss:        0.000610  [ 5952/ 8083]
loss:        0.000485  [ 6112/ 8083]
loss:        0.000493  [ 6272/ 8083]
loss:        0.000578  [ 6432/ 8083]
loss:        0.000535  [ 6592/ 8083]
loss:        0.000506  [ 6752/ 8083]
loss:        0.000407  [ 6912/ 8083]
loss:        0.000541  [ 7072/ 8083]
loss:        0.000566  [ 7232/ 8083]
loss:        0.000383  [ 7392/ 8083]
loss:        0.000547  [ 7552/ 8083]
loss:        0.000500  [ 7712/ 8083]
loss:        0.000558  [ 7872/ 8083]
loss:        0.000421  [ 8032/ 8083]

Avg validation loss:        0.000527
Learning rate: [1.0000000000000002e-06]
EarlyStopping counter: 2 out of 10


Epoch 23
-------------------------------
loss:        0.000499  [   32/ 8083]
loss:        0.000565  [  192/ 8083]
loss:        0.000525  [  352/ 8083]
loss:        0.000480  [  512/ 8083]
loss:        0.000501  [  672/ 8083]
loss:        0.000630  [  832/ 8083]
loss:        0.000621  [  992/ 8083]
loss:        0.000456  [ 1152/ 8083]
loss:        0.000530  [ 1312/ 8083]
loss:        0.000472  [ 1472/ 8083]
loss:        0.000614  [ 1632/ 8083]
loss:        0.000499  [ 1792/ 8083]
loss:        0.000527  [ 1952/ 8083]
loss:        0.000497  [ 2112/ 8083]
loss:        0.000586  [ 2272/ 8083]
loss:        0.000598  [ 2432/ 8083]
loss:        0.000504  [ 2592/ 8083]
loss:        0.000575  [ 2752/ 8083]
loss:        0.000513  [ 2912/ 8083]
loss:        0.000480  [ 3072/ 8083]
loss:        0.000586  [ 3232/ 8083]
loss:        0.000523  [ 3392/ 8083]
loss:        0.000420  [ 3552/ 8083]
loss:        0.000527  [ 3712/ 8083]
loss:        0.000534  [ 3872/ 8083]
loss:        0.000611  [ 4032/ 8083]
loss:        0.000502  [ 4192/ 8083]
loss:        0.000502  [ 4352/ 8083]
loss:        0.000510  [ 4512/ 8083]
loss:        0.000569  [ 4672/ 8083]
loss:        0.000587  [ 4832/ 8083]
loss:        0.000592  [ 4992/ 8083]
loss:        0.000581  [ 5152/ 8083]
loss:        0.000513  [ 5312/ 8083]
loss:        0.000517  [ 5472/ 8083]
loss:        0.000546  [ 5632/ 8083]
loss:        0.000541  [ 5792/ 8083]
loss:        0.000428  [ 5952/ 8083]
loss:        0.000467  [ 6112/ 8083]
loss:        0.000476  [ 6272/ 8083]
loss:        0.000537  [ 6432/ 8083]
loss:        0.000544  [ 6592/ 8083]
loss:        0.000534  [ 6752/ 8083]
loss:        0.000536  [ 6912/ 8083]
loss:        0.000431  [ 7072/ 8083]
loss:        0.000478  [ 7232/ 8083]
loss:        0.000496  [ 7392/ 8083]
loss:        0.000467  [ 7552/ 8083]
loss:        0.000434  [ 7712/ 8083]
loss:        0.000585  [ 7872/ 8083]
loss:        0.000495  [ 8032/ 8083]

Avg validation loss:        0.000527
Learning rate: [1.0000000000000002e-06]
EarlyStopping counter: 3 out of 10


Epoch 24
-------------------------------
loss:        0.000577  [   32/ 8083]
loss:        0.000503  [  192/ 8083]
loss:        0.000544  [  352/ 8083]
loss:        0.000487  [  512/ 8083]
loss:        0.000572  [  672/ 8083]
loss:        0.000510  [  832/ 8083]
loss:        0.000495  [  992/ 8083]
loss:        0.000498  [ 1152/ 8083]
loss:        0.000574  [ 1312/ 8083]
loss:        0.000599  [ 1472/ 8083]
loss:        0.000514  [ 1632/ 8083]
loss:        0.000574  [ 1792/ 8083]
loss:        0.000549  [ 1952/ 8083]
loss:        0.000457  [ 2112/ 8083]
loss:        0.000528  [ 2272/ 8083]
loss:        0.000440  [ 2432/ 8083]
loss:        0.000471  [ 2592/ 8083]
loss:        0.000544  [ 2752/ 8083]
loss:        0.000517  [ 2912/ 8083]
loss:        0.000508  [ 3072/ 8083]
loss:        0.000513  [ 3232/ 8083]
loss:        0.000574  [ 3392/ 8083]
loss:        0.000480  [ 3552/ 8083]
loss:        0.000571  [ 3712/ 8083]
loss:        0.000500  [ 3872/ 8083]
loss:        0.000524  [ 4032/ 8083]
loss:        0.000653  [ 4192/ 8083]
loss:        0.000547  [ 4352/ 8083]
loss:        0.000551  [ 4512/ 8083]
loss:        0.000451  [ 4672/ 8083]
loss:        0.000461  [ 4832/ 8083]
loss:        0.000391  [ 4992/ 8083]
loss:        0.000596  [ 5152/ 8083]
loss:        0.000496  [ 5312/ 8083]
loss:        0.000452  [ 5472/ 8083]
loss:        0.000516  [ 5632/ 8083]
loss:        0.000472  [ 5792/ 8083]
loss:        0.000514  [ 5952/ 8083]
loss:        0.000496  [ 6112/ 8083]
loss:        0.000548  [ 6272/ 8083]
loss:        0.000503  [ 6432/ 8083]
loss:        0.000496  [ 6592/ 8083]
loss:        0.000534  [ 6752/ 8083]
loss:        0.000553  [ 6912/ 8083]
loss:        0.000528  [ 7072/ 8083]
loss:        0.000549  [ 7232/ 8083]
loss:        0.000499  [ 7392/ 8083]
loss:        0.000496  [ 7552/ 8083]
loss:        0.000623  [ 7712/ 8083]
loss:        0.000499  [ 7872/ 8083]
loss:        0.000449  [ 8032/ 8083]

Avg validation loss:        0.000527
Learning rate: [1.0000000000000002e-07]
EarlyStopping counter: 4 out of 10


Epoch 25
-------------------------------
loss:        0.000473  [   32/ 8083]
loss:        0.000661  [  192/ 8083]
loss:        0.000616  [  352/ 8083]
loss:        0.000490  [  512/ 8083]
loss:        0.000602  [  672/ 8083]
loss:        0.000444  [  832/ 8083]
loss:        0.000485  [  992/ 8083]
loss:        0.000540  [ 1152/ 8083]
loss:        0.000568  [ 1312/ 8083]
loss:        0.000535  [ 1472/ 8083]
loss:        0.000558  [ 1632/ 8083]
loss:        0.000534  [ 1792/ 8083]
loss:        0.000465  [ 1952/ 8083]
loss:        0.000500  [ 2112/ 8083]
loss:        0.000592  [ 2272/ 8083]
loss:        0.000592  [ 2432/ 8083]
loss:        0.000587  [ 2592/ 8083]
loss:        0.000435  [ 2752/ 8083]
loss:        0.000452  [ 2912/ 8083]
loss:        0.000496  [ 3072/ 8083]
loss:        0.000479  [ 3232/ 8083]
loss:        0.000501  [ 3392/ 8083]
loss:        0.000527  [ 3552/ 8083]
loss:        0.000511  [ 3712/ 8083]
loss:        0.000503  [ 3872/ 8083]
loss:        0.000566  [ 4032/ 8083]
loss:        0.000474  [ 4192/ 8083]
loss:        0.000488  [ 4352/ 8083]
loss:        0.000584  [ 4512/ 8083]
loss:        0.000459  [ 4672/ 8083]
loss:        0.000441  [ 4832/ 8083]
loss:        0.000477  [ 4992/ 8083]
loss:        0.000496  [ 5152/ 8083]
loss:        0.000536  [ 5312/ 8083]
loss:        0.000537  [ 5472/ 8083]
loss:        0.000512  [ 5632/ 8083]
loss:        0.000518  [ 5792/ 8083]
loss:        0.000501  [ 5952/ 8083]
loss:        0.000531  [ 6112/ 8083]
loss:        0.000524  [ 6272/ 8083]
loss:        0.000525  [ 6432/ 8083]
loss:        0.000608  [ 6592/ 8083]
loss:        0.000518  [ 6752/ 8083]
loss:        0.000582  [ 6912/ 8083]
loss:        0.000505  [ 7072/ 8083]
loss:        0.000568  [ 7232/ 8083]
loss:        0.000593  [ 7392/ 8083]
loss:        0.000459  [ 7552/ 8083]
loss:        0.000585  [ 7712/ 8083]
loss:        0.000578  [ 7872/ 8083]
loss:        0.000494  [ 8032/ 8083]

Avg validation loss:        0.000527
Learning rate: [1.0000000000000002e-07]
EarlyStopping counter: 5 out of 10


Epoch 26
-------------------------------
loss:        0.000522  [   32/ 8083]
loss:        0.000492  [  192/ 8083]
loss:        0.000546  [  352/ 8083]
loss:        0.000557  [  512/ 8083]
loss:        0.000589  [  672/ 8083]
loss:        0.000591  [  832/ 8083]
loss:        0.000492  [  992/ 8083]
loss:        0.000574  [ 1152/ 8083]
loss:        0.000448  [ 1312/ 8083]
loss:        0.000511  [ 1472/ 8083]
loss:        0.000514  [ 1632/ 8083]
loss:        0.000505  [ 1792/ 8083]
loss:        0.000455  [ 1952/ 8083]
loss:        0.000602  [ 2112/ 8083]
loss:        0.000472  [ 2272/ 8083]
loss:        0.000618  [ 2432/ 8083]
loss:        0.000661  [ 2592/ 8083]
loss:        0.000551  [ 2752/ 8083]
loss:        0.000565  [ 2912/ 8083]
loss:        0.000538  [ 3072/ 8083]
loss:        0.000492  [ 3232/ 8083]
loss:        0.000536  [ 3392/ 8083]
loss:        0.000607  [ 3552/ 8083]
loss:        0.000528  [ 3712/ 8083]
loss:        0.000402  [ 3872/ 8083]
loss:        0.000583  [ 4032/ 8083]
loss:        0.000544  [ 4192/ 8083]
loss:        0.000518  [ 4352/ 8083]
loss:        0.000552  [ 4512/ 8083]
loss:        0.000493  [ 4672/ 8083]
loss:        0.000488  [ 4832/ 8083]
loss:        0.000433  [ 4992/ 8083]
loss:        0.000466  [ 5152/ 8083]
loss:        0.000476  [ 5312/ 8083]
loss:        0.000525  [ 5472/ 8083]
loss:        0.000536  [ 5632/ 8083]
loss:        0.000480  [ 5792/ 8083]
loss:        0.000493  [ 5952/ 8083]
loss:        0.000570  [ 6112/ 8083]
loss:        0.000598  [ 6272/ 8083]
loss:        0.000633  [ 6432/ 8083]
loss:        0.000561  [ 6592/ 8083]
loss:        0.000438  [ 6752/ 8083]
loss:        0.000495  [ 6912/ 8083]
loss:        0.000535  [ 7072/ 8083]
loss:        0.000575  [ 7232/ 8083]
loss:        0.000549  [ 7392/ 8083]
loss:        0.000575  [ 7552/ 8083]
loss:        0.000502  [ 7712/ 8083]
loss:        0.000494  [ 7872/ 8083]
loss:        0.000598  [ 8032/ 8083]

Avg validation loss:        0.000525
Learning rate: [1.0000000000000002e-07]
EarlyStopping counter: 6 out of 10


Epoch 27
-------------------------------
loss:        0.000524  [   32/ 8083]
loss:        0.000568  [  192/ 8083]
loss:        0.000435  [  352/ 8083]
loss:        0.000466  [  512/ 8083]
loss:        0.000546  [  672/ 8083]
loss:        0.000595  [  832/ 8083]
loss:        0.000635  [  992/ 8083]
loss:        0.000545  [ 1152/ 8083]
loss:        0.000482  [ 1312/ 8083]
loss:        0.000641  [ 1472/ 8083]
loss:        0.000613  [ 1632/ 8083]
loss:        0.000577  [ 1792/ 8083]
loss:        0.000510  [ 1952/ 8083]
loss:        0.000438  [ 2112/ 8083]
loss:        0.000492  [ 2272/ 8083]
loss:        0.000531  [ 2432/ 8083]
loss:        0.000429  [ 2592/ 8083]
loss:        0.000569  [ 2752/ 8083]
loss:        0.000410  [ 2912/ 8083]
loss:        0.000462  [ 3072/ 8083]
loss:        0.000660  [ 3232/ 8083]
loss:        0.000548  [ 3392/ 8083]
loss:        0.000526  [ 3552/ 8083]
loss:        0.000579  [ 3712/ 8083]
loss:        0.000516  [ 3872/ 8083]
loss:        0.000471  [ 4032/ 8083]
loss:        0.000467  [ 4192/ 8083]
loss:        0.000499  [ 4352/ 8083]
loss:        0.000600  [ 4512/ 8083]
loss:        0.000458  [ 4672/ 8083]
loss:        0.000560  [ 4832/ 8083]
loss:        0.000456  [ 4992/ 8083]
loss:        0.000530  [ 5152/ 8083]
loss:        0.000462  [ 5312/ 8083]
loss:        0.000631  [ 5472/ 8083]
loss:        0.000448  [ 5632/ 8083]
loss:        0.000468  [ 5792/ 8083]
loss:        0.000549  [ 5952/ 8083]
loss:        0.000559  [ 6112/ 8083]
loss:        0.000574  [ 6272/ 8083]
loss:        0.000606  [ 6432/ 8083]
loss:        0.000455  [ 6592/ 8083]
loss:        0.000510  [ 6752/ 8083]
loss:        0.000410  [ 6912/ 8083]
loss:        0.000456  [ 7072/ 8083]
loss:        0.000501  [ 7232/ 8083]
loss:        0.000574  [ 7392/ 8083]
loss:        0.000407  [ 7552/ 8083]
loss:        0.000594  [ 7712/ 8083]
loss:        0.000461  [ 7872/ 8083]
loss:        0.000437  [ 8032/ 8083]

Avg validation loss:        0.000526
Learning rate: [1.0000000000000002e-07]
EarlyStopping counter: 7 out of 10


Epoch 28
-------------------------------
loss:        0.000519  [   32/ 8083]
loss:        0.000562  [  192/ 8083]
loss:        0.000526  [  352/ 8083]
loss:        0.000541  [  512/ 8083]
loss:        0.000459  [  672/ 8083]
loss:        0.000497  [  832/ 8083]
loss:        0.000493  [  992/ 8083]
loss:        0.000506  [ 1152/ 8083]
loss:        0.000526  [ 1312/ 8083]
loss:        0.000601  [ 1472/ 8083]
loss:        0.000490  [ 1632/ 8083]
loss:        0.000593  [ 1792/ 8083]
loss:        0.000509  [ 1952/ 8083]
loss:        0.000512  [ 2112/ 8083]
loss:        0.000513  [ 2272/ 8083]
loss:        0.000563  [ 2432/ 8083]
loss:        0.000573  [ 2592/ 8083]
loss:        0.000446  [ 2752/ 8083]
loss:        0.000417  [ 2912/ 8083]
loss:        0.000560  [ 3072/ 8083]
loss:        0.000622  [ 3232/ 8083]
loss:        0.000446  [ 3392/ 8083]
loss:        0.000534  [ 3552/ 8083]
loss:        0.000525  [ 3712/ 8083]
loss:        0.000458  [ 3872/ 8083]
loss:        0.000513  [ 4032/ 8083]
loss:        0.000571  [ 4192/ 8083]
loss:        0.000445  [ 4352/ 8083]
loss:        0.000405  [ 4512/ 8083]
loss:        0.000417  [ 4672/ 8083]
loss:        0.000560  [ 4832/ 8083]
loss:        0.000537  [ 4992/ 8083]
loss:        0.000507  [ 5152/ 8083]
loss:        0.000482  [ 5312/ 8083]
loss:        0.000405  [ 5472/ 8083]
loss:        0.000544  [ 5632/ 8083]
loss:        0.000468  [ 5792/ 8083]
loss:        0.000512  [ 5952/ 8083]
loss:        0.000636  [ 6112/ 8083]
loss:        0.000574  [ 6272/ 8083]
loss:        0.000560  [ 6432/ 8083]
loss:        0.000550  [ 6592/ 8083]
loss:        0.000530  [ 6752/ 8083]
loss:        0.000520  [ 6912/ 8083]
loss:        0.000621  [ 7072/ 8083]
loss:        0.000481  [ 7232/ 8083]
loss:        0.000462  [ 7392/ 8083]
loss:        0.000487  [ 7552/ 8083]
loss:        0.000567  [ 7712/ 8083]
loss:        0.000530  [ 7872/ 8083]
loss:        0.000530  [ 8032/ 8083]

Avg validation loss:        0.000527
Learning rate: [1.0000000000000004e-08]
EarlyStopping counter: 8 out of 10


Epoch 29
-------------------------------
loss:        0.000579  [   32/ 8083]
loss:        0.000611  [  192/ 8083]
loss:        0.000480  [  352/ 8083]
loss:        0.000622  [  512/ 8083]
loss:        0.000609  [  672/ 8083]
loss:        0.000611  [  832/ 8083]
loss:        0.000549  [  992/ 8083]
loss:        0.000617  [ 1152/ 8083]
loss:        0.000514  [ 1312/ 8083]
loss:        0.000517  [ 1472/ 8083]
loss:        0.000526  [ 1632/ 8083]
loss:        0.000480  [ 1792/ 8083]
loss:        0.000558  [ 1952/ 8083]
loss:        0.000459  [ 2112/ 8083]
loss:        0.000570  [ 2272/ 8083]
loss:        0.000461  [ 2432/ 8083]
loss:        0.000551  [ 2592/ 8083]
loss:        0.000534  [ 2752/ 8083]
loss:        0.000423  [ 2912/ 8083]
loss:        0.000547  [ 3072/ 8083]
loss:        0.000526  [ 3232/ 8083]
loss:        0.000622  [ 3392/ 8083]
loss:        0.000505  [ 3552/ 8083]
loss:        0.000592  [ 3712/ 8083]
loss:        0.000478  [ 3872/ 8083]
loss:        0.000393  [ 4032/ 8083]
loss:        0.000540  [ 4192/ 8083]
loss:        0.000503  [ 4352/ 8083]
loss:        0.000597  [ 4512/ 8083]
loss:        0.000529  [ 4672/ 8083]
loss:        0.000448  [ 4832/ 8083]
loss:        0.000475  [ 4992/ 8083]
loss:        0.000602  [ 5152/ 8083]
loss:        0.000585  [ 5312/ 8083]
loss:        0.000461  [ 5472/ 8083]
loss:        0.000501  [ 5632/ 8083]
loss:        0.000562  [ 5792/ 8083]
loss:        0.000572  [ 5952/ 8083]
loss:        0.000517  [ 6112/ 8083]
loss:        0.000522  [ 6272/ 8083]
loss:        0.000493  [ 6432/ 8083]
loss:        0.000519  [ 6592/ 8083]
loss:        0.000531  [ 6752/ 8083]
loss:        0.000421  [ 6912/ 8083]
loss:        0.000499  [ 7072/ 8083]
loss:        0.000382  [ 7232/ 8083]
loss:        0.000633  [ 7392/ 8083]
loss:        0.000512  [ 7552/ 8083]
loss:        0.000434  [ 7712/ 8083]
loss:        0.000572  [ 7872/ 8083]
loss:        0.000384  [ 8032/ 8083]

Avg validation loss:        0.000526
Learning rate: [1.0000000000000004e-08]
EarlyStopping counter: 9 out of 10


Epoch 30
-------------------------------
loss:        0.000563  [   32/ 8083]
loss:        0.000439  [  192/ 8083]
loss:        0.000474  [  352/ 8083]
loss:        0.000536  [  512/ 8083]
loss:        0.000534  [  672/ 8083]
loss:        0.000394  [  832/ 8083]
loss:        0.000482  [  992/ 8083]
loss:        0.000511  [ 1152/ 8083]
loss:        0.000532  [ 1312/ 8083]
loss:        0.000512  [ 1472/ 8083]
loss:        0.000538  [ 1632/ 8083]
loss:        0.000475  [ 1792/ 8083]
loss:        0.000603  [ 1952/ 8083]
loss:        0.000557  [ 2112/ 8083]
loss:        0.000466  [ 2272/ 8083]
loss:        0.000616  [ 2432/ 8083]
loss:        0.000580  [ 2592/ 8083]
loss:        0.000442  [ 2752/ 8083]
loss:        0.000463  [ 2912/ 8083]
loss:        0.000565  [ 3072/ 8083]
loss:        0.000528  [ 3232/ 8083]
loss:        0.000585  [ 3392/ 8083]
loss:        0.000468  [ 3552/ 8083]
loss:        0.000314  [ 3712/ 8083]
loss:        0.000537  [ 3872/ 8083]
loss:        0.000444  [ 4032/ 8083]
loss:        0.000531  [ 4192/ 8083]
loss:        0.000588  [ 4352/ 8083]
loss:        0.000527  [ 4512/ 8083]
loss:        0.000666  [ 4672/ 8083]
loss:        0.000475  [ 4832/ 8083]
loss:        0.000455  [ 4992/ 8083]
loss:        0.000555  [ 5152/ 8083]
loss:        0.000611  [ 5312/ 8083]
loss:        0.000592  [ 5472/ 8083]
loss:        0.000438  [ 5632/ 8083]
loss:        0.000475  [ 5792/ 8083]
loss:        0.000484  [ 5952/ 8083]
loss:        0.000521  [ 6112/ 8083]
loss:        0.000443  [ 6272/ 8083]
loss:        0.000533  [ 6432/ 8083]
loss:        0.000548  [ 6592/ 8083]
loss:        0.000483  [ 6752/ 8083]
loss:        0.000503  [ 6912/ 8083]
loss:        0.000566  [ 7072/ 8083]
loss:        0.000531  [ 7232/ 8083]
loss:        0.000466  [ 7392/ 8083]
loss:        0.000499  [ 7552/ 8083]
loss:        0.000495  [ 7712/ 8083]
loss:        0.000539  [ 7872/ 8083]
loss:        0.000510  [ 8032/ 8083]

Avg validation loss:        0.000526
Learning rate: [1.0000000000000004e-08]
EarlyStopping counter: 10 out of 10
Early stopping
Avg test loss:        0.000535 

Done!</code></pre>
</div>
</div>
<div id="cell-115" class="cell" data-execution_count="58">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># to look at the parameters (weights and biases) of the model</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="co"># print(model.state_dict())</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="loading-in-previous-models" class="level1">
<h1>Loading in previous models</h1>
<p>As weâ€™ve trained the model, the model parameters are already stored in the <code>model</code> object. But as we were training the model, we were saving it to file, and that, and other trained models can be loaded.</p>
<p>The model parameters that are being loaded must match the model object that has been defined above. If the model object has changed, the model parameters will not be able to be loaded.</p>
<div id="cell-117" class="cell" data-execution_count="129">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>path_save_weights</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="129">
<pre><code>'model_checkpoints/checkpoint_CNN_buffalo2005_2025-02-04.pt'</code></pre>
</div>
</div>
<section id="if-loading-a-previously-trained-model" class="level3">
<h3 class="anchored" data-anchor-id="if-loading-a-previously-trained-model">If loading a previously trained model</h3>
<div id="cell-119" class="cell" data-execution_count="130">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># to load previously saved weights</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a><span class="co"># path_save_weights = f'model_checkpoints/checkpoint_CNN_buffalo2005_2025-02-04.pt'</span></span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>model.load_state_dict(torch.load(path_save_weights, </span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a>                                 weights_only<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a>                                 map_location<span class="op">=</span>torch.device(<span class="st">'cpu'</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="130">
<pre><code>&lt;All keys matched successfully&gt;</code></pre>
</div>
</div>
</section>
</section>
<section id="view-model-outputs" class="level1">
<h1>View model outputs</h1>
<section id="save-the-validation-loss-as-a-dataframe" class="level3">
<h3 class="anchored" data-anchor-id="save-the-validation-loss-as-a-dataframe">Save the validation loss as a dataframe</h3>
<div id="cell-122" class="cell">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Directory for saving the loss dataframe</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>filename_loss_csv <span class="op">=</span> <span class="ss">f'outputs/deepSSF_val_loss_buffalo</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>today_date<span class="sc">}</span><span class="ss">.csv'</span></span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>val_losses_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"epoch"</span>: <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(val_losses) <span class="op">+</span> <span class="dv">1</span>),</span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"val_losses"</span>: val_losses</span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the validation losses to a CSV file</span></span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a>val_losses_df.to_csv(filename_loss_csv, index<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="plot-the-validation-loss" class="level3">
<h3 class="anchored" data-anchor-id="plot-the-validation-loss">Plot the validation loss</h3>
<div id="cell-124" class="cell">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Directory for saving the loss plots</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>filename_loss <span class="op">=</span> <span class="ss">f'outputs/model_training_local/val_loss_buffalo</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>today_date<span class="sc">}</span><span class="ss">.png'</span></span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the validation losses</span></span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>plt.plot(val_losses, label<span class="op">=</span><span class="st">'Validation Loss'</span>, color<span class="op">=</span><span class="st">'red'</span>)  <span class="co"># Plot validation loss in red</span></span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Validation Losses'</span>)</span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a>plt.legend()  <span class="co"># Show legend to distinguish lines</span></span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a>plt.savefig(filename_loss, dpi<span class="op">=</span><span class="dv">600</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-63-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="animation-of-model-training" class="level2">
<h2 class="anchored" data-anchor-id="animation-of-model-training">Animation of model training</h2>
<p>Hereâ€™s what the images saved during training look like when combined into an animation (from an earlier model training).</p>
<p>We can see the habitat selection subnetwork starts to give probability weight to certain features as it learns their association to next-steps. We can see this quite clearly with the river feature, which progressively downweights (indicating avoidance) as the training progresses.</p>
<p>As the model fine-tunes, the habitat selection process becomes more defined in the next-step probabilities.</p>
<p><img src="../figures/model_training.gif" class="img-fluid"></p>
</section>
</section>
<section id="test-the-model-on-sample-covariates" class="level1">
<h1>Test the model on sample covariates</h1>
<p>Use the same sample covariates as above (selected before training the model) from the <em>test</em> dataset, and then run the model on these covariates. To select a different sample, change the <code>iteration_index</code> in the code above and re-run those chunks.</p>
<p>Print the scalar values and plot the sample covariates</p>
<div id="cell-128" class="cell" data-execution_count="131">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># To save the outputs of the model, create a directory</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>output_dir <span class="op">=</span> <span class="ss">f'outputs/model_outputs/id</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_yday</span><span class="sc">{</span>yday_t2_integer<span class="sc">}</span><span class="ss">_hour</span><span class="sc">{</span>hour_t2_integer<span class="sc">}</span><span class="ss">'</span></span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>os.makedirs(output_dir, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Print relevant information about the current prediction context</span></span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a><span class="co"># such as time of day, day of year, and bearing angles in both radians and degrees.</span></span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Hour: </span><span class="sc">{</span>hour_t2_integer<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Day of the year: </span><span class="sc">{</span>yday_t2_integer<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Bearing (radians): </span><span class="sc">{</span>bearing<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Bearing (degrees): </span><span class="sc">{</span>bearing_degrees<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the covariates</span></span>
<span id="cb91-13"><a href="#cb91-13" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="fl">7.5</span>))</span>
<span id="cb91-14"><a href="#cb91-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-15"><a href="#cb91-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot NDVI</span></span>
<span id="cb91-16"><a href="#cb91-16" aria-hidden="true" tabindex="-1"></a>im1 <span class="op">=</span> axs[<span class="dv">0</span>, <span class="dv">0</span>].imshow(ndvi_natural.numpy(), cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb91-17"><a href="#cb91-17" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="st">'NDVI'</span>)</span>
<span id="cb91-18"><a href="#cb91-18" aria-hidden="true" tabindex="-1"></a>fig.colorbar(im1, ax<span class="op">=</span>axs[<span class="dv">0</span>, <span class="dv">0</span>])</span>
<span id="cb91-19"><a href="#cb91-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-20"><a href="#cb91-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Canopy cover</span></span>
<span id="cb91-21"><a href="#cb91-21" aria-hidden="true" tabindex="-1"></a>im2 <span class="op">=</span> axs[<span class="dv">0</span>, <span class="dv">1</span>].imshow(canopy_natural.numpy(), cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb91-22"><a href="#cb91-22" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>, <span class="dv">1</span>].set_title(<span class="st">'Canopy cover'</span>)</span>
<span id="cb91-23"><a href="#cb91-23" aria-hidden="true" tabindex="-1"></a>fig.colorbar(im2, ax<span class="op">=</span>axs[<span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb91-24"><a href="#cb91-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-25"><a href="#cb91-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Herbaceous vegetation</span></span>
<span id="cb91-26"><a href="#cb91-26" aria-hidden="true" tabindex="-1"></a>im3 <span class="op">=</span> axs[<span class="dv">1</span>, <span class="dv">0</span>].imshow(herby_natural.numpy(), cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb91-27"><a href="#cb91-27" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>, <span class="dv">0</span>].set_title(<span class="st">'Herbaceous vegetation'</span>)</span>
<span id="cb91-28"><a href="#cb91-28" aria-hidden="true" tabindex="-1"></a>fig.colorbar(im3, ax<span class="op">=</span>axs[<span class="dv">1</span>, <span class="dv">0</span>])</span>
<span id="cb91-29"><a href="#cb91-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-30"><a href="#cb91-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Slope</span></span>
<span id="cb91-31"><a href="#cb91-31" aria-hidden="true" tabindex="-1"></a>im4 <span class="op">=</span> axs[<span class="dv">1</span>, <span class="dv">1</span>].imshow(slope_natural.numpy(), cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb91-32"><a href="#cb91-32" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>, <span class="dv">1</span>].set_title(<span class="st">'Slope'</span>)</span>
<span id="cb91-33"><a href="#cb91-33" aria-hidden="true" tabindex="-1"></a>fig.colorbar(im4, ax<span class="op">=</span>axs[<span class="dv">1</span>, <span class="dv">1</span>])</span>
<span id="cb91-34"><a href="#cb91-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-35"><a href="#cb91-35" aria-hidden="true" tabindex="-1"></a>filename_covs <span class="op">=</span> <span class="ss">f'</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/id</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_sample</span><span class="sc">{</span>iteration_index<span class="sc">}</span><span class="ss">_yday</span><span class="sc">{</span>yday_t2_integer<span class="sc">}</span><span class="ss">_hour</span><span class="sc">{</span>hour_t2_integer<span class="sc">}</span><span class="ss">_bearing</span><span class="sc">{</span>bearing_degrees<span class="sc">}</span><span class="ss">_next_r</span><span class="sc">{</span>row<span class="sc">}</span><span class="ss">_c</span><span class="sc">{</span>column<span class="sc">}</span><span class="ss">.png'</span></span>
<span id="cb91-36"><a href="#cb91-36" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb91-37"><a href="#cb91-37" aria-hidden="true" tabindex="-1"></a>plt.savefig(filename_covs, dpi<span class="op">=</span><span class="dv">600</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>) <span class="co"># if we want to save the figure</span></span>
<span id="cb91-38"><a href="#cb91-38" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb91-39"><a href="#cb91-39" aria-hidden="true" tabindex="-1"></a>plt.close()  <span class="co"># Close the figure to free memory</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Hour: 12
Day of the year: 7
Bearing (radians): -2.4189999103546143
Bearing (degrees): 221</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-64-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="run-the-model-on-the-sample-covariates" class="level2">
<h2 class="anchored" data-anchor-id="run-the-model-on-the-sample-covariates">Run the model on the sample covariates</h2>
<div id="cell-130" class="cell" data-execution_count="132">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Switch the model to evaluation mode (e.g., disables dropout, etc.)</span></span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Move all input tensors (x1, x2, x3) to the appropriate device (CPU/GPU)</span></span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> x1_sample.to(device)</span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> x2_sample.to(device)</span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a>x3 <span class="op">=</span> x3_sample.to(device)</span>
<span id="cb93-12"><a href="#cb93-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-13"><a href="#cb93-13" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-14"><a href="#cb93-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Pass the inputs through the model; 'test' will have shape [batch, H, W, 2]</span></span>
<span id="cb93-15"><a href="#cb93-15" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-16"><a href="#cb93-16" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> model((x1, x2, x3))</span>
<span id="cb93-17"><a href="#cb93-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test.shape)</span>
<span id="cb93-18"><a href="#cb93-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-19"><a href="#cb93-19" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-20"><a href="#cb93-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract and exponentiate the habitat density channel</span></span>
<span id="cb93-21"><a href="#cb93-21" aria-hidden="true" tabindex="-1"></a><span class="co">#    (at index 0 in the last dimension)</span></span>
<span id="cb93-22"><a href="#cb93-22" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-23"><a href="#cb93-23" aria-hidden="true" tabindex="-1"></a>hab_density <span class="op">=</span> test.detach().cpu().numpy()[<span class="dv">0</span>, :, :, <span class="dv">0</span>]</span>
<span id="cb93-24"><a href="#cb93-24" aria-hidden="true" tabindex="-1"></a>hab_density_exp <span class="op">=</span> np.exp(hab_density)</span>
<span id="cb93-25"><a href="#cb93-25" aria-hidden="true" tabindex="-1"></a><span class="co"># print(np.sum(hab_density_exp))  # Debug: check the sum of exponentiated values</span></span>
<span id="cb93-26"><a href="#cb93-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-27"><a href="#cb93-27" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-28"><a href="#cb93-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Create masks to remove unwanted edge cells from visualization</span></span>
<span id="cb93-29"><a href="#cb93-29" aria-hidden="true" tabindex="-1"></a><span class="co">#    (setting them to -âˆž affects the color scale in plots)</span></span>
<span id="cb93-30"><a href="#cb93-30" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-31"><a href="#cb93-31" aria-hidden="true" tabindex="-1"></a>x_mask <span class="op">=</span> np.ones_like(hab_density)</span>
<span id="cb93-32"><a href="#cb93-32" aria-hidden="true" tabindex="-1"></a>y_mask <span class="op">=</span> np.ones_like(hab_density)</span>
<span id="cb93-33"><a href="#cb93-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-34"><a href="#cb93-34" aria-hidden="true" tabindex="-1"></a>x_mask[:, :<span class="dv">3</span>] <span class="op">=</span> <span class="op">-</span>np.inf</span>
<span id="cb93-35"><a href="#cb93-35" aria-hidden="true" tabindex="-1"></a>x_mask[:, <span class="dv">98</span>:] <span class="op">=</span> <span class="op">-</span>np.inf</span>
<span id="cb93-36"><a href="#cb93-36" aria-hidden="true" tabindex="-1"></a>y_mask[:<span class="dv">3</span>, :] <span class="op">=</span> <span class="op">-</span>np.inf</span>
<span id="cb93-37"><a href="#cb93-37" aria-hidden="true" tabindex="-1"></a>y_mask[<span class="dv">98</span>:, :] <span class="op">=</span> <span class="op">-</span>np.inf</span>
<span id="cb93-38"><a href="#cb93-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-39"><a href="#cb93-39" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-40"><a href="#cb93-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the masks to the habitat density (log scale) and exponentiated version</span></span>
<span id="cb93-41"><a href="#cb93-41" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-42"><a href="#cb93-42" aria-hidden="true" tabindex="-1"></a>hab_density_mask <span class="op">=</span> hab_density <span class="op">*</span> x_mask <span class="op">*</span> y_mask</span>
<span id="cb93-43"><a href="#cb93-43" aria-hidden="true" tabindex="-1"></a>hab_density_exp_mask <span class="op">=</span> hab_density_exp <span class="op">*</span> x_mask <span class="op">*</span> y_mask</span>
<span id="cb93-44"><a href="#cb93-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-45"><a href="#cb93-45" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-46"><a href="#cb93-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot and save the habitat density in log scale</span></span>
<span id="cb93-47"><a href="#cb93-47" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-48"><a href="#cb93-48" aria-hidden="true" tabindex="-1"></a>plt.imshow(hab_density_mask)</span>
<span id="cb93-49"><a href="#cb93-49" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb93-50"><a href="#cb93-50" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Habitat selection probability (log)'</span>)</span>
<span id="cb93-51"><a href="#cb93-51" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="ss">f'</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/hab_log_prob_id</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>today_date<span class="sc">}</span><span class="ss">.png'</span>, dpi<span class="op">=</span><span class="dv">600</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb93-52"><a href="#cb93-52" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb93-53"><a href="#cb93-53" aria-hidden="true" tabindex="-1"></a>plt.close()</span>
<span id="cb93-54"><a href="#cb93-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-55"><a href="#cb93-55" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-56"><a href="#cb93-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot and save the habitat density in probability (exponentiated) scale</span></span>
<span id="cb93-57"><a href="#cb93-57" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-58"><a href="#cb93-58" aria-hidden="true" tabindex="-1"></a>plt.imshow(hab_density_exp_mask)</span>
<span id="cb93-59"><a href="#cb93-59" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb93-60"><a href="#cb93-60" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Habitat selection probability'</span>)</span>
<span id="cb93-61"><a href="#cb93-61" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="ss">f'</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/hab_prob_id</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>today_date<span class="sc">}</span><span class="ss">.png'</span>, dpi<span class="op">=</span><span class="dv">600</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb93-62"><a href="#cb93-62" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb93-63"><a href="#cb93-63" aria-hidden="true" tabindex="-1"></a>plt.close()</span>
<span id="cb93-64"><a href="#cb93-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-65"><a href="#cb93-65" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-66"><a href="#cb93-66" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract and exponentiate the movement density channel</span></span>
<span id="cb93-67"><a href="#cb93-67" aria-hidden="true" tabindex="-1"></a><span class="co">#    (at index 1 in the last dimension)</span></span>
<span id="cb93-68"><a href="#cb93-68" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-69"><a href="#cb93-69" aria-hidden="true" tabindex="-1"></a>move_density <span class="op">=</span> test.detach().cpu().numpy()[<span class="dv">0</span>, :, :, <span class="dv">1</span>]</span>
<span id="cb93-70"><a href="#cb93-70" aria-hidden="true" tabindex="-1"></a>move_density_exp <span class="op">=</span> np.exp(move_density)</span>
<span id="cb93-71"><a href="#cb93-71" aria-hidden="true" tabindex="-1"></a><span class="co"># print(np.sum(move_density_exp))  # Debug: check the sum of exponentiated values</span></span>
<span id="cb93-72"><a href="#cb93-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-73"><a href="#cb93-73" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-74"><a href="#cb93-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the same masking strategy to movement densities</span></span>
<span id="cb93-75"><a href="#cb93-75" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-76"><a href="#cb93-76" aria-hidden="true" tabindex="-1"></a>move_density_mask <span class="op">=</span> move_density <span class="op">*</span> x_mask <span class="op">*</span> y_mask</span>
<span id="cb93-77"><a href="#cb93-77" aria-hidden="true" tabindex="-1"></a>move_density_exp_mask <span class="op">=</span> move_density_exp <span class="op">*</span> x_mask <span class="op">*</span> y_mask</span>
<span id="cb93-78"><a href="#cb93-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-79"><a href="#cb93-79" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-80"><a href="#cb93-80" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot and save the movement density in log scale</span></span>
<span id="cb93-81"><a href="#cb93-81" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-82"><a href="#cb93-82" aria-hidden="true" tabindex="-1"></a>plt.imshow(move_density_mask)</span>
<span id="cb93-83"><a href="#cb93-83" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb93-84"><a href="#cb93-84" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Movement probability (log)'</span>)</span>
<span id="cb93-85"><a href="#cb93-85" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="ss">f'</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/move_log_prob_id</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>today_date<span class="sc">}</span><span class="ss">.png'</span>, dpi<span class="op">=</span><span class="dv">600</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb93-86"><a href="#cb93-86" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb93-87"><a href="#cb93-87" aria-hidden="true" tabindex="-1"></a>plt.close()</span>
<span id="cb93-88"><a href="#cb93-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-89"><a href="#cb93-89" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-90"><a href="#cb93-90" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot and save the movement density in probability (exponentiated) scale</span></span>
<span id="cb93-91"><a href="#cb93-91" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-92"><a href="#cb93-92" aria-hidden="true" tabindex="-1"></a>plt.imshow(move_density_exp_mask)</span>
<span id="cb93-93"><a href="#cb93-93" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb93-94"><a href="#cb93-94" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Movement probability'</span>)</span>
<span id="cb93-95"><a href="#cb93-95" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="ss">f'</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/move_prob_id</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>today_date<span class="sc">}</span><span class="ss">.png'</span>, dpi<span class="op">=</span><span class="dv">600</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb93-96"><a href="#cb93-96" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb93-97"><a href="#cb93-97" aria-hidden="true" tabindex="-1"></a>plt.close()</span>
<span id="cb93-98"><a href="#cb93-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-99"><a href="#cb93-99" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-100"><a href="#cb93-100" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the next-step density by adding habitat + movement (log-space)</span></span>
<span id="cb93-101"><a href="#cb93-101" aria-hidden="true" tabindex="-1"></a><span class="co">#     Then exponentiate and normalize</span></span>
<span id="cb93-102"><a href="#cb93-102" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-103"><a href="#cb93-103" aria-hidden="true" tabindex="-1"></a>step_density <span class="op">=</span> test[<span class="dv">0</span>, :, :, <span class="dv">0</span>] <span class="op">+</span> test[<span class="dv">0</span>, :, :, <span class="dv">1</span>]</span>
<span id="cb93-104"><a href="#cb93-104" aria-hidden="true" tabindex="-1"></a>step_density <span class="op">=</span> step_density.detach().cpu().numpy()</span>
<span id="cb93-105"><a href="#cb93-105" aria-hidden="true" tabindex="-1"></a>step_density_exp <span class="op">=</span> np.exp(step_density)</span>
<span id="cb93-106"><a href="#cb93-106" aria-hidden="true" tabindex="-1"></a><span class="co"># print('Sum of step density exp = ', np.sum(step_density_exp))  # Debug</span></span>
<span id="cb93-107"><a href="#cb93-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-108"><a href="#cb93-108" aria-hidden="true" tabindex="-1"></a>step_density_exp_norm <span class="op">=</span> step_density_exp <span class="op">/</span> np.<span class="bu">sum</span>(step_density_exp)</span>
<span id="cb93-109"><a href="#cb93-109" aria-hidden="true" tabindex="-1"></a><span class="co"># print('Sum of step density exp norm = ', np.sum(step_density_exp_norm))  # Debug</span></span>
<span id="cb93-110"><a href="#cb93-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-111"><a href="#cb93-111" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-112"><a href="#cb93-112" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply masks to the step densities (log and exponentiated + normalized)</span></span>
<span id="cb93-113"><a href="#cb93-113" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-114"><a href="#cb93-114" aria-hidden="true" tabindex="-1"></a>step_density_mask <span class="op">=</span> step_density <span class="op">*</span> x_mask <span class="op">*</span> y_mask</span>
<span id="cb93-115"><a href="#cb93-115" aria-hidden="true" tabindex="-1"></a>step_density_exp_norm_mask <span class="op">=</span> step_density_exp_norm <span class="op">*</span> x_mask <span class="op">*</span> y_mask</span>
<span id="cb93-116"><a href="#cb93-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-117"><a href="#cb93-117" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-118"><a href="#cb93-118" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot and save the combined next-step probability surface in log scale</span></span>
<span id="cb93-119"><a href="#cb93-119" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-120"><a href="#cb93-120" aria-hidden="true" tabindex="-1"></a>plt.imshow(step_density_mask)</span>
<span id="cb93-121"><a href="#cb93-121" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb93-122"><a href="#cb93-122" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Next-step probability (log)'</span>)</span>
<span id="cb93-123"><a href="#cb93-123" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="ss">f'</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/step_log_prob_id</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>today_date<span class="sc">}</span><span class="ss">.png'</span>, dpi<span class="op">=</span><span class="dv">600</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb93-124"><a href="#cb93-124" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb93-125"><a href="#cb93-125" aria-hidden="true" tabindex="-1"></a>plt.close()</span>
<span id="cb93-126"><a href="#cb93-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-127"><a href="#cb93-127" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-128"><a href="#cb93-128" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot and save the combined next-step probability surface in probability scale</span></span>
<span id="cb93-129"><a href="#cb93-129" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb93-130"><a href="#cb93-130" aria-hidden="true" tabindex="-1"></a>plt.imshow(step_density_exp_norm_mask)</span>
<span id="cb93-131"><a href="#cb93-131" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb93-132"><a href="#cb93-132" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Next-step probability'</span>)</span>
<span id="cb93-133"><a href="#cb93-133" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="ss">f'</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/step_prob_id</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>today_date<span class="sc">}</span><span class="ss">.png'</span>, dpi<span class="op">=</span><span class="dv">600</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb93-134"><a href="#cb93-134" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb93-135"><a href="#cb93-135" aria-hidden="true" tabindex="-1"></a>plt.close()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([1, 101, 101, 2])</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-65-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-65-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-65-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-65-output-5.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-65-output-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-65-output-7.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="extracting-convolution-layer-outputs" class="level1">
<h1>Extracting convolution layer outputs</h1>
<p>In the convolutional blocks, each convolutional layer learns a set of <strong>filters</strong> (kernels) that extract different features from the input data. In the habitat selection subnetwork, the convolution filters (and their associated bias parameters - not shown below) are the only parameters that are trained, and it is the filters that transform the set of input covariates into the habitat selection probabilities. They do this by maximising features of the inputs that correlate with observed next-steps.</p>
<p>For each convolutional layer, there are typically a number of filters. For the habitat selection subnetwork, we used 4 filters in the first two layers, and a single filter in the last layer. Each of these filters has a number of <strong>channels</strong> which correspond one-to-one with the input layers. The outputs of the filter channels are then combined to produce a feature map, with a single feature map produced for each filter. In successive layers, the feature maps become the input layers, and the filters operate on these layers. Because there are multiple filters in ech layer, they can â€˜specialiseâ€™ in extracting different features from the input layers.</p>
<p>By visualizing and inspecting these filters, and the corresponding feature maps, we can:</p>
<ul>
<li>Gain interpretability: Understand what kind of features the network is detectingâ€”e.g., edges, shapes, or textures.</li>
<li>Debug: Check if the filters have meaningful patterns or if something went wrong (e.g., all zeros or random noise).</li>
<li>Compare layers: See how early layers often learn low-level patterns while deeper layers learn more abstract features.</li>
</ul>
<p>We will first set up some activation hooks for storing the feature maps. Activation hooks are placed at certain points within the modelâ€™s forward pass and store intermediate results. We will also extract the convolution filters (which are weights of the model and as such donâ€™t require hooks - we can access them directly).</p>
<p>We will then run the sample covariates through the model and extract the feature maps from the habitat selection convolutional block, and plot them along with the covariates and convolution filters.</p>
<p>Note that there are also ReLU activation functions in the convolutional blocks, which are not shown below. These are applied to the feature maps, and set all negative values to zero. They are not learned parameters, but are part of the forward pass of the model.</p>
<section id="convolutional-layer-1" class="level2">
<h2 class="anchored" data-anchor-id="convolutional-layer-1">Convolutional layer 1</h2>
<section id="activation-hook" class="level3">
<h3 class="anchored" data-anchor-id="activation-hook">Activation hook</h3>
<div id="cell-133" class="cell" data-execution_count="133">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dictionary to store activation outputs</span></span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a>activation <span class="op">=</span> {}</span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_activation(name):</span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns a hook function that can be registered on a layer </span></span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a><span class="co">    to capture its output (i.e., feature maps) after the forward pass.</span></span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-11"><a href="#cb95-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb95-12"><a href="#cb95-12" aria-hidden="true" tabindex="-1"></a><span class="co">        name (str): The key under which the activation is stored in the 'activation' dict.</span></span>
<span id="cb95-13"><a href="#cb95-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb95-14"><a href="#cb95-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> hook(model, <span class="bu">input</span>, output):</span>
<span id="cb95-15"><a href="#cb95-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Detach and save the layer's output in the dictionary</span></span>
<span id="cb95-16"><a href="#cb95-16" aria-hidden="true" tabindex="-1"></a>        activation[name] <span class="op">=</span> output.detach()</span>
<span id="cb95-17"><a href="#cb95-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> hook</span>
<span id="cb95-18"><a href="#cb95-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-19"><a href="#cb95-19" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb95-20"><a href="#cb95-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Register a forward hook on the first convolution layer </span></span>
<span id="cb95-21"><a href="#cb95-21" aria-hidden="true" tabindex="-1"></a><span class="co">#    in the model's 'conv_habitat' block</span></span>
<span id="cb95-22"><a href="#cb95-22" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb95-23"><a href="#cb95-23" aria-hidden="true" tabindex="-1"></a>model.conv_habitat.conv2d[<span class="dv">0</span>].register_forward_hook(get_activation(<span class="st">"hab_conv1"</span>))</span>
<span id="cb95-24"><a href="#cb95-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-25"><a href="#cb95-25" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb95-26"><a href="#cb95-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform a forward pass through the model with the desired input</span></span>
<span id="cb95-27"><a href="#cb95-27" aria-hidden="true" tabindex="-1"></a><span class="co">#    The feature maps from the hooked layer will be stored in 'activation'</span></span>
<span id="cb95-28"><a href="#cb95-28" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb95-29"><a href="#cb95-29" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> model((x1, x2, x3))  <span class="co"># e.g., model((spatial_data_x, scalars_to_grid, bearing_x))</span></span>
<span id="cb95-30"><a href="#cb95-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-31"><a href="#cb95-31" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb95-32"><a href="#cb95-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Retrieve the captured feature maps from the dictionary</span></span>
<span id="cb95-33"><a href="#cb95-33" aria-hidden="true" tabindex="-1"></a><span class="co">#    and move them to the CPU for inspection</span></span>
<span id="cb95-34"><a href="#cb95-34" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb95-35"><a href="#cb95-35" aria-hidden="true" tabindex="-1"></a>feat_maps1 <span class="op">=</span> activation[<span class="st">"hab_conv1"</span>].cpu()</span>
<span id="cb95-36"><a href="#cb95-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Feature map shape:"</span>, feat_maps1.shape)</span>
<span id="cb95-37"><a href="#cb95-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Typically shape: (batch_size, out_channels, height, width)</span></span>
<span id="cb95-38"><a href="#cb95-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-39"><a href="#cb95-39" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb95-40"><a href="#cb95-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the feature maps for the first sample in the batch</span></span>
<span id="cb95-41"><a href="#cb95-41" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb95-42"><a href="#cb95-42" aria-hidden="true" tabindex="-1"></a>feat_maps1_sample <span class="op">=</span> feat_maps1[<span class="dv">0</span>]  <span class="co"># Shape: (out_channels, H, W)</span></span>
<span id="cb95-43"><a href="#cb95-43" aria-hidden="true" tabindex="-1"></a>num_maps1 <span class="op">=</span> feat_maps1_sample.shape[<span class="dv">0</span>]</span>
<span id="cb95-44"><a href="#cb95-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of feature maps:"</span>, num_maps1)</span>
<span id="cb95-45"><a href="#cb95-45" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Feature map shape: torch.Size([1, 4, 101, 101])
Number of feature maps: 4</code></pre>
</div>
</div>
</section>
<section id="stack-spatial-and-scalar-as-grid-covariates" class="level3">
<h3 class="anchored" data-anchor-id="stack-spatial-and-scalar-as-grid-covariates">Stack spatial and scalar (as grid) covariates</h3>
<p>For plotting. Also create a vector of names to index over.</p>
<div id="cell-135" class="cell" data-execution_count="134">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>covariate_stack <span class="op">=</span> torch.cat([x1, scalar_maps], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(covariate_stack.shape)</span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a>covariate_names <span class="op">=</span> [<span class="st">'NDVI'</span>, <span class="st">'Canopy cover'</span>, <span class="st">'Herbaceous vegetation'</span>, <span class="st">'Slope'</span>, </span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'Hour sin'</span>, <span class="st">'Hour cos'</span>, <span class="st">'yday sin'</span>, <span class="st">'yday cos'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([1, 8, 101, 101])</code></pre>
</div>
</div>
</section>
<section id="extract-filters-and-plot" class="level3">
<h3 class="anchored" data-anchor-id="extract-filters-and-plot">Extract filters and plot</h3>
<div id="cell-137" class="cell" data-execution_count="135">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Check or print the convolution layer in conv_habitat (for debugging)</span></span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.conv_habitat.conv2d)</span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-6"><a href="#cb99-6" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb99-7"><a href="#cb99-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the model to evaluation mode (disables dropout, etc.)</span></span>
<span id="cb99-8"><a href="#cb99-8" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb99-9"><a href="#cb99-9" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb99-10"><a href="#cb99-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-11"><a href="#cb99-11" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb99-12"><a href="#cb99-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the weights (filters) from the first convolution layer in conv_habitat</span></span>
<span id="cb99-13"><a href="#cb99-13" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb99-14"><a href="#cb99-14" aria-hidden="true" tabindex="-1"></a>filters_c1 <span class="op">=</span> model.conv_habitat.conv2d[<span class="dv">0</span>].weight.data.clone().cpu()</span>
<span id="cb99-15"><a href="#cb99-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Filters shape:"</span>, filters_c1.shape)</span>
<span id="cb99-16"><a href="#cb99-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Typically (out_channels, in_channels, kernel_height, kernel_width)</span></span>
<span id="cb99-17"><a href="#cb99-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-18"><a href="#cb99-18" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb99-19"><a href="#cb99-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize each filterâ€™s first channel in a grid of subplots</span></span>
<span id="cb99-20"><a href="#cb99-20" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb99-21"><a href="#cb99-21" aria-hidden="true" tabindex="-1"></a>num_filters_c1 <span class="op">=</span> filters_c1.shape[<span class="dv">1</span>]</span>
<span id="cb99-22"><a href="#cb99-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(num_filters_c1)</span>
<span id="cb99-23"><a href="#cb99-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-24"><a href="#cb99-24" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> z <span class="kw">in</span> <span class="bu">range</span>(num_maps1):</span>
<span id="cb99-25"><a href="#cb99-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-26"><a href="#cb99-26" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, num_filters_c1, figsize<span class="op">=</span>(<span class="dv">2</span><span class="op">*</span>num_filters_c1, <span class="dv">4</span>))</span>
<span id="cb99-27"><a href="#cb99-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_filters_c1):</span>
<span id="cb99-28"><a href="#cb99-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-29"><a href="#cb99-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add the covariates as the first row of subplots</span></span>
<span id="cb99-30"><a href="#cb99-30" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">0</span>,i].imshow(covariate_stack[<span class="dv">0</span>, i].detach().cpu().numpy(), cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb99-31"><a href="#cb99-31" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">0</span>,i].axis(<span class="st">'off'</span>)</span>
<span id="cb99-32"><a href="#cb99-32" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">0</span>,i].set_title(<span class="ss">f'</span><span class="sc">{</span>covariate_names[i]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb99-33"><a href="#cb99-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">&gt;</span> <span class="dv">3</span>:</span>
<span id="cb99-34"><a href="#cb99-34" aria-hidden="true" tabindex="-1"></a>            im1 <span class="op">=</span> axes[<span class="dv">0</span>,i].imshow(covariate_stack[<span class="dv">0</span>, i].detach().cpu().numpy(), cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb99-35"><a href="#cb99-35" aria-hidden="true" tabindex="-1"></a>            im1.set_clim(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb99-36"><a href="#cb99-36" aria-hidden="true" tabindex="-1"></a>            axes[<span class="dv">0</span>,i].text(scalar_maps.shape[<span class="dv">2</span>] <span class="op">//</span> <span class="dv">2</span>, scalar_maps.shape[<span class="dv">3</span>] <span class="op">//</span> <span class="dv">2</span>, </span>
<span id="cb99-37"><a href="#cb99-37" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f'Value: </span><span class="sc">{</span><span class="bu">round</span>(x2[<span class="dv">0</span>, i<span class="op">-</span><span class="dv">4</span>].item(), <span class="dv">2</span>)<span class="sc">}</span><span class="ss">'</span>, </span>
<span id="cb99-38"><a href="#cb99-38" aria-hidden="true" tabindex="-1"></a>                ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'center'</span>, color<span class="op">=</span><span class="st">'white'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb99-39"><a href="#cb99-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-40"><a href="#cb99-40" aria-hidden="true" tabindex="-1"></a>        kernel <span class="op">=</span> filters_c1[z, i, :, :]  <span class="co"># Show the first input channel</span></span>
<span id="cb99-41"><a href="#cb99-41" aria-hidden="true" tabindex="-1"></a>        im <span class="op">=</span> axes[<span class="dv">1</span>,i].imshow(kernel, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb99-42"><a href="#cb99-42" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">1</span>,i].axis(<span class="st">'off'</span>)</span>
<span id="cb99-43"><a href="#cb99-43" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">1</span>,i].set_title(<span class="ss">f'Layer 1, Filter </span><span class="sc">{</span>z<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb99-44"><a href="#cb99-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Annotate each cell with the numeric value</span></span>
<span id="cb99-45"><a href="#cb99-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> (j, k), val <span class="kw">in</span> np.ndenumerate(kernel):</span>
<span id="cb99-46"><a href="#cb99-46" aria-hidden="true" tabindex="-1"></a>            axes[<span class="dv">1</span>,i].text(k, j, <span class="ss">f'</span><span class="sc">{</span>val<span class="sc">:.2f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'center'</span>, color<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb99-47"><a href="#cb99-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-48"><a href="#cb99-48" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb99-49"><a href="#cb99-49" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="ss">f'</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/id</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_conv_layer1_filters</span><span class="sc">{</span>z<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>today_date<span class="sc">}</span><span class="ss">.png'</span>, dpi<span class="op">=</span><span class="dv">600</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb99-50"><a href="#cb99-50" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb99-51"><a href="#cb99-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-52"><a href="#cb99-52" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb99-53"><a href="#cb99-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># -----------------------------------------------------------</span></span>
<span id="cb99-54"><a href="#cb99-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Loop over each feature map channel and save them as images.</span></span>
<span id="cb99-55"><a href="#cb99-55" aria-hidden="true" tabindex="-1"></a>    <span class="co">#    Multiply by x_mask * y_mask if you need to mask out edges.</span></span>
<span id="cb99-56"><a href="#cb99-56" aria-hidden="true" tabindex="-1"></a>    <span class="co"># -----------------------------------------------------------</span></span>
<span id="cb99-57"><a href="#cb99-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-58"><a href="#cb99-58" aria-hidden="true" tabindex="-1"></a>    plt.figure()</span>
<span id="cb99-59"><a href="#cb99-59" aria-hidden="true" tabindex="-1"></a>    plt.imshow(feat_maps1_sample[z].numpy() <span class="op">*</span> x_mask <span class="op">*</span> y_mask, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb99-60"><a href="#cb99-60" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"Layer 1, Feature Map </span><span class="sc">{</span>z<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb99-61"><a href="#cb99-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Hide axis if you prefer: plt.axis('off')</span></span>
<span id="cb99-62"><a href="#cb99-62" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="ss">f'</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/id</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_conv_layer1_feature_map</span><span class="sc">{</span>z<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>today_date<span class="sc">}</span><span class="ss">.png'</span>, dpi<span class="op">=</span><span class="dv">600</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb99-63"><a href="#cb99-63" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb99-64"><a href="#cb99-64" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Sequential(
  (0): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(4, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
Filters shape: torch.Size([4, 8, 3, 3])
8</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-68-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-68-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-68-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-68-output-5.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-68-output-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-68-output-7.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-68-output-8.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-68-output-9.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="convolutional-layer-2" class="level2">
<h2 class="anchored" data-anchor-id="convolutional-layer-2">Convolutional layer 2</h2>
<section id="activation-hook-1" class="level3">
<h3 class="anchored" data-anchor-id="activation-hook-1">Activation hook</h3>
<div id="cell-139" class="cell" data-execution_count="136">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Register a forward hook on the second convolution layer </span></span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a><span class="co">#    in the model's 'conv_habitat' block</span></span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>model.conv_habitat.conv2d[<span class="dv">2</span>].register_forward_hook(get_activation(<span class="st">"hab_conv2"</span>))</span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb101-8"><a href="#cb101-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform a forward pass through the model with the desired input</span></span>
<span id="cb101-9"><a href="#cb101-9" aria-hidden="true" tabindex="-1"></a><span class="co">#    The feature maps from the hooked layer will be stored in 'activation'</span></span>
<span id="cb101-10"><a href="#cb101-10" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb101-11"><a href="#cb101-11" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> model((x1, x2, x3))  <span class="co"># e.g., model((spatial_data_x, scalars_to_grid, bearing_x))</span></span>
<span id="cb101-12"><a href="#cb101-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-13"><a href="#cb101-13" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb101-14"><a href="#cb101-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Retrieve the captured feature maps from the dictionary</span></span>
<span id="cb101-15"><a href="#cb101-15" aria-hidden="true" tabindex="-1"></a><span class="co">#    and move them to the CPU for inspection</span></span>
<span id="cb101-16"><a href="#cb101-16" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb101-17"><a href="#cb101-17" aria-hidden="true" tabindex="-1"></a>feat_maps2 <span class="op">=</span> activation[<span class="st">"hab_conv2"</span>].cpu()</span>
<span id="cb101-18"><a href="#cb101-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Feature map shape:"</span>, feat_maps2.shape)</span>
<span id="cb101-19"><a href="#cb101-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Typically shape: (batch_size, out_channels, height, width)</span></span>
<span id="cb101-20"><a href="#cb101-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-21"><a href="#cb101-21" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb101-22"><a href="#cb101-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the feature maps for the first sample in the batch</span></span>
<span id="cb101-23"><a href="#cb101-23" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb101-24"><a href="#cb101-24" aria-hidden="true" tabindex="-1"></a>feat_maps2_sample <span class="op">=</span> feat_maps2[<span class="dv">0</span>]  <span class="co"># Shape: (out_channels, H, W)</span></span>
<span id="cb101-25"><a href="#cb101-25" aria-hidden="true" tabindex="-1"></a>num_maps2 <span class="op">=</span> feat_maps2_sample.shape[<span class="dv">0</span>]</span>
<span id="cb101-26"><a href="#cb101-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of feature maps:"</span>, num_maps2)</span>
<span id="cb101-27"><a href="#cb101-27" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Feature map shape: torch.Size([1, 4, 101, 101])
Number of feature maps: 4</code></pre>
</div>
</div>
</section>
<section id="extract-filters-and-plot-1" class="level3">
<h3 class="anchored" data-anchor-id="extract-filters-and-plot-1">Extract filters and plot</h3>
<div id="cell-141" class="cell" data-execution_count="137">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the weights (filters) from the second convolution layer in conv_habitat</span></span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>filters_c2 <span class="op">=</span> model.conv_habitat.conv2d[<span class="dv">2</span>].weight.data.clone().cpu()</span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Filters shape:"</span>, filters_c2.shape)</span>
<span id="cb103-6"><a href="#cb103-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Typically (out_channels, in_channels, kernel_height, kernel_width)</span></span>
<span id="cb103-7"><a href="#cb103-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-8"><a href="#cb103-8" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb103-9"><a href="#cb103-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize each filterâ€™s first channel in a grid of subplots</span></span>
<span id="cb103-10"><a href="#cb103-10" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb103-11"><a href="#cb103-11" aria-hidden="true" tabindex="-1"></a>num_filters_c2 <span class="op">=</span> filters_c2.shape[<span class="dv">1</span>]</span>
<span id="cb103-12"><a href="#cb103-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(num_filters_c2)</span>
<span id="cb103-13"><a href="#cb103-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-14"><a href="#cb103-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> z <span class="kw">in</span> <span class="bu">range</span>(num_maps2):</span>
<span id="cb103-15"><a href="#cb103-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-16"><a href="#cb103-16" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, num_filters_c2, figsize<span class="op">=</span>(<span class="dv">2</span><span class="op">*</span>num_filters_c2, <span class="dv">4</span>))</span>
<span id="cb103-17"><a href="#cb103-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_filters_c2):</span>
<span id="cb103-18"><a href="#cb103-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-19"><a href="#cb103-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add the covariates as the first row of subplots</span></span>
<span id="cb103-20"><a href="#cb103-20" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">0</span>,i].imshow(feat_maps1_sample[i].numpy() <span class="op">*</span> x_mask <span class="op">*</span> y_mask, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb103-21"><a href="#cb103-21" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">0</span>,i].axis(<span class="st">'off'</span>)</span>
<span id="cb103-22"><a href="#cb103-22" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">0</span>,i].set_title(<span class="ss">f"Layer 1, Map </span><span class="sc">{</span>z<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb103-23"><a href="#cb103-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-24"><a href="#cb103-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># if i &gt; 3:</span></span>
<span id="cb103-25"><a href="#cb103-25" aria-hidden="true" tabindex="-1"></a>        <span class="co">#     im1 = axes[0,i].imshow(covariate_stack[0, i].detach().cpu().numpy(), cmap='viridis')</span></span>
<span id="cb103-26"><a href="#cb103-26" aria-hidden="true" tabindex="-1"></a>        <span class="co">#     im1.set_clim(-1, 1)</span></span>
<span id="cb103-27"><a href="#cb103-27" aria-hidden="true" tabindex="-1"></a>        <span class="co">#     axes[0,i].text(scalar_maps.shape[2] // 2, scalar_maps.shape[3] // 2, </span></span>
<span id="cb103-28"><a href="#cb103-28" aria-hidden="true" tabindex="-1"></a>        <span class="co">#         f'Value: {round(x2[0, i-4].item(), 2)}', </span></span>
<span id="cb103-29"><a href="#cb103-29" aria-hidden="true" tabindex="-1"></a>        <span class="co">#         ha='center', va='center', color='white', fontsize=12)</span></span>
<span id="cb103-30"><a href="#cb103-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-31"><a href="#cb103-31" aria-hidden="true" tabindex="-1"></a>        kernel <span class="op">=</span> filters_c2[z, i, :, :]  <span class="co"># Show the first input channel</span></span>
<span id="cb103-32"><a href="#cb103-32" aria-hidden="true" tabindex="-1"></a>        im <span class="op">=</span> axes[<span class="dv">1</span>,i].imshow(kernel, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb103-33"><a href="#cb103-33" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">1</span>,i].axis(<span class="st">'off'</span>)</span>
<span id="cb103-34"><a href="#cb103-34" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">1</span>,i].set_title(<span class="ss">f'Layer 2, Filter </span><span class="sc">{</span>z<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb103-35"><a href="#cb103-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Annotate each cell with the numeric value</span></span>
<span id="cb103-36"><a href="#cb103-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> (j, k), val <span class="kw">in</span> np.ndenumerate(kernel):</span>
<span id="cb103-37"><a href="#cb103-37" aria-hidden="true" tabindex="-1"></a>            axes[<span class="dv">1</span>,i].text(k, j, <span class="ss">f'</span><span class="sc">{</span>val<span class="sc">:.2f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'center'</span>, color<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb103-38"><a href="#cb103-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-39"><a href="#cb103-39" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb103-40"><a href="#cb103-40" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="ss">f'</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/id</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_conv_layer2_filters</span><span class="sc">{</span>z<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>today_date<span class="sc">}</span><span class="ss">.png'</span>, dpi<span class="op">=</span><span class="dv">600</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb103-41"><a href="#cb103-41" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb103-42"><a href="#cb103-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-43"><a href="#cb103-43" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb103-44"><a href="#cb103-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># -----------------------------------------------------------</span></span>
<span id="cb103-45"><a href="#cb103-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 6. Loop over each feature map channel and save them as images.</span></span>
<span id="cb103-46"><a href="#cb103-46" aria-hidden="true" tabindex="-1"></a>    <span class="co">#    Multiply by x_mask * y_mask if you need to mask out edges.</span></span>
<span id="cb103-47"><a href="#cb103-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># -----------------------------------------------------------</span></span>
<span id="cb103-48"><a href="#cb103-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-49"><a href="#cb103-49" aria-hidden="true" tabindex="-1"></a>    plt.figure()</span>
<span id="cb103-50"><a href="#cb103-50" aria-hidden="true" tabindex="-1"></a>    plt.imshow(feat_maps2_sample[z].numpy() <span class="op">*</span> x_mask <span class="op">*</span> y_mask, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb103-51"><a href="#cb103-51" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"Layer 2, Feature Map </span><span class="sc">{</span>z<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb103-52"><a href="#cb103-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Hide axis if you prefer: plt.axis('off')</span></span>
<span id="cb103-53"><a href="#cb103-53" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="ss">f'</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/id</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_conv_layer2_feature_map</span><span class="sc">{</span>z<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>today_date<span class="sc">}</span><span class="ss">.png'</span>, dpi<span class="op">=</span><span class="dv">600</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb103-54"><a href="#cb103-54" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb103-55"><a href="#cb103-55" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Filters shape: torch.Size([4, 4, 3, 3])
4</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-70-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-70-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-70-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-70-output-5.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-70-output-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-70-output-7.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-70-output-8.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-70-output-9.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="convolutional-layer-3" class="level2">
<h2 class="anchored" data-anchor-id="convolutional-layer-3">Convolutional layer 3</h2>
<section id="activation-hook-2" class="level3">
<h3 class="anchored" data-anchor-id="activation-hook-2">Activation hook</h3>
<div id="cell-143" class="cell" data-execution_count="138">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Register a forward hook on the third convolution layer </span></span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a><span class="co">#    in the model's 'conv_habitat' block</span></span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>model.conv_habitat.conv2d[<span class="dv">4</span>].register_forward_hook(get_activation(<span class="st">"hab_conv3"</span>))</span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform a forward pass through the model with the desired input</span></span>
<span id="cb105-9"><a href="#cb105-9" aria-hidden="true" tabindex="-1"></a><span class="co">#    The feature maps from the hooked layer will be stored in 'activation'</span></span>
<span id="cb105-10"><a href="#cb105-10" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb105-11"><a href="#cb105-11" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> model((x1, x2, x3))  <span class="co"># e.g., model((spatial_data_x, scalars_to_grid, bearing_x))</span></span>
<span id="cb105-12"><a href="#cb105-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-13"><a href="#cb105-13" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb105-14"><a href="#cb105-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Retrieve the captured feature maps from the dictionary</span></span>
<span id="cb105-15"><a href="#cb105-15" aria-hidden="true" tabindex="-1"></a><span class="co">#    and move them to the CPU for inspection</span></span>
<span id="cb105-16"><a href="#cb105-16" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb105-17"><a href="#cb105-17" aria-hidden="true" tabindex="-1"></a>feat_maps3 <span class="op">=</span> activation[<span class="st">"hab_conv3"</span>].cpu()</span>
<span id="cb105-18"><a href="#cb105-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Feature map shape:"</span>, feat_maps3.shape)</span>
<span id="cb105-19"><a href="#cb105-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Typically shape: (batch_size, out_channels, height, width)</span></span>
<span id="cb105-20"><a href="#cb105-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-21"><a href="#cb105-21" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb105-22"><a href="#cb105-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the feature maps for the first sample in the batch</span></span>
<span id="cb105-23"><a href="#cb105-23" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb105-24"><a href="#cb105-24" aria-hidden="true" tabindex="-1"></a>feat_maps3_sample <span class="op">=</span> feat_maps3[<span class="dv">0</span>]  <span class="co"># Shape: (out_channels, H, W)</span></span>
<span id="cb105-25"><a href="#cb105-25" aria-hidden="true" tabindex="-1"></a>num_maps3 <span class="op">=</span> feat_maps3_sample.shape[<span class="dv">0</span>]</span>
<span id="cb105-26"><a href="#cb105-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of feature maps:"</span>, num_maps3)</span>
<span id="cb105-27"><a href="#cb105-27" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Feature map shape: torch.Size([1, 1, 101, 101])
Number of feature maps: 1</code></pre>
</div>
</div>
</section>
<section id="extract-filters-and-plot-2" class="level3">
<h3 class="anchored" data-anchor-id="extract-filters-and-plot-2">Extract filters and plot</h3>
<div id="cell-145" class="cell" data-execution_count="139">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the weights (filters) from the second convolution layer in conv_habitat</span></span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a>filters_c3 <span class="op">=</span> model.conv_habitat.conv2d[<span class="dv">4</span>].weight.data.clone().cpu()</span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Filters shape:"</span>, filters_c3.shape)</span>
<span id="cb107-6"><a href="#cb107-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Typically (out_channels, in_channels, kernel_height, kernel_width)</span></span>
<span id="cb107-7"><a href="#cb107-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-8"><a href="#cb107-8" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb107-9"><a href="#cb107-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize each filterâ€™s first channel in a grid of subplots</span></span>
<span id="cb107-10"><a href="#cb107-10" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb107-11"><a href="#cb107-11" aria-hidden="true" tabindex="-1"></a>num_filters_c3 <span class="op">=</span> filters_c3.shape[<span class="dv">1</span>]</span>
<span id="cb107-12"><a href="#cb107-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(num_filters_c3)</span>
<span id="cb107-13"><a href="#cb107-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-14"><a href="#cb107-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> z <span class="kw">in</span> <span class="bu">range</span>(num_maps3):</span>
<span id="cb107-15"><a href="#cb107-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-16"><a href="#cb107-16" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, num_filters_c3, figsize<span class="op">=</span>(<span class="dv">2</span><span class="op">*</span>num_filters_c3, <span class="dv">4</span>))</span>
<span id="cb107-17"><a href="#cb107-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_filters_c3):</span>
<span id="cb107-18"><a href="#cb107-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-19"><a href="#cb107-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add the covariates as the first row of subplots</span></span>
<span id="cb107-20"><a href="#cb107-20" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">0</span>,i].imshow(feat_maps2_sample[i].numpy() <span class="op">*</span> x_mask <span class="op">*</span> y_mask, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb107-21"><a href="#cb107-21" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">0</span>,i].axis(<span class="st">'off'</span>)</span>
<span id="cb107-22"><a href="#cb107-22" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">0</span>,i].set_title(<span class="ss">f"Layer 2, Map </span><span class="sc">{</span>z<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb107-23"><a href="#cb107-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-24"><a href="#cb107-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-25"><a href="#cb107-25" aria-hidden="true" tabindex="-1"></a>        kernel <span class="op">=</span> filters_c3[z, i, :, :]  <span class="co"># Show the first input channel</span></span>
<span id="cb107-26"><a href="#cb107-26" aria-hidden="true" tabindex="-1"></a>        im <span class="op">=</span> axes[<span class="dv">1</span>,i].imshow(kernel, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb107-27"><a href="#cb107-27" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">1</span>,i].axis(<span class="st">'off'</span>)</span>
<span id="cb107-28"><a href="#cb107-28" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">1</span>,i].set_title(<span class="ss">f'Layer 3, Filter </span><span class="sc">{</span>z<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb107-29"><a href="#cb107-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Annotate each cell with the numeric value</span></span>
<span id="cb107-30"><a href="#cb107-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> (j, k), val <span class="kw">in</span> np.ndenumerate(kernel):</span>
<span id="cb107-31"><a href="#cb107-31" aria-hidden="true" tabindex="-1"></a>            axes[<span class="dv">1</span>,i].text(k, j, <span class="ss">f'</span><span class="sc">{</span>val<span class="sc">:.2f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'center'</span>, color<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb107-32"><a href="#cb107-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-33"><a href="#cb107-33" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb107-34"><a href="#cb107-34" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="ss">f'</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/id</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_conv_layer3_filters</span><span class="sc">{</span>z<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>today_date<span class="sc">}</span><span class="ss">.png'</span>, dpi<span class="op">=</span><span class="dv">600</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb107-35"><a href="#cb107-35" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb107-36"><a href="#cb107-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-37"><a href="#cb107-37" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb107-38"><a href="#cb107-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># -----------------------------------------------------------</span></span>
<span id="cb107-39"><a href="#cb107-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 6. Loop over each feature map channel and save them as images.</span></span>
<span id="cb107-40"><a href="#cb107-40" aria-hidden="true" tabindex="-1"></a>    <span class="co">#    Multiply by x_mask * y_mask if you need to mask out edges.</span></span>
<span id="cb107-41"><a href="#cb107-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># -----------------------------------------------------------</span></span>
<span id="cb107-42"><a href="#cb107-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-43"><a href="#cb107-43" aria-hidden="true" tabindex="-1"></a>    plt.figure()</span>
<span id="cb107-44"><a href="#cb107-44" aria-hidden="true" tabindex="-1"></a>    plt.imshow(feat_maps3_sample[z].numpy() <span class="op">*</span> x_mask <span class="op">*</span> y_mask, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb107-45"><a href="#cb107-45" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"Habitat selection log probability"</span>)</span>
<span id="cb107-46"><a href="#cb107-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Hide axis if you prefer: plt.axis('off')</span></span>
<span id="cb107-47"><a href="#cb107-47" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="ss">f'</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/id</span><span class="sc">{</span>buffalo_id<span class="sc">}</span><span class="ss">_conv_layer3_feature_map</span><span class="sc">{</span>z<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>today_date<span class="sc">}</span><span class="ss">.png'</span>, dpi<span class="op">=</span><span class="dv">600</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb107-48"><a href="#cb107-48" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb107-49"><a href="#cb107-49" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Filters shape: torch.Size([1, 4, 3, 3])
4</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-72-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-72-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="checking-estimated-movement-parameters" class="level1">
<h1>Checking estimated movement parameters</h1>
<p>Similarly to the convolutional layers, we can set hooks to extract the predicted movement parameters from the model, and assess how variable that is across samples.</p>
<div id="cell-147" class="cell" data-execution_count="140">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a list to store the intermediate output from the fully connected</span></span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a><span class="co">#    movement sub-network (fcn_movement_all)</span></span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true" tabindex="-1"></a>intermediate_output <span class="op">=</span> []</span>
<span id="cb109-6"><a href="#cb109-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-7"><a href="#cb109-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> hook(module, <span class="bu">input</span>, output):</span>
<span id="cb109-8"><a href="#cb109-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb109-9"><a href="#cb109-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Hook function that captures the output of the specified layer</span></span>
<span id="cb109-10"><a href="#cb109-10" aria-hidden="true" tabindex="-1"></a><span class="co">    (fcn_movement_all) during the forward pass.</span></span>
<span id="cb109-11"><a href="#cb109-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb109-12"><a href="#cb109-12" aria-hidden="true" tabindex="-1"></a>    intermediate_output.append(output)</span>
<span id="cb109-13"><a href="#cb109-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-14"><a href="#cb109-14" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb109-15"><a href="#cb109-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Register the forward hook on 'fcn_movement_all', so its outputs</span></span>
<span id="cb109-16"><a href="#cb109-16" aria-hidden="true" tabindex="-1"></a><span class="co">#    are recorded every time the model does a forward pass.</span></span>
<span id="cb109-17"><a href="#cb109-17" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb109-18"><a href="#cb109-18" aria-hidden="true" tabindex="-1"></a>hook_handle <span class="op">=</span> model.fcn_movement_all.register_forward_hook(hook)</span>
<span id="cb109-19"><a href="#cb109-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-20"><a href="#cb109-20" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb109-21"><a href="#cb109-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform a forward pass with the model in evaluation mode, </span></span>
<span id="cb109-22"><a href="#cb109-22" aria-hidden="true" tabindex="-1"></a><span class="co">#    disabling gradient computation.</span></span>
<span id="cb109-23"><a href="#cb109-23" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb109-24"><a href="#cb109-24" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb109-25"><a href="#cb109-25" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb109-26"><a href="#cb109-26" aria-hidden="true" tabindex="-1"></a>    final_output <span class="op">=</span> model((x1, x2, x3))</span>
<span id="cb109-27"><a href="#cb109-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-28"><a href="#cb109-28" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb109-29"><a href="#cb109-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect the captured intermediate output</span></span>
<span id="cb109-30"><a href="#cb109-30" aria-hidden="true" tabindex="-1"></a><span class="co">#    'intermediate_output[0]' corresponds to the first (and only) forward pass.</span></span>
<span id="cb109-31"><a href="#cb109-31" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb109-32"><a href="#cb109-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Intermediate output shape:"</span>, intermediate_output[<span class="dv">0</span>].shape)</span>
<span id="cb109-33"><a href="#cb109-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Intermediate output values:"</span>, intermediate_output[<span class="dv">0</span>][<span class="dv">0</span>])</span>
<span id="cb109-34"><a href="#cb109-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-35"><a href="#cb109-35" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb109-36"><a href="#cb109-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove the hook to avoid repeated capturing in subsequent passes</span></span>
<span id="cb109-37"><a href="#cb109-37" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb109-38"><a href="#cb109-38" aria-hidden="true" tabindex="-1"></a>hook_handle.remove()</span>
<span id="cb109-39"><a href="#cb109-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-40"><a href="#cb109-40" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb109-41"><a href="#cb109-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Unpack the parameters from the FCN output (assumes a specific ordering)</span></span>
<span id="cb109-42"><a href="#cb109-42" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb109-43"><a href="#cb109-43" aria-hidden="true" tabindex="-1"></a>gamma_shape1, gamma_scale1, gamma_weight1, <span class="op">\</span></span>
<span id="cb109-44"><a href="#cb109-44" aria-hidden="true" tabindex="-1"></a>gamma_shape2, gamma_scale2, gamma_weight2, <span class="op">\</span></span>
<span id="cb109-45"><a href="#cb109-45" aria-hidden="true" tabindex="-1"></a>vonmises_mu1, vonmises_kappa1, vonmises_weight1, <span class="op">\</span></span>
<span id="cb109-46"><a href="#cb109-46" aria-hidden="true" tabindex="-1"></a>vonmises_mu2, vonmises_kappa2, vonmises_weight2 <span class="op">=</span> intermediate_output[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb109-47"><a href="#cb109-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-48"><a href="#cb109-48" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb109-49"><a href="#cb109-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert parameters from log-space (if applicable) and print them</span></span>
<span id="cb109-50"><a href="#cb109-50" aria-hidden="true" tabindex="-1"></a><span class="co">#    Gamma and von Mises parameters</span></span>
<span id="cb109-51"><a href="#cb109-51" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb109-52"><a href="#cb109-52" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Gamma #1 ---</span></span>
<span id="cb109-53"><a href="#cb109-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Gamma shape 1:"</span>, torch.exp(gamma_shape1))</span>
<span id="cb109-54"><a href="#cb109-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Gamma scale 1:"</span>, torch.exp(gamma_scale1))</span>
<span id="cb109-55"><a href="#cb109-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Gamma weight 1:"</span>,</span>
<span id="cb109-56"><a href="#cb109-56" aria-hidden="true" tabindex="-1"></a>      torch.exp(gamma_weight1) <span class="op">/</span> (torch.exp(gamma_weight1) <span class="op">+</span> torch.exp(gamma_weight2)))</span>
<span id="cb109-57"><a href="#cb109-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-58"><a href="#cb109-58" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Gamma #2 ---</span></span>
<span id="cb109-59"><a href="#cb109-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Gamma shape 2:"</span>, torch.exp(gamma_shape2))</span>
<span id="cb109-60"><a href="#cb109-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Gamma scale 2:"</span>, torch.exp(gamma_scale2) <span class="op">*</span> <span class="dv">500</span>)  <span class="co"># scale factor 500</span></span>
<span id="cb109-61"><a href="#cb109-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Gamma weight 2:"</span>,</span>
<span id="cb109-62"><a href="#cb109-62" aria-hidden="true" tabindex="-1"></a>      torch.exp(gamma_weight2) <span class="op">/</span> (torch.exp(gamma_weight1) <span class="op">+</span> torch.exp(gamma_weight2)))</span>
<span id="cb109-63"><a href="#cb109-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-64"><a href="#cb109-64" aria-hidden="true" tabindex="-1"></a><span class="co"># --- von Mises #1 ---</span></span>
<span id="cb109-65"><a href="#cb109-65" aria-hidden="true" tabindex="-1"></a><span class="co"># % (2*np.pi) ensures the mu (angle) is wrapped within [0, 2Ï€)</span></span>
<span id="cb109-66"><a href="#cb109-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Von Mises mu 1:"</span>, vonmises_mu1 <span class="op">%</span> (<span class="dv">2</span><span class="op">*</span>np.pi))</span>
<span id="cb109-67"><a href="#cb109-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Von Mises kappa 1:"</span>, torch.exp(vonmises_kappa1))</span>
<span id="cb109-68"><a href="#cb109-68" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Von Mises weight 1:"</span>,</span>
<span id="cb109-69"><a href="#cb109-69" aria-hidden="true" tabindex="-1"></a>      torch.exp(vonmises_weight1) <span class="op">/</span> (torch.exp(vonmises_weight1) <span class="op">+</span> torch.exp(vonmises_weight2)))</span>
<span id="cb109-70"><a href="#cb109-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-71"><a href="#cb109-71" aria-hidden="true" tabindex="-1"></a><span class="co"># --- von Mises #2 ---</span></span>
<span id="cb109-72"><a href="#cb109-72" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Von Mises mu 2:"</span>, vonmises_mu2 <span class="op">%</span> (<span class="dv">2</span><span class="op">*</span>np.pi))</span>
<span id="cb109-73"><a href="#cb109-73" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Von Mises kappa 2:"</span>, torch.exp(vonmises_kappa2))</span>
<span id="cb109-74"><a href="#cb109-74" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Von Mises weight 2:"</span>,</span>
<span id="cb109-75"><a href="#cb109-75" aria-hidden="true" tabindex="-1"></a>      torch.exp(vonmises_weight2) <span class="op">/</span> (torch.exp(vonmises_weight1) <span class="op">+</span> torch.exp(vonmises_weight2)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Intermediate output shape: torch.Size([1, 12])
Intermediate output values: tensor([ 0.6031,  0.9589,  0.3745, -3.1411, -0.6276, -2.2735,  0.1798, -1.3312,
         0.5611,  0.1856, -0.4886, -0.6691])
Gamma shape 1: tensor(1.8278)
Gamma scale 1: tensor(2.6088)
Gamma weight 1: tensor(0.9339)
Gamma shape 2: tensor(0.0432)
Gamma scale 2: tensor(266.9277)
Gamma weight 2: tensor(0.0661)
Von Mises mu 1: tensor(0.1798)
Von Mises kappa 1: tensor(0.2642)
Von Mises weight 1: tensor(0.7738)
Von Mises mu 2: tensor(0.1856)
Von Mises kappa 2: tensor(0.6135)
Von Mises weight 2: tensor(0.2262)</code></pre>
</div>
</div>
<section id="plot-the-movement-distributions" class="level2">
<h2 class="anchored" data-anchor-id="plot-the-movement-distributions">Plot the movement distributions</h2>
<p>We can use the movement parameters to plot the step length and turning angle distributions for the sample covariates.</p>
<div id="cell-149" class="cell" data-execution_count="141">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Define helper functions for calculating Gamma and von Mises log-densities</span></span>
<span id="cb111-3"><a href="#cb111-3" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb111-4"><a href="#cb111-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gamma_density(x, shape, scale):</span>
<span id="cb111-5"><a href="#cb111-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb111-6"><a href="#cb111-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Computes the log of the Gamma density for each value in x.</span></span>
<span id="cb111-7"><a href="#cb111-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-8"><a href="#cb111-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb111-9"><a href="#cb111-9" aria-hidden="true" tabindex="-1"></a><span class="co">      x (Tensor): Input values for which to compute the density.</span></span>
<span id="cb111-10"><a href="#cb111-10" aria-hidden="true" tabindex="-1"></a><span class="co">      shape (float): Gamma shape parameter</span></span>
<span id="cb111-11"><a href="#cb111-11" aria-hidden="true" tabindex="-1"></a><span class="co">      scale (float): Gamma scale parameter</span></span>
<span id="cb111-12"><a href="#cb111-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-13"><a href="#cb111-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb111-14"><a href="#cb111-14" aria-hidden="true" tabindex="-1"></a><span class="co">      Tensor: The log of the Gamma probability density at each x.</span></span>
<span id="cb111-15"><a href="#cb111-15" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb111-16"><a href="#cb111-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span><span class="dv">1</span><span class="op">*</span>torch.lgamma(shape) <span class="op">-</span> shape<span class="op">*</span>torch.log(scale) <span class="op">\</span></span>
<span id="cb111-17"><a href="#cb111-17" aria-hidden="true" tabindex="-1"></a>           <span class="op">+</span> (shape <span class="op">-</span> <span class="dv">1</span>)<span class="op">*</span>torch.log(x) <span class="op">-</span> x<span class="op">/</span>scale</span>
<span id="cb111-18"><a href="#cb111-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-19"><a href="#cb111-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> vonmises_density(x, kappa, vm_mu):</span>
<span id="cb111-20"><a href="#cb111-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb111-21"><a href="#cb111-21" aria-hidden="true" tabindex="-1"></a><span class="co">    Computes the log of the von Mises density for each value in x.</span></span>
<span id="cb111-22"><a href="#cb111-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-23"><a href="#cb111-23" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb111-24"><a href="#cb111-24" aria-hidden="true" tabindex="-1"></a><span class="co">      x (Tensor): Input angles in radians.</span></span>
<span id="cb111-25"><a href="#cb111-25" aria-hidden="true" tabindex="-1"></a><span class="co">      kappa (float): Concentration parameter (kappa)</span></span>
<span id="cb111-26"><a href="#cb111-26" aria-hidden="true" tabindex="-1"></a><span class="co">      vm_mu (float): Mean direction parameter (mu)</span></span>
<span id="cb111-27"><a href="#cb111-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-28"><a href="#cb111-28" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb111-29"><a href="#cb111-29" aria-hidden="true" tabindex="-1"></a><span class="co">      Tensor: The log of the von Mises probability density at each x.</span></span>
<span id="cb111-30"><a href="#cb111-30" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb111-31"><a href="#cb111-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> kappa<span class="op">*</span>torch.cos(x <span class="op">-</span> vm_mu) <span class="op">-</span> <span class="dv">1</span><span class="op">*</span>(np.log(<span class="dv">2</span><span class="op">*</span>torch.pi) <span class="op">+</span> torch.log(torch.special.i0(kappa)))</span>
<span id="cb111-32"><a href="#cb111-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-33"><a href="#cb111-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-34"><a href="#cb111-34" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb111-35"><a href="#cb111-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Round and display the mixture weights for the Gamma distributions</span></span>
<span id="cb111-36"><a href="#cb111-36" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb111-37"><a href="#cb111-37" aria-hidden="true" tabindex="-1"></a>gamma_weight1_recovered <span class="op">=</span> torch.exp(gamma_weight1)<span class="op">/</span>(torch.exp(gamma_weight1) <span class="op">+</span> torch.exp(gamma_weight2))</span>
<span id="cb111-38"><a href="#cb111-38" aria-hidden="true" tabindex="-1"></a>rounded_gamma_weight1 <span class="op">=</span> <span class="bu">round</span>(gamma_weight1_recovered.item(), <span class="dv">2</span>)</span>
<span id="cb111-39"><a href="#cb111-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-40"><a href="#cb111-40" aria-hidden="true" tabindex="-1"></a>gamma_weight2_recovered <span class="op">=</span> torch.exp(gamma_weight2)<span class="op">/</span>(torch.exp(gamma_weight1) <span class="op">+</span> torch.exp(gamma_weight2))</span>
<span id="cb111-41"><a href="#cb111-41" aria-hidden="true" tabindex="-1"></a>rounded_gamma_weight2 <span class="op">=</span> <span class="bu">round</span>(gamma_weight2_recovered.item(), <span class="dv">2</span>)</span>
<span id="cb111-42"><a href="#cb111-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-43"><a href="#cb111-43" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb111-44"><a href="#cb111-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Round and display the mixture weights for the von Mises distributions</span></span>
<span id="cb111-45"><a href="#cb111-45" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb111-46"><a href="#cb111-46" aria-hidden="true" tabindex="-1"></a>vonmises_weight1_recovered <span class="op">=</span> torch.exp(vonmises_weight1)<span class="op">/</span>(torch.exp(vonmises_weight1) <span class="op">+</span> torch.exp(vonmises_weight2))</span>
<span id="cb111-47"><a href="#cb111-47" aria-hidden="true" tabindex="-1"></a>rounded_vm_weight1 <span class="op">=</span> <span class="bu">round</span>(vonmises_weight1_recovered.item(), <span class="dv">2</span>)</span>
<span id="cb111-48"><a href="#cb111-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-49"><a href="#cb111-49" aria-hidden="true" tabindex="-1"></a>vonmises_weight2_recovered <span class="op">=</span> torch.exp(vonmises_weight2)<span class="op">/</span>(torch.exp(vonmises_weight1) <span class="op">+</span> torch.exp(vonmises_weight2))</span>
<span id="cb111-50"><a href="#cb111-50" aria-hidden="true" tabindex="-1"></a>rounded_vm_weight2 <span class="op">=</span> <span class="bu">round</span>(vonmises_weight2_recovered.item(), <span class="dv">2</span>)</span>
<span id="cb111-51"><a href="#cb111-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-52"><a href="#cb111-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-53"><a href="#cb111-53" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb111-54"><a href="#cb111-54" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Plotting the Gamma mixture distribution</span></span>
<span id="cb111-55"><a href="#cb111-55" aria-hidden="true" tabindex="-1"></a><span class="co">#    a) Generate x values</span></span>
<span id="cb111-56"><a href="#cb111-56" aria-hidden="true" tabindex="-1"></a><span class="co">#    b) Compute individual Gamma log densities</span></span>
<span id="cb111-57"><a href="#cb111-57" aria-hidden="true" tabindex="-1"></a><span class="co">#    c) Exponentiate and combine using recovered weights</span></span>
<span id="cb111-58"><a href="#cb111-58" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb111-59"><a href="#cb111-59" aria-hidden="true" tabindex="-1"></a>x_values <span class="op">=</span> torch.linspace(<span class="dv">1</span>, <span class="dv">101</span>, <span class="dv">1000</span>).to(device)</span>
<span id="cb111-60"><a href="#cb111-60" aria-hidden="true" tabindex="-1"></a>gamma1_density <span class="op">=</span> gamma_density(x_values, torch.exp(gamma_shape1), torch.exp(gamma_scale1))</span>
<span id="cb111-61"><a href="#cb111-61" aria-hidden="true" tabindex="-1"></a>gamma2_density <span class="op">=</span> gamma_density(x_values, torch.exp(gamma_shape2), torch.exp(gamma_scale2)<span class="op">*</span><span class="dv">500</span>)</span>
<span id="cb111-62"><a href="#cb111-62" aria-hidden="true" tabindex="-1"></a>gamma_mixture_density <span class="op">=</span> gamma_weight1_recovered<span class="op">*</span>torch.exp(gamma1_density) <span class="op">\</span></span>
<span id="cb111-63"><a href="#cb111-63" aria-hidden="true" tabindex="-1"></a>                        <span class="op">+</span> gamma_weight2_recovered<span class="op">*</span>torch.exp(gamma2_density)</span>
<span id="cb111-64"><a href="#cb111-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-65"><a href="#cb111-65" aria-hidden="true" tabindex="-1"></a><span class="co"># Move results to CPU and convert to NumPy for plotting</span></span>
<span id="cb111-66"><a href="#cb111-66" aria-hidden="true" tabindex="-1"></a>x_values_np <span class="op">=</span> x_values.cpu().numpy()</span>
<span id="cb111-67"><a href="#cb111-67" aria-hidden="true" tabindex="-1"></a>gamma1_density_np <span class="op">=</span> np.exp(gamma1_density.cpu().numpy())</span>
<span id="cb111-68"><a href="#cb111-68" aria-hidden="true" tabindex="-1"></a>gamma2_density_np <span class="op">=</span> np.exp(gamma2_density.cpu().numpy())</span>
<span id="cb111-69"><a href="#cb111-69" aria-hidden="true" tabindex="-1"></a>gamma_mixture_density_np <span class="op">=</span> gamma_mixture_density.cpu().numpy()</span>
<span id="cb111-70"><a href="#cb111-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-71"><a href="#cb111-71" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb111-72"><a href="#cb111-72" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Plot the Gamma distributions and their mixture</span></span>
<span id="cb111-73"><a href="#cb111-73" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb111-74"><a href="#cb111-74" aria-hidden="true" tabindex="-1"></a>plt.plot(x_values_np, gamma1_density_np, label<span class="op">=</span><span class="ss">f'Gamma 1 Density: weight = </span><span class="sc">{</span>rounded_gamma_weight1<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb111-75"><a href="#cb111-75" aria-hidden="true" tabindex="-1"></a>plt.plot(x_values_np, gamma2_density_np, label<span class="op">=</span><span class="ss">f'Gamma 2 Density: weight = </span><span class="sc">{</span>rounded_gamma_weight2<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb111-76"><a href="#cb111-76" aria-hidden="true" tabindex="-1"></a>plt.plot(x_values_np, gamma_mixture_density_np, label<span class="op">=</span><span class="st">'Gamma Mixture Density'</span>)</span>
<span id="cb111-77"><a href="#cb111-77" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb111-78"><a href="#cb111-78" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb111-79"><a href="#cb111-79" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Gamma Density Function'</span>)</span>
<span id="cb111-80"><a href="#cb111-80" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb111-81"><a href="#cb111-81" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb111-82"><a href="#cb111-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-83"><a href="#cb111-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-84"><a href="#cb111-84" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb111-85"><a href="#cb111-85" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Plotting the von Mises mixture distribution</span></span>
<span id="cb111-86"><a href="#cb111-86" aria-hidden="true" tabindex="-1"></a><span class="co">#    a) Generate x values from -Ï€ to Ï€</span></span>
<span id="cb111-87"><a href="#cb111-87" aria-hidden="true" tabindex="-1"></a><span class="co">#    b) Compute individual von Mises log densities</span></span>
<span id="cb111-88"><a href="#cb111-88" aria-hidden="true" tabindex="-1"></a><span class="co">#    c) Exponentiate and combine using recovered weights</span></span>
<span id="cb111-89"><a href="#cb111-89" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb111-90"><a href="#cb111-90" aria-hidden="true" tabindex="-1"></a>x_values <span class="op">=</span> torch.linspace(<span class="op">-</span>np.pi, np.pi, <span class="dv">1000</span>).to(device)</span>
<span id="cb111-91"><a href="#cb111-91" aria-hidden="true" tabindex="-1"></a>vonmises1_density <span class="op">=</span> vonmises_density(x_values, torch.exp(vonmises_kappa1), vonmises_mu1)</span>
<span id="cb111-92"><a href="#cb111-92" aria-hidden="true" tabindex="-1"></a>vonmises2_density <span class="op">=</span> vonmises_density(x_values, torch.exp(vonmises_kappa2), vonmises_mu2)</span>
<span id="cb111-93"><a href="#cb111-93" aria-hidden="true" tabindex="-1"></a>vonmises_mixture_density <span class="op">=</span> vonmises_weight1_recovered<span class="op">*</span>torch.exp(vonmises1_density) <span class="op">\</span></span>
<span id="cb111-94"><a href="#cb111-94" aria-hidden="true" tabindex="-1"></a>                           <span class="op">+</span> vonmises_weight2_recovered<span class="op">*</span>torch.exp(vonmises2_density)</span>
<span id="cb111-95"><a href="#cb111-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-96"><a href="#cb111-96" aria-hidden="true" tabindex="-1"></a><span class="co"># Move results to CPU and convert to NumPy for plotting</span></span>
<span id="cb111-97"><a href="#cb111-97" aria-hidden="true" tabindex="-1"></a>x_values_np <span class="op">=</span> x_values.cpu().numpy()</span>
<span id="cb111-98"><a href="#cb111-98" aria-hidden="true" tabindex="-1"></a>vonmises1_density_np <span class="op">=</span> np.exp(vonmises1_density.cpu().numpy())</span>
<span id="cb111-99"><a href="#cb111-99" aria-hidden="true" tabindex="-1"></a>vonmises2_density_np <span class="op">=</span> np.exp(vonmises2_density.cpu().numpy())</span>
<span id="cb111-100"><a href="#cb111-100" aria-hidden="true" tabindex="-1"></a>vonmises_mixture_density_np <span class="op">=</span> vonmises_mixture_density.cpu().numpy()</span>
<span id="cb111-101"><a href="#cb111-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-102"><a href="#cb111-102" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb111-103"><a href="#cb111-103" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Plot the von Mises distributions and their mixture</span></span>
<span id="cb111-104"><a href="#cb111-104" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb111-105"><a href="#cb111-105" aria-hidden="true" tabindex="-1"></a>plt.plot(x_values_np, vonmises1_density_np, label<span class="op">=</span><span class="ss">f'Von Mises 1 Density: weight = </span><span class="sc">{</span>rounded_vm_weight1<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb111-106"><a href="#cb111-106" aria-hidden="true" tabindex="-1"></a>plt.plot(x_values_np, vonmises2_density_np, label<span class="op">=</span><span class="ss">f'Von Mises 2 Density: weight = </span><span class="sc">{</span>rounded_vm_weight2<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb111-107"><a href="#cb111-107" aria-hidden="true" tabindex="-1"></a>plt.plot(x_values_np, vonmises_mixture_density_np, label<span class="op">=</span><span class="st">'Von Mises Mixture Density'</span>)</span>
<span id="cb111-108"><a href="#cb111-108" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x (radians)'</span>)</span>
<span id="cb111-109"><a href="#cb111-109" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb111-110"><a href="#cb111-110" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Von Mises Density Function'</span>)</span>
<span id="cb111-111"><a href="#cb111-111" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="dv">0</span>, <span class="fl">1.2</span>)  <span class="co"># Set a limit for the y-axis</span></span>
<span id="cb111-112"><a href="#cb111-112" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb111-113"><a href="#cb111-113" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-74-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-74-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="generate-a-distribution-of-movement-parameters" class="level2">
<h2 class="anchored" data-anchor-id="generate-a-distribution-of-movement-parameters">Generate a distribution of movement parameters</h2>
<p>To see how variable the movement parameters are across samples, we can generate a distribution of movement parameters from a batch of samples.</p>
<p>We take the code from above that we used to create the DataLoader for the test data and increase the batch size (to get more samples to create the distribution from).</p>
<p>As weâ€™re not using the test dataset any more, weâ€™ll just put all of the samples in the same batch, and generate movement parameters for all of them.</p>
<div id="cell-151" class="cell">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'There are </span><span class="sc">{</span><span class="bu">len</span>(dataset_test)<span class="sc">}</span><span class="ss"> samples in the test dataset'</span>)</span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>bs <span class="op">=</span> <span class="bu">len</span>(dataset_test) <span class="co"># batch size</span></span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a>dataloader_test <span class="op">=</span> DataLoader(dataset<span class="op">=</span>dataset_test, batch_size<span class="op">=</span>bs, shuffle<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>There are 1010 samples in the test dataset</code></pre>
</div>
</div>
<p>Take all of the samples from the test dataset and put them in a single batch.</p>
<div id="cell-153" class="cell">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Fetch a batch of data from the training dataloader</span></span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb114-4"><a href="#cb114-4" aria-hidden="true" tabindex="-1"></a>x1_batch, x2_batch, x3_batch, labels <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(dataloader_test))</span>
<span id="cb114-5"><a href="#cb114-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-6"><a href="#cb114-6" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb114-7"><a href="#cb114-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Register a forward hook to capture the outputs </span></span>
<span id="cb114-8"><a href="#cb114-8" aria-hidden="true" tabindex="-1"></a><span class="co">#    from 'fcn_movement_all' during the forward pass</span></span>
<span id="cb114-9"><a href="#cb114-9" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb114-10"><a href="#cb114-10" aria-hidden="true" tabindex="-1"></a>hook_handle <span class="op">=</span> model.fcn_movement_all.register_forward_hook(hook)</span>
<span id="cb114-11"><a href="#cb114-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-12"><a href="#cb114-12" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb114-13"><a href="#cb114-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform a forward pass in evaluation mode to generate </span></span>
<span id="cb114-14"><a href="#cb114-14" aria-hidden="true" tabindex="-1"></a><span class="co">#    and capture the sub-network's outputs in 'intermediate_output'</span></span>
<span id="cb114-15"><a href="#cb114-15" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb114-16"><a href="#cb114-16" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()  <span class="co"># Disables certain layers like dropout</span></span>
<span id="cb114-17"><a href="#cb114-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-18"><a href="#cb114-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Pass the batch through the model</span></span>
<span id="cb114-19"><a href="#cb114-19" aria-hidden="true" tabindex="-1"></a>final_output <span class="op">=</span> model((x1_batch, x2_batch, x3_batch))</span>
<span id="cb114-20"><a href="#cb114-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-21"><a href="#cb114-21" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb114-22"><a href="#cb114-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare lists to store the distribution parameters </span></span>
<span id="cb114-23"><a href="#cb114-23" aria-hidden="true" tabindex="-1"></a><span class="co">#    for each sample in the batch</span></span>
<span id="cb114-24"><a href="#cb114-24" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb114-25"><a href="#cb114-25" aria-hidden="true" tabindex="-1"></a>gamma_shape1_list <span class="op">=</span> []</span>
<span id="cb114-26"><a href="#cb114-26" aria-hidden="true" tabindex="-1"></a>gamma_scale1_list <span class="op">=</span> []</span>
<span id="cb114-27"><a href="#cb114-27" aria-hidden="true" tabindex="-1"></a>gamma_weight1_list <span class="op">=</span> []</span>
<span id="cb114-28"><a href="#cb114-28" aria-hidden="true" tabindex="-1"></a>gamma_shape2_list <span class="op">=</span> []</span>
<span id="cb114-29"><a href="#cb114-29" aria-hidden="true" tabindex="-1"></a>gamma_scale2_list <span class="op">=</span> []</span>
<span id="cb114-30"><a href="#cb114-30" aria-hidden="true" tabindex="-1"></a>gamma_weight2_list <span class="op">=</span> []</span>
<span id="cb114-31"><a href="#cb114-31" aria-hidden="true" tabindex="-1"></a>vonmises_mu1_list <span class="op">=</span> []</span>
<span id="cb114-32"><a href="#cb114-32" aria-hidden="true" tabindex="-1"></a>vonmises_kappa1_list <span class="op">=</span> []</span>
<span id="cb114-33"><a href="#cb114-33" aria-hidden="true" tabindex="-1"></a>vonmises_weight1_list <span class="op">=</span> []</span>
<span id="cb114-34"><a href="#cb114-34" aria-hidden="true" tabindex="-1"></a>vonmises_mu2_list <span class="op">=</span> []</span>
<span id="cb114-35"><a href="#cb114-35" aria-hidden="true" tabindex="-1"></a>vonmises_kappa2_list <span class="op">=</span> []</span>
<span id="cb114-36"><a href="#cb114-36" aria-hidden="true" tabindex="-1"></a>vonmises_weight2_list <span class="op">=</span> []</span>
<span id="cb114-37"><a href="#cb114-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-38"><a href="#cb114-38" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb114-39"><a href="#cb114-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract parameters from 'intermediate_output' </span></span>
<span id="cb114-40"><a href="#cb114-40" aria-hidden="true" tabindex="-1"></a><span class="co">#    for every sample in the batch</span></span>
<span id="cb114-41"><a href="#cb114-41" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb114-42"><a href="#cb114-42" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch_output <span class="kw">in</span> intermediate_output:</span>
<span id="cb114-43"><a href="#cb114-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Each 'batch_output' corresponds to one forward pass;</span></span>
<span id="cb114-44"><a href="#cb114-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># it might contain multiple samples if the batch size &gt; 1</span></span>
<span id="cb114-45"><a href="#cb114-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> sample_output <span class="kw">in</span> batch_output:</span>
<span id="cb114-46"><a href="#cb114-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Unpack the 12 parameters of the Gamma and von Mises mixtures</span></span>
<span id="cb114-47"><a href="#cb114-47" aria-hidden="true" tabindex="-1"></a>        gamma_shape1, gamma_scale1, gamma_weight1, <span class="op">\</span></span>
<span id="cb114-48"><a href="#cb114-48" aria-hidden="true" tabindex="-1"></a>        gamma_shape2, gamma_scale2, gamma_weight2, <span class="op">\</span></span>
<span id="cb114-49"><a href="#cb114-49" aria-hidden="true" tabindex="-1"></a>        vonmises_mu1, vonmises_kappa1, vonmises_weight1, <span class="op">\</span></span>
<span id="cb114-50"><a href="#cb114-50" aria-hidden="true" tabindex="-1"></a>        vonmises_mu2, vonmises_kappa2, vonmises_weight2 <span class="op">=</span> sample_output</span>
<span id="cb114-51"><a href="#cb114-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-52"><a href="#cb114-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert log-space parameters to real space, then store</span></span>
<span id="cb114-53"><a href="#cb114-53" aria-hidden="true" tabindex="-1"></a>        gamma_shape1_list.append(torch.exp(gamma_shape1).item())</span>
<span id="cb114-54"><a href="#cb114-54" aria-hidden="true" tabindex="-1"></a>        gamma_scale1_list.append(torch.exp(gamma_scale1).item())</span>
<span id="cb114-55"><a href="#cb114-55" aria-hidden="true" tabindex="-1"></a>        gamma_weight1_list.append(</span>
<span id="cb114-56"><a href="#cb114-56" aria-hidden="true" tabindex="-1"></a>            (torch.exp(gamma_weight1)<span class="op">/</span>(torch.exp(gamma_weight1) <span class="op">+</span> torch.exp(gamma_weight2))).item()</span>
<span id="cb114-57"><a href="#cb114-57" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb114-58"><a href="#cb114-58" aria-hidden="true" tabindex="-1"></a>        gamma_shape2_list.append(torch.exp(gamma_shape2).item())</span>
<span id="cb114-59"><a href="#cb114-59" aria-hidden="true" tabindex="-1"></a>        gamma_scale2_list.append((torch.exp(gamma_scale2)<span class="op">*</span><span class="dv">500</span>).item())  <span class="co"># scale factor 500</span></span>
<span id="cb114-60"><a href="#cb114-60" aria-hidden="true" tabindex="-1"></a>        gamma_weight2_list.append(</span>
<span id="cb114-61"><a href="#cb114-61" aria-hidden="true" tabindex="-1"></a>            (torch.exp(gamma_weight2)<span class="op">/</span>(torch.exp(gamma_weight1) <span class="op">+</span> torch.exp(gamma_weight2))).item()</span>
<span id="cb114-62"><a href="#cb114-62" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb114-63"><a href="#cb114-63" aria-hidden="true" tabindex="-1"></a>        vonmises_mu1_list.append((vonmises_mu1 <span class="op">%</span> (<span class="dv">2</span><span class="op">*</span>np.pi)).item())</span>
<span id="cb114-64"><a href="#cb114-64" aria-hidden="true" tabindex="-1"></a>        vonmises_kappa1_list.append(torch.exp(vonmises_kappa1).item())</span>
<span id="cb114-65"><a href="#cb114-65" aria-hidden="true" tabindex="-1"></a>        vonmises_weight1_list.append(</span>
<span id="cb114-66"><a href="#cb114-66" aria-hidden="true" tabindex="-1"></a>            (torch.exp(vonmises_weight1)<span class="op">/</span>(torch.exp(vonmises_weight1) <span class="op">+</span> torch.exp(vonmises_weight2))).item()</span>
<span id="cb114-67"><a href="#cb114-67" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb114-68"><a href="#cb114-68" aria-hidden="true" tabindex="-1"></a>        vonmises_mu2_list.append((vonmises_mu2 <span class="op">%</span> (<span class="dv">2</span><span class="op">*</span>np.pi)).item())</span>
<span id="cb114-69"><a href="#cb114-69" aria-hidden="true" tabindex="-1"></a>        vonmises_kappa2_list.append(torch.exp(vonmises_kappa2).item())</span>
<span id="cb114-70"><a href="#cb114-70" aria-hidden="true" tabindex="-1"></a>        vonmises_weight2_list.append(</span>
<span id="cb114-71"><a href="#cb114-71" aria-hidden="true" tabindex="-1"></a>            (torch.exp(vonmises_weight2)<span class="op">/</span>(torch.exp(vonmises_weight1) <span class="op">+</span> torch.exp(vonmises_weight2))).item()</span>
<span id="cb114-72"><a href="#cb114-72" aria-hidden="true" tabindex="-1"></a>        )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="plot-the-distribution-of-movement-parameters" class="level3">
<h3 class="anchored" data-anchor-id="plot-the-distribution-of-movement-parameters">Plot the distribution of movement parameters</h3>
<div id="cell-155" class="cell" data-execution_count="144">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a helper function to plot histograms </span></span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a><span class="co">#    for the collected parameters</span></span>
<span id="cb115-4"><a href="#cb115-4" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb115-5"><a href="#cb115-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_histogram(data, title, xlabel):</span>
<span id="cb115-6"><a href="#cb115-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb115-7"><a href="#cb115-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Plots a histogram of the provided data.</span></span>
<span id="cb115-8"><a href="#cb115-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-9"><a href="#cb115-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb115-10"><a href="#cb115-10" aria-hidden="true" tabindex="-1"></a><span class="co">        data (list): Data points to plot in a histogram.</span></span>
<span id="cb115-11"><a href="#cb115-11" aria-hidden="true" tabindex="-1"></a><span class="co">        title (str): Title of the histogram plot.</span></span>
<span id="cb115-12"><a href="#cb115-12" aria-hidden="true" tabindex="-1"></a><span class="co">        xlabel (str): X-axis label.</span></span>
<span id="cb115-13"><a href="#cb115-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb115-14"><a href="#cb115-14" aria-hidden="true" tabindex="-1"></a>    plt.figure()</span>
<span id="cb115-15"><a href="#cb115-15" aria-hidden="true" tabindex="-1"></a>    plt.hist(data, bins<span class="op">=</span><span class="dv">30</span>, alpha<span class="op">=</span><span class="fl">0.75</span>)</span>
<span id="cb115-16"><a href="#cb115-16" aria-hidden="true" tabindex="-1"></a>    plt.title(title)</span>
<span id="cb115-17"><a href="#cb115-17" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(xlabel)</span>
<span id="cb115-18"><a href="#cb115-18" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb115-19"><a href="#cb115-19" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb115-20"><a href="#cb115-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-21"><a href="#cb115-21" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb115-22"><a href="#cb115-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot histograms for each parameter distribution</span></span>
<span id="cb115-23"><a href="#cb115-23" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb115-24"><a href="#cb115-24" aria-hidden="true" tabindex="-1"></a>plot_histogram(gamma_shape1_list, <span class="st">'Gamma Shape 1 Distribution'</span>, <span class="st">'Shape 1'</span>)</span>
<span id="cb115-25"><a href="#cb115-25" aria-hidden="true" tabindex="-1"></a>plot_histogram(gamma_scale1_list, <span class="st">'Gamma Scale 1 Distribution'</span>, <span class="st">'Scale 1'</span>)</span>
<span id="cb115-26"><a href="#cb115-26" aria-hidden="true" tabindex="-1"></a>plot_histogram(gamma_weight1_list, <span class="st">'Gamma Weight 1 Distribution'</span>, <span class="st">'Weight 1'</span>)</span>
<span id="cb115-27"><a href="#cb115-27" aria-hidden="true" tabindex="-1"></a>plot_histogram(gamma_shape2_list, <span class="st">'Gamma Shape 2 Distribution'</span>, <span class="st">'Shape 2'</span>)</span>
<span id="cb115-28"><a href="#cb115-28" aria-hidden="true" tabindex="-1"></a>plot_histogram(gamma_scale2_list, <span class="st">'Gamma Scale 2 Distribution'</span>, <span class="st">'Scale 2'</span>)</span>
<span id="cb115-29"><a href="#cb115-29" aria-hidden="true" tabindex="-1"></a>plot_histogram(gamma_weight2_list, <span class="st">'Gamma Weight 2 Distribution'</span>, <span class="st">'Weight 2'</span>)</span>
<span id="cb115-30"><a href="#cb115-30" aria-hidden="true" tabindex="-1"></a>plot_histogram(vonmises_mu1_list, <span class="st">'Von Mises Mu 1 Distribution'</span>, <span class="st">'Mu 1'</span>)</span>
<span id="cb115-31"><a href="#cb115-31" aria-hidden="true" tabindex="-1"></a>plot_histogram(vonmises_kappa1_list, <span class="st">'Von Mises Kappa 1 Distribution'</span>, <span class="st">'Kappa 1'</span>)</span>
<span id="cb115-32"><a href="#cb115-32" aria-hidden="true" tabindex="-1"></a>plot_histogram(vonmises_weight1_list, <span class="st">'Von Mises Weight 1 Distribution'</span>, <span class="st">'Weight 1'</span>)</span>
<span id="cb115-33"><a href="#cb115-33" aria-hidden="true" tabindex="-1"></a>plot_histogram(vonmises_mu2_list, <span class="st">'Von Mises Mu 2 Distribution'</span>, <span class="st">'Mu 2'</span>)</span>
<span id="cb115-34"><a href="#cb115-34" aria-hidden="true" tabindex="-1"></a>plot_histogram(vonmises_kappa2_list, <span class="st">'Von Mises Kappa 2 Distribution'</span>, <span class="st">'Kappa 2'</span>)</span>
<span id="cb115-35"><a href="#cb115-35" aria-hidden="true" tabindex="-1"></a>plot_histogram(vonmises_weight2_list, <span class="st">'Von Mises Weight 2 Distribution'</span>, <span class="st">'Weight 2'</span>)</span>
<span id="cb115-36"><a href="#cb115-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-37"><a href="#cb115-37" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb115-38"><a href="#cb115-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove the hook to stop capturing outputs </span></span>
<span id="cb115-39"><a href="#cb115-39" aria-hidden="true" tabindex="-1"></a><span class="co">#    in subsequent forward passes</span></span>
<span id="cb115-40"><a href="#cb115-40" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb115-41"><a href="#cb115-41" aria-hidden="true" tabindex="-1"></a>hook_handle.remove()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-77-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-77-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-77-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-77-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-77-output-5.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-77-output-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-77-output-7.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-77-output-8.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-77-output-9.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-77-output-10.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-77-output-11.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepSSF_train_files/figure-html/cell-77-output-12.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:scottwforrest@gmail.com">
      <i class="bi bi-envelope-at-fill" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/swforrest">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/swforrest/">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.com.au/citations?user=ECYMO3YAAAAJ&amp;hl=en&amp;authuser=1">
<p>Scholar</p>
</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>